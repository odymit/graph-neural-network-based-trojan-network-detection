{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "\n",
    "# POC 激活验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import dgl\n",
    "import torch\n",
    "from utils_gnn import cnn2graph_activation\n",
    "# from model_lib import mnist_cnn_model as father_model\n",
    "from utils_basic import load_spec_model\n",
    "from utils_gnn import padding, unpadding\n",
    "from dgl.data import DGLDataset\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from dgl import save_graphs, load_graphs\n",
    "import torch\n",
    "import json\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "# from model_lib.mnist_cnn_model import Model\n",
    "from random import randint\n",
    "from utils_basic import load_spec_model\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from torchinfo import summary\n",
    "import torch.nn.functional as F\n",
    "from dgl.nn.pytorch.conv import GINConv\n",
    "from dgl.nn.pytorch.glob import SumPooling, AvgPooling, MaxPooling, SortPooling\n",
    "from utils_gnn import MLP\n",
    "\n",
    "\n",
    "# x = '/home/dorian/repos/Meta-Nerual-Trojan-Detection/shadow_model_ckpt/mnist/models5/shadow_jumbo_9.model'\n",
    "x = './shadow_model_ckpt/mnist/models5/shadow_jumbo_0.model'\n",
    "# load model \n",
    "# Model = load_spec_model(father_model, '5')\n",
    "from model_lib.mnist_cnn_model import Model6 as Model\n",
    "model = Model(gpu=True)\n",
    "params = torch.load(x)\n",
    "model.load_state_dict(params)\n",
    "del params\n",
    "\n",
    "# load model detail \n",
    "model_detail = {}\n",
    "model_detail_path = \"./intermediate_data/model_detail.json\"\n",
    "import json\n",
    "with open(model_detail_path, 'r') as f:\n",
    "    model_detail = json.load(f)\n",
    "# print(model_detail)\n",
    "g = cnn2graph_activation(model, model_detail['mnist']['5'])\n",
    "dgl.save_graphs('./intermediate_data/grapj_test.bin', g)\n",
    "del model_detail\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "# from utils_gnn import SGNACT\n",
    "GPU = True\n",
    "if GPU:\n",
    "        torch.cuda.manual_seed_all(0)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "        \n",
    "transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "        ])\n",
    "BATCH_SIZE = 1\n",
    "# MNIST image dataset \n",
    "trainset = torchvision.datasets.MNIST(root='./raw_data/', train=True, download=True, transform=transform)\n",
    "dataloader = torch.utils.data.DataLoader(trainset, batch_size=BATCH_SIZE)\n",
    "\n",
    "# get a image\n",
    "image = None\n",
    "label = None\n",
    "for i, (x_in, y_in) in enumerate(dataloader):\n",
    "    image = x_in\n",
    "    model(image)\n",
    "    label = y_in\n",
    "    break\n",
    "del trainset, dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# define the init process\n",
    "def init_conv(data, data_size, weight, bias, kernel_size, stride, padding):\n",
    "    row, col = weight.size()\n",
    "    # print(weight.size())\n",
    "    # get actual conv kernel weight and bias\n",
    "    w = unpadding(weight, kernel_size[0], kernel_size[1])\n",
    "    w = w.unsqueeze(0).unsqueeze(0)\n",
    "    b = unpadding(bias, 1, 1)[0]\n",
    "    # get conv operator \n",
    "    # print(\"kernel_size, stride, padding:\")\n",
    "    # print(kernel_size, stride, padding)\n",
    "    operator = torch.nn.Conv2d(1, 1, kernel_size=kernel_size, \n",
    "                    stride=stride, padding=padding)\n",
    "    # set conv operator weight and bias\n",
    "    operator.weight.data = w\n",
    "    operator.bias.data = b\n",
    "    # conduct conv operation\n",
    "    # print(\"conv input size:\", data.size())\n",
    "    x = operator(data.to(\"cuda\"))\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "def initiate_node_feature(graph, image):\n",
    "    ft = None \n",
    "    mask = graph.ndata['tag'] == 0\n",
    "    out_channels = int(sum(mask))\n",
    "    ft = torch.zeros((len(graph.nodes()), 1, 1, 28, 28))\n",
    "    convd_size = torch.zeros((len(graph.nodes()), 2))\n",
    "    for i in range(out_channels):\n",
    "        kernel_size, stride, padding = graph.ndata['kernel_params'][i]\n",
    "        # do conv\n",
    "        res_ft = init_conv(image, None, graph.ndata['kernel_weight'][i], graph.ndata['bias'][i],\n",
    "                kernel_size, stride, padding)\n",
    "        # do relu\n",
    "        relu_opt = torch.nn.functional.relu\n",
    "        res_ft = relu_opt(res_ft)\n",
    "\n",
    "        # do max pooling\n",
    "        pooling = graph.ndata['pooling_params'][i]\n",
    "        if pooling.all() != 0:\n",
    "            # do max_pooling\n",
    "            kernel_size, stride, pad, dilation, ceil_mode = pooling\n",
    "            max_pooling_operator = torch.nn.MaxPool2d(kernel_size=kernel_size, stride=stride, \n",
    "                padding=pad, dilation=dilation, ceil_mode=ceil_mode)\n",
    "            \n",
    "            res_ft = max_pooling_operator(res_ft)\n",
    "        _, _, r, c = res_ft.size()\n",
    "        ft[i] = res_ft\n",
    "        convd_size[i] = torch.tensor([int(r), int(c)])\n",
    "    graph.ndata['ft'] = ft.to(\"cuda\")\n",
    "    graph.ndata['ft_size'] = convd_size.to(\"cuda\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 3, 3],\n",
      "       device='cuda:0')\n",
      "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71,\n",
      "        72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# init ft feature and get subg\n",
    "with torch.no_grad():\n",
    "    initiate_node_feature(g, image)\n",
    "print(g.ndata['tag'])\n",
    "# get node id\n",
    "def nodes_with_feature_smaller_two(nodes):\n",
    "    return nodes.data['tag'] <= 1\n",
    "nodes_idx = g.filter_nodes(nodes_with_feature_smaller_two)\n",
    "# print(nodes_idx)\n",
    "subg = dgl.node_subgraph(g, nodes_idx, relabel_nodes=True)\n",
    "print(subg.nodes())\n",
    "ft32 = None\n",
    "# got the right subg of conv layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from utils_gnn import equals, prepare_data\n",
    "import pdb\n",
    "\n",
    "def prepare_conv_data(nkernel_weight, \n",
    "                      nkernel_size, \n",
    "                      nkernel_bias, \n",
    "                      nkernel_params, \n",
    "                      channels):\n",
    "    # prepare conv kernel weight\n",
    "    _, width, height = nkernel_size\n",
    "    kernel_weight = nkernel_weight\n",
    "    kernel_weight = unpadding(kernel_weight, channels, width * height)\n",
    "    kernel_weight = kernel_weight.reshape(1, channels, width, height)\n",
    "    # prepare conv bias\n",
    "    bias = nkernel_bias\n",
    "    kernel_bias = unpadding(bias, 1, 1)[0]\n",
    "\n",
    "    # prepare conv operator\n",
    "    kernel_size, stride, pad = nkernel_params\n",
    "\n",
    "    return kernel_weight, kernel_bias, kernel_size, stride, pad\n",
    "    \n",
    "def do_operation(data, conv_opt, pooling_params):\n",
    "    # do conv\n",
    "    torch.save(data, \"./intermediate_data/data_test.pt\")\n",
    "    conv_ft = conv_opt(data.to(\"cuda\")).to(\"cuda\")\n",
    "    _, _, width, height = conv_ft.size()\n",
    "    np.savetxt(\"./intermediate_data/conv_ft.csv\", conv_ft.reshape(width, height).cpu().numpy(), delimiter=',')\n",
    "    # do relu\n",
    "    relu_ft = torch.nn.functional.relu(conv_ft)\n",
    "    np.savetxt(\"./intermediate_data/relu_ft.csv\", relu_ft.reshape(width, height).cpu().numpy(), delimiter=',')\n",
    "    ret_ft = relu_ft\n",
    "    # do pooling\n",
    "    if pooling_params.any() != 0:\n",
    "        kernel_size, stride, pad, dilation, ceil_mode = pooling_params\n",
    "        kernel_size, stride, pad, dilation, ceil_mode = int(kernel_size), int(stride), int(pad), int(dilation), bool(ceil_mode)\n",
    "        max_pooling_operator = torch.nn.MaxPool2d(kernel_size=kernel_size, stride=stride, \n",
    "            padding=pad, dilation=dilation, ceil_mode=ceil_mode)\n",
    "        \n",
    "        ret_ft = max_pooling_operator(relu_ft)\n",
    "        _, _, width, height = ret_ft.size()\n",
    "        np.savetxt(\"./intermediate_data/ret_ft.csv\", ret_ft.reshape(width, height).cpu().numpy(), delimiter=',')\n",
    "\n",
    "    return ret_ft\n",
    "\n",
    "\n",
    "\n",
    "def my_reduce(nodes):\n",
    "    # received data and their size\n",
    "    mfeat = nodes.mailbox['m']\n",
    "    msize = nodes.mailbox['n']\n",
    "    \n",
    "    mf_size = mfeat.size()\n",
    "    n_nodes = mf_size[0]\n",
    "    n_channels = mf_size[1]\n",
    "\n",
    "    # prepare ret_ft & ret_size, input size (1, 1, 28, 28)\n",
    "    ret_ft = torch.zeros((n_nodes, 1, 1, 28, 28)).to(\"cuda\")\n",
    "    ret_size = torch.zeros((n_nodes, 2)).to(\"cuda\")\n",
    "\n",
    "    # for each node, do conv for received data\n",
    "    for out_idx in range(n_nodes):\n",
    "\n",
    "        # prepare received data and conv weight\n",
    "        received_data = mfeat[out_idx]\n",
    "        received_size = msize[out_idx]\n",
    "        # skip if all zeros\n",
    "        if equals(received_data, zeros=True):\n",
    "            continue\n",
    "        # (n, 1, 1, 28, 28) -> (1, n, width, height)\n",
    "        data = prepare_data(received_data, received_size)\n",
    "\n",
    "        # prepare conv operator data\n",
    "        kernel_weight, kernel_bias, kernel_size, stride, pad = prepare_conv_data(nodes.data['kernel_weight'][out_idx], \n",
    "                                                                                nodes.data['kernel_size'][out_idx],\n",
    "                                                                                nodes.data['bias'][out_idx], \n",
    "                                                                                nodes.data['kernel_params'][out_idx], \n",
    "                                                                                n_channels)\n",
    "        \n",
    "        # prepare conv operator\n",
    "        conv_opt = torch.nn.Conv2d(n_channels, 1, kernel_size=kernel_size, stride=stride, padding=pad)\n",
    "        conv_opt.weight.data = kernel_weight\n",
    "        conv_opt.bias.data = kernel_bias\n",
    "\n",
    "        # do operation\n",
    "        ft = do_operation(data, conv_opt, nodes.data['pooling_params'][out_idx])\n",
    "\n",
    "        # save ft size\n",
    "        _, _, width, height = ft.size()\n",
    "        np.savetxt(\"./intermediate_data/ret_ft.csv\", ft.reshape(width, height).cpu().numpy(), delimiter=',')\n",
    "        pad_ft = padding(ft.reshape(width, height), 28, 28)\n",
    "        np.savetxt(\"./intermediate_data/pad_ft.csv\", pad_ft.cpu().numpy(), delimiter=',')\n",
    "        reshaped_ft = pad_ft.reshape(1, 1, 28, 28)\n",
    "        # update return data\n",
    "        ret_ft[out_idx] = reshaped_ft\n",
    "        ret_size[out_idx] = torch.tensor([width, height]).to(\"cuda\")\n",
    "        \n",
    "    # return size is [n, 1, 1, 28, 28], reduced from [n, m, 1, 1, 28, 28]\n",
    "    return {'h': ret_ft, 'g': ret_size}\n",
    "\n",
    "def my_message(edges):\n",
    "    return {'m': edges.src['ft'], 'n': edges.src['ft_size']}\n",
    "\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    subg.update_all(my_message, my_reduce)\n",
    "    subg.ndata['ft'] += subg.ndata['h']\n",
    "    subg.ndata['ft_size'] += subg.ndata['g']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([88, 1, 1, 28, 28])\n",
      "torch.Size([88, 2])\n"
     ]
    }
   ],
   "source": [
    "print(subg.ndata['ft'].size())\n",
    "print(subg.ndata['ft_size'].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ft: \n",
      "zeros -  [3, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87]\n",
      "nonzeros -  [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31]\n",
      "h: \n",
      "zeros -  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 46, 47, 49, 57, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87]\n",
      "nonzeros -  [32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 48, 50, 51, 52, 53, 54, 55, 56, 58, 59, 60, 61, 62, 63]\n",
      "ft_size: \n",
      "zeros -  [32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87]\n",
      "nonzeros -  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31]\n",
      "g: \n",
      "zeros -  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87]\n",
      "nonzeros -  [32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63]\n"
     ]
    }
   ],
   "source": [
    "def print_zeros_in_feat(key):\n",
    "    print(key + \": \")\n",
    "    zeros = []\n",
    "    nonzero = []\n",
    "    for id in subg.nodes():\n",
    "        id = int(id)\n",
    "        feat = subg.nodes[id].data[key]\n",
    "        if torch.eq(feat, torch.zeros(feat.size()).to(\"cuda\")).all() == True:\n",
    "            zeros.append(id)\n",
    "        else:\n",
    "            nonzero.append(id)\n",
    "    print(\"zeros - \", zeros)\n",
    "    print(\"nonzeros - \", nonzero)\n",
    "\n",
    "print_zeros_in_feat('ft')\n",
    "print_zeros_in_feat('h')\n",
    "print_zeros_in_feat('ft_size')\n",
    "print_zeros_in_feat('g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt = 0\n",
    "ft_list = []\n",
    "for f,s in zip(subg.ndata['ft'], subg.ndata['ft_size']):\n",
    "    w, h = s\n",
    "    w, h = int(w), int(h)\n",
    "    data = unpadding(f.reshape(28, 28), w, h)\n",
    "    ft_list.append(data)\n",
    "    np.savetxt(\"./intermediate_data/graph_results/node-%d.csv\" % cnt, data.cpu(), delimiter=',')\n",
    "    cnt += 1\n",
    "\n",
    "cnt = 0\n",
    "cnn_params = None \n",
    "with open(\"./intermediate_data/params.json\", \"r\") as f:\n",
    "    cnn_params = json.load(f)\n",
    "from torch.nn.functional import relu\n",
    "from utils_gnn import unpadding\n",
    "conv1 = torch.tensor(cnn_params['conv1'])\n",
    "conv2 = torch.tensor(cnn_params['conv2'])\n",
    "conv3 = torch.tensor(cnn_params['conv3'])\n",
    "conv4 = torch.tensor(cnn_params['conv4'])\n",
    "l = [conv1, conv2, conv3, conv4]\n",
    "neural_list = []\n",
    "for layer in l:\n",
    "    for neural in layer[0]:\n",
    "        neural_list.append(neural)\n",
    "        np.savetxt(\"./intermediate_data/model_results/node-%d.csv\" % cnt, neural.cpu(), delimiter=',')\n",
    "        cnt += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 32, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "print(conv1.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : 0\n",
      "1 : 0\n",
      "3 : 0\n",
      "4 : 0\n",
      "6 : 0\n",
      "7 : 0\n",
      "9 : 0\n",
      "10 : 0\n",
      "12 : 0\n",
      "13 : 0\n",
      "14 : 0\n",
      "16 : 0\n",
      "17 : 0\n",
      "18 : 0\n",
      "21 : 0\n",
      "22 : 0\n",
      "23 : 0\n",
      "24 : 0\n",
      "25 : 0\n",
      "26 : 0\n",
      "27 : 0\n",
      "28 : 0\n",
      "29 : 0\n",
      "31 : 0\n"
     ]
    }
   ],
   "source": [
    "cnt = 0\n",
    "f_cnt = -1\n",
    "for f in ft_list[:32]:\n",
    "    f_cnt += 1\n",
    "    if f.all() == 0:\n",
    "        print(f_cnt, ':', 0)\n",
    "        continue\n",
    "    d_cnt = -1\n",
    "    for d in conv1[0]:\n",
    "        d_cnt += 1\n",
    "        try:\n",
    "            print(torch.eq(h, d.to(\"cuda\")).all())\n",
    "            condition = torch.eq(h, d.to(\"cuda\")).all() == True \n",
    "            if condition:\n",
    "                print(\"equeals\", f_cnt, d_cnt)\n",
    "                cnt += 1\n",
    "        except:\n",
    "            continue\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.13 ('mntd')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2d7768e61f5674adf4efa61c7b8cc3ee2c06ae8f502b5df709cd3e31381a4347"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
