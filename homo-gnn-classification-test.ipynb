{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e9ac4d52",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 简单图网络后门检测任务 PoC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a7ca79d",
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.10.1+cu102'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "71978209",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512\n",
      "shadow_benign_2137.model\n",
      "shadow_jumbo_2130.model\n",
      "shadow_jumbo_2095.model\n",
      "shadow_jumbo_2089.model\n",
      "shadow_benign_2280.model\n",
      "shadow_jumbo_2247.model\n",
      "shadow_jumbo_2049.model\n",
      "shadow_jumbo_2160.model\n",
      "shadow_benign_2193.model\n",
      "shadow_benign_2122.model\n",
      "shadow_benign_2195.model\n",
      "shadow_benign_2177.model\n",
      "shadow_jumbo_2100.model\n",
      "shadow_benign_2083.model\n",
      "shadow_benign_2284.model\n",
      "shadow_jumbo_2299.model\n",
      "shadow_benign_2097.model\n",
      "shadow_jumbo_2122.model\n",
      "shadow_benign_2053.model\n",
      "shadow_jumbo_2291.model\n",
      "shadow_jumbo_2096.model\n",
      "shadow_jumbo_2154.model\n",
      "shadow_benign_2236.model\n",
      "shadow_benign_2249.model\n",
      "shadow_jumbo_2216.model\n",
      "shadow_benign_2135.model\n",
      "shadow_jumbo_2153.model\n",
      "shadow_benign_2197.model\n",
      "shadow_jumbo_2190.model\n",
      "shadow_jumbo_2259.model\n",
      "shadow_jumbo_2094.model\n",
      "shadow_jumbo_2214.model\n",
      "shadow_benign_2205.model\n",
      "shadow_benign_2082.model\n",
      "shadow_jumbo_2273.model\n",
      "shadow_benign_2272.model\n",
      "shadow_jumbo_2278.model\n",
      "shadow_jumbo_2254.model\n",
      "shadow_benign_2161.model\n",
      "shadow_jumbo_2056.model\n",
      "shadow_benign_2256.model\n",
      "shadow_benign_2112.model\n",
      "shadow_jumbo_2099.model\n",
      "shadow_benign_2131.model\n",
      "shadow_jumbo_2302.model\n",
      "shadow_benign_2254.model\n",
      "shadow_jumbo_2117.model\n",
      "shadow_benign_2275.model\n",
      "shadow_jumbo_2287.model\n",
      "shadow_benign_2208.model\n",
      "shadow_jumbo_2070.model\n",
      "shadow_benign_2299.model\n",
      "shadow_benign_2062.model\n",
      "shadow_benign_2115.model\n",
      "shadow_jumbo_2085.model\n",
      "shadow_benign_2098.model\n",
      "shadow_jumbo_2280.model\n",
      "shadow_benign_2145.model\n",
      "shadow_benign_2199.model\n",
      "shadow_benign_2273.model\n",
      "shadow_jumbo_2265.model\n",
      "shadow_benign_2240.model\n",
      "shadow_jumbo_2197.model\n",
      "shadow_jumbo_2218.model\n",
      "shadow_benign_2159.model\n",
      "shadow_benign_2201.model\n",
      "shadow_jumbo_2303.model\n",
      "shadow_benign_2244.model\n",
      "shadow_benign_2262.model\n",
      "shadow_benign_2203.model\n",
      "shadow_benign_2167.model\n",
      "shadow_benign_2095.model\n",
      "shadow_jumbo_2173.model\n",
      "shadow_jumbo_2147.model\n",
      "shadow_jumbo_2084.model\n",
      "shadow_benign_2188.model\n",
      "shadow_benign_2291.model\n",
      "shadow_benign_2171.model\n",
      "shadow_benign_2129.model\n",
      "shadow_benign_2058.model\n",
      "shadow_jumbo_2221.model\n",
      "shadow_jumbo_2232.model\n",
      "shadow_benign_2246.model\n",
      "shadow_benign_2132.model\n",
      "shadow_benign_2180.model\n",
      "shadow_benign_2266.model\n",
      "shadow_jumbo_2168.model\n",
      "shadow_benign_2166.model\n",
      "shadow_jumbo_2105.model\n",
      "shadow_jumbo_2225.model\n",
      "shadow_jumbo_2293.model\n",
      "shadow_jumbo_2268.model\n",
      "shadow_jumbo_2178.model\n",
      "shadow_benign_2089.model\n",
      "shadow_jumbo_2068.model\n",
      "shadow_jumbo_2052.model\n",
      "shadow_jumbo_2062.model\n",
      "shadow_benign_2247.model\n",
      "shadow_jumbo_2156.model\n",
      "shadow_jumbo_2131.model\n",
      "shadow_jumbo_2224.model\n",
      "shadow_jumbo_2258.model\n",
      "shadow_jumbo_2076.model\n",
      "shadow_jumbo_2144.model\n",
      "shadow_jumbo_2187.model\n",
      "shadow_jumbo_2162.model\n",
      "shadow_jumbo_2212.model\n",
      "shadow_jumbo_2053.model\n",
      "shadow_benign_2225.model\n",
      "shadow_jumbo_2157.model\n",
      "shadow_jumbo_2288.model\n",
      "shadow_benign_2214.model\n",
      "shadow_benign_2110.model\n",
      "shadow_benign_2079.model\n",
      "shadow_benign_2139.model\n",
      "shadow_jumbo_2065.model\n",
      "shadow_jumbo_2083.model\n",
      "shadow_benign_2103.model\n",
      "shadow_jumbo_2158.model\n",
      "shadow_jumbo_2199.model\n",
      "shadow_benign_2127.model\n",
      "shadow_benign_2196.model\n",
      "shadow_benign_2138.model\n",
      "shadow_benign_2265.model\n",
      "shadow_benign_2168.model\n",
      "shadow_jumbo_2201.model\n",
      "shadow_benign_2050.model\n",
      "shadow_benign_2125.model\n",
      "shadow_jumbo_2274.model\n",
      "shadow_jumbo_2271.model\n",
      "shadow_jumbo_2058.model\n",
      "shadow_jumbo_2253.model\n",
      "shadow_jumbo_2213.model\n",
      "shadow_benign_2303.model\n",
      "shadow_jumbo_2194.model\n",
      "shadow_benign_2253.model\n",
      "shadow_jumbo_2054.model\n",
      "shadow_jumbo_2077.model\n",
      "shadow_benign_2142.model\n",
      "shadow_benign_2150.model\n",
      "shadow_benign_2100.model\n",
      "shadow_benign_2218.model\n",
      "shadow_jumbo_2226.model\n",
      "shadow_jumbo_2079.model\n",
      "shadow_benign_2102.model\n",
      "shadow_jumbo_2149.model\n",
      "shadow_jumbo_2281.model\n",
      "shadow_jumbo_2133.model\n",
      "shadow_benign_2066.model\n",
      "shadow_jumbo_2189.model\n",
      "shadow_jumbo_2063.model\n",
      "shadow_benign_2061.model\n",
      "shadow_jumbo_2295.model\n",
      "shadow_benign_2234.model\n",
      "shadow_benign_2183.model\n",
      "shadow_benign_2087.model\n",
      "shadow_jumbo_2234.model\n",
      "shadow_benign_2237.model\n",
      "shadow_benign_2295.model\n",
      "shadow_jumbo_2088.model\n",
      "shadow_benign_2113.model\n",
      "shadow_jumbo_2272.model\n",
      "shadow_benign_2192.model\n",
      "shadow_jumbo_2193.model\n",
      "shadow_benign_2252.model\n",
      "shadow_benign_2301.model\n",
      "shadow_benign_2277.model\n",
      "shadow_jumbo_2260.model\n",
      "shadow_jumbo_2104.model\n",
      "shadow_jumbo_2067.model\n",
      "shadow_benign_2117.model\n",
      "shadow_jumbo_2170.model\n",
      "shadow_jumbo_2082.model\n",
      "shadow_jumbo_2090.model\n",
      "shadow_benign_2118.model\n",
      "shadow_jumbo_2202.model\n",
      "shadow_jumbo_2066.model\n",
      "shadow_jumbo_2250.model\n",
      "shadow_benign_2242.model\n",
      "shadow_benign_2081.model\n",
      "shadow_jumbo_2300.model\n",
      "shadow_benign_2175.model\n",
      "shadow_jumbo_2148.model\n",
      "shadow_benign_2092.model\n",
      "shadow_jumbo_2204.model\n",
      "shadow_benign_2156.model\n",
      "shadow_benign_2239.model\n",
      "shadow_jumbo_2142.model\n",
      "shadow_jumbo_2235.model\n",
      "shadow_benign_2227.model\n",
      "shadow_jumbo_2208.model\n",
      "shadow_jumbo_2171.model\n",
      "shadow_jumbo_2127.model\n",
      "shadow_benign_2257.model\n",
      "shadow_jumbo_2109.model\n",
      "shadow_benign_2090.model\n",
      "shadow_benign_2104.model\n",
      "shadow_benign_2296.model\n",
      "shadow_jumbo_2219.model\n",
      "shadow_jumbo_2290.model\n",
      "shadow_benign_2259.model\n",
      "shadow_benign_2290.model\n",
      "shadow_jumbo_2270.model\n",
      "shadow_jumbo_2177.model\n",
      "shadow_benign_2128.model\n",
      "shadow_jumbo_2263.model\n",
      "shadow_jumbo_2080.model\n",
      "shadow_benign_2181.model\n",
      "shadow_benign_2270.model\n",
      "shadow_benign_2054.model\n",
      "shadow_jumbo_2283.model\n",
      "shadow_benign_2073.model\n",
      "shadow_jumbo_2256.model\n",
      "shadow_jumbo_2151.model\n",
      "shadow_jumbo_2111.model\n",
      "shadow_jumbo_2186.model\n",
      "shadow_jumbo_2097.model\n",
      "shadow_benign_2206.model\n",
      "shadow_jumbo_2069.model\n",
      "shadow_jumbo_2092.model\n",
      "shadow_jumbo_2296.model\n",
      "shadow_benign_2300.model\n",
      "shadow_benign_2224.model\n",
      "shadow_jumbo_2223.model\n",
      "shadow_jumbo_2191.model\n",
      "shadow_jumbo_2143.model\n",
      "shadow_jumbo_2228.model\n",
      "shadow_jumbo_2233.model\n",
      "shadow_benign_2133.model\n",
      "shadow_benign_2143.model\n",
      "shadow_benign_2147.model\n",
      "shadow_jumbo_2262.model\n",
      "shadow_jumbo_2107.model\n",
      "shadow_benign_2178.model\n",
      "shadow_benign_2281.model\n",
      "shadow_jumbo_2139.model\n",
      "shadow_jumbo_2064.model\n",
      "shadow_benign_2228.model\n",
      "shadow_jumbo_2172.model\n",
      "shadow_benign_2250.model\n",
      "shadow_jumbo_2264.model\n",
      "shadow_benign_2094.model\n",
      "shadow_jumbo_2140.model\n",
      "shadow_benign_2101.model\n",
      "shadow_jumbo_2124.model\n",
      "shadow_jumbo_2276.model\n",
      "shadow_benign_2060.model\n",
      "shadow_benign_2106.model\n",
      "shadow_jumbo_2301.model\n",
      "shadow_benign_2140.model\n",
      "shadow_jumbo_2182.model\n",
      "shadow_jumbo_2051.model\n",
      "shadow_jumbo_2141.model\n",
      "shadow_jumbo_2050.model\n",
      "shadow_benign_2108.model\n",
      "shadow_benign_2264.model\n",
      "shadow_jumbo_2210.model\n",
      "shadow_benign_2221.model\n",
      "shadow_jumbo_2165.model\n",
      "shadow_jumbo_2279.model\n",
      "shadow_jumbo_2297.model\n",
      "shadow_benign_2278.model\n",
      "shadow_jumbo_2246.model\n",
      "shadow_jumbo_2115.model\n",
      "shadow_jumbo_2114.model\n",
      "shadow_jumbo_2174.model\n",
      "shadow_benign_2179.model\n",
      "shadow_jumbo_2057.model\n",
      "shadow_jumbo_2236.model\n",
      "shadow_jumbo_2195.model\n",
      "shadow_jumbo_2093.model\n",
      "shadow_benign_2297.model\n",
      "shadow_benign_2216.model\n",
      "shadow_benign_2288.model\n",
      "shadow_jumbo_2237.model\n",
      "shadow_jumbo_2098.model\n",
      "shadow_jumbo_2269.model\n",
      "shadow_jumbo_2261.model\n",
      "shadow_benign_2076.model\n",
      "shadow_jumbo_2060.model\n",
      "shadow_benign_2078.model\n",
      "shadow_jumbo_2169.model\n",
      "shadow_benign_2151.model\n",
      "shadow_benign_2274.model\n",
      "shadow_benign_2209.model\n",
      "shadow_jumbo_2112.model\n",
      "shadow_benign_2144.model\n",
      "shadow_jumbo_2211.model\n",
      "shadow_jumbo_2249.model\n",
      "shadow_benign_2116.model\n",
      "shadow_jumbo_2161.model\n",
      "shadow_jumbo_2200.model\n",
      "shadow_benign_2121.model\n",
      "shadow_benign_2084.model\n",
      "shadow_jumbo_2138.model\n",
      "shadow_benign_2070.model\n",
      "shadow_jumbo_2164.model\n",
      "shadow_jumbo_2118.model\n",
      "shadow_benign_2172.model\n",
      "shadow_benign_2294.model\n",
      "shadow_jumbo_2222.model\n",
      "shadow_benign_2124.model\n",
      "shadow_jumbo_2181.model\n",
      "shadow_benign_2268.model\n",
      "shadow_benign_2293.model\n",
      "shadow_jumbo_2230.model\n",
      "shadow_jumbo_2106.model\n",
      "shadow_jumbo_2294.model\n",
      "shadow_benign_2232.model\n",
      "shadow_jumbo_2159.model\n",
      "shadow_benign_2241.model\n",
      "shadow_benign_2068.model\n",
      "shadow_jumbo_2087.model\n",
      "shadow_jumbo_2267.model\n",
      "shadow_benign_2126.model\n",
      "shadow_jumbo_2229.model\n",
      "shadow_jumbo_2207.model\n",
      "shadow_benign_2162.model\n",
      "shadow_benign_2263.model\n",
      "shadow_jumbo_2061.model\n",
      "shadow_benign_2233.model\n",
      "shadow_benign_2186.model\n",
      "shadow_benign_2251.model\n",
      "shadow_benign_2152.model\n",
      "shadow_jumbo_2284.model\n",
      "shadow_benign_2048.model\n",
      "shadow_jumbo_2055.model\n",
      "shadow_benign_2261.model\n",
      "shadow_jumbo_2176.model\n",
      "shadow_jumbo_2121.model\n",
      "shadow_benign_2064.model\n",
      "shadow_jumbo_2248.model\n",
      "shadow_benign_2215.model\n",
      "shadow_jumbo_2129.model\n",
      "shadow_jumbo_2185.model\n",
      "shadow_jumbo_2103.model\n",
      "shadow_benign_2154.model\n",
      "shadow_benign_2091.model\n",
      "shadow_jumbo_2123.model\n",
      "shadow_benign_2220.model\n",
      "shadow_benign_2202.model\n",
      "shadow_benign_2194.model\n",
      "shadow_jumbo_2217.model\n",
      "shadow_jumbo_2285.model\n",
      "shadow_benign_2185.model\n",
      "shadow_benign_2111.model\n",
      "shadow_jumbo_2073.model\n",
      "shadow_benign_2080.model\n",
      "shadow_benign_2096.model\n",
      "shadow_jumbo_2241.model\n",
      "shadow_benign_2072.model\n",
      "shadow_benign_2184.model\n",
      "shadow_benign_2276.model\n",
      "shadow_benign_2085.model\n",
      "shadow_jumbo_2075.model\n",
      "shadow_benign_2067.model\n",
      "shadow_benign_2155.model\n",
      "shadow_benign_2164.model\n",
      "shadow_jumbo_2078.model\n",
      "shadow_jumbo_2108.model\n",
      "shadow_jumbo_2137.model\n",
      "shadow_benign_2243.model\n",
      "shadow_benign_2204.model\n",
      "shadow_jumbo_2289.model\n",
      "shadow_jumbo_2113.model\n",
      "shadow_jumbo_2292.model\n",
      "shadow_benign_2267.model\n",
      "shadow_benign_2292.model\n",
      "shadow_benign_2176.model\n",
      "shadow_benign_2077.model\n",
      "shadow_jumbo_2242.model\n",
      "shadow_jumbo_2086.model\n",
      "shadow_benign_2260.model\n",
      "shadow_jumbo_2188.model\n",
      "shadow_jumbo_2134.model\n",
      "shadow_benign_2134.model\n",
      "shadow_jumbo_2180.model\n",
      "shadow_jumbo_2277.model\n",
      "shadow_jumbo_2059.model\n",
      "shadow_benign_2200.model\n",
      "shadow_benign_2130.model\n",
      "shadow_jumbo_2192.model\n",
      "shadow_benign_2298.model\n",
      "shadow_benign_2141.model\n",
      "shadow_jumbo_2206.model\n",
      "shadow_jumbo_2071.model\n",
      "shadow_benign_2286.model\n",
      "shadow_benign_2056.model\n",
      "shadow_benign_2055.model\n",
      "shadow_jumbo_2257.model\n",
      "shadow_benign_2153.model\n",
      "shadow_benign_2174.model\n",
      "shadow_benign_2283.model\n",
      "shadow_jumbo_2128.model\n",
      "shadow_jumbo_2240.model\n",
      "shadow_benign_2093.model\n",
      "shadow_jumbo_2125.model\n",
      "shadow_jumbo_2198.model\n",
      "shadow_benign_2065.model\n",
      "shadow_benign_2287.model\n",
      "shadow_jumbo_2286.model\n",
      "shadow_benign_2136.model\n",
      "shadow_benign_2212.model\n",
      "shadow_benign_2207.model\n",
      "shadow_benign_2173.model\n",
      "shadow_jumbo_2091.model\n",
      "shadow_jumbo_2135.model\n",
      "shadow_benign_2235.model\n",
      "shadow_benign_2189.model\n",
      "shadow_benign_2069.model\n",
      "shadow_benign_2123.model\n",
      "shadow_jumbo_2146.model\n",
      "shadow_jumbo_2203.model\n",
      "shadow_benign_2099.model\n",
      "shadow_benign_2120.model\n",
      "shadow_benign_2198.model\n",
      "shadow_benign_2255.model\n",
      "shadow_jumbo_2227.model\n",
      "shadow_jumbo_2120.model\n",
      "shadow_jumbo_2150.model\n",
      "shadow_jumbo_2102.model\n",
      "shadow_benign_2049.model\n",
      "shadow_benign_2052.model\n",
      "shadow_jumbo_2244.model\n",
      "shadow_jumbo_2298.model\n",
      "shadow_benign_2149.model\n",
      "shadow_benign_2222.model\n",
      "shadow_jumbo_2282.model\n",
      "shadow_jumbo_2175.model\n",
      "shadow_jumbo_2074.model\n",
      "shadow_benign_2213.model\n",
      "shadow_jumbo_2184.model\n",
      "shadow_jumbo_2132.model\n",
      "shadow_benign_2160.model\n",
      "shadow_jumbo_2072.model\n",
      "shadow_benign_2226.model\n",
      "shadow_benign_2230.model\n",
      "shadow_jumbo_2110.model\n",
      "shadow_jumbo_2145.model\n",
      "shadow_jumbo_2136.model\n",
      "shadow_benign_2231.model\n",
      "shadow_jumbo_2251.model\n",
      "shadow_benign_2170.model\n",
      "shadow_jumbo_2255.model\n",
      "shadow_benign_2238.model\n",
      "shadow_benign_2051.model\n",
      "shadow_benign_2057.model\n",
      "shadow_benign_2075.model\n",
      "shadow_benign_2271.model\n",
      "shadow_benign_2165.model\n",
      "shadow_jumbo_2275.model\n",
      "shadow_benign_2211.model\n",
      "shadow_benign_2148.model\n",
      "shadow_benign_2059.model\n",
      "shadow_benign_2245.model\n",
      "shadow_benign_2285.model\n",
      "shadow_benign_2219.model\n",
      "shadow_jumbo_2238.model\n",
      "shadow_benign_2229.model\n",
      "shadow_benign_2190.model\n",
      "shadow_benign_2182.model\n",
      "shadow_benign_2279.model\n",
      "shadow_jumbo_2163.model\n",
      "shadow_jumbo_2220.model\n",
      "shadow_benign_2258.model\n",
      "shadow_benign_2074.model\n",
      "shadow_jumbo_2116.model\n",
      "shadow_jumbo_2081.model\n",
      "shadow_benign_2282.model\n",
      "shadow_benign_2169.model\n",
      "shadow_jumbo_2183.model\n",
      "shadow_benign_2248.model\n",
      "shadow_benign_2063.model\n",
      "shadow_jumbo_2231.model\n",
      "shadow_jumbo_2239.model\n",
      "shadow_benign_2157.model\n",
      "shadow_benign_2119.model\n",
      "shadow_jumbo_2152.model\n",
      "shadow_benign_2088.model\n",
      "shadow_benign_2217.model\n",
      "shadow_jumbo_2245.model\n",
      "shadow_jumbo_2126.model\n",
      "shadow_jumbo_2048.model\n",
      "shadow_benign_2187.model\n",
      "shadow_jumbo_2166.model\n",
      "shadow_jumbo_2205.model\n",
      "shadow_jumbo_2252.model\n",
      "shadow_benign_2105.model\n",
      "shadow_jumbo_2155.model\n",
      "shadow_jumbo_2266.model\n",
      "shadow_benign_2210.model\n",
      "shadow_benign_2146.model\n",
      "shadow_benign_2109.model\n",
      "shadow_benign_2114.model\n",
      "shadow_benign_2289.model\n",
      "shadow_benign_2191.model\n",
      "shadow_jumbo_2167.model\n",
      "shadow_jumbo_2179.model\n",
      "shadow_benign_2163.model\n",
      "shadow_jumbo_2101.model\n",
      "shadow_benign_2269.model\n",
      "shadow_benign_2302.model\n",
      "shadow_jumbo_2215.model\n",
      "shadow_benign_2086.model\n",
      "shadow_jumbo_2243.model\n",
      "shadow_benign_2071.model\n",
      "shadow_jumbo_2119.model\n",
      "shadow_benign_2223.model\n",
      "shadow_benign_2158.model\n",
      "shadow_jumbo_2209.model\n",
      "shadow_benign_2107.model\n",
      "shadow_jumbo_2196.model\n",
      "shadow_benign_2137.model\n",
      "shadow_jumbo_2130.model\n",
      "shadow_jumbo_2095.model\n",
      "shadow_jumbo_2089.model\n",
      "shadow_benign_2280.model\n",
      "shadow_jumbo_2247.model\n",
      "shadow_jumbo_2049.model\n",
      "shadow_jumbo_2160.model\n",
      "shadow_benign_2193.model\n",
      "shadow_benign_2122.model\n",
      "shadow_benign_2195.model\n",
      "shadow_benign_2177.model\n",
      "shadow_jumbo_2100.model\n",
      "shadow_benign_2083.model\n",
      "shadow_benign_2284.model\n",
      "shadow_jumbo_2299.model\n",
      "shadow_benign_2097.model\n",
      "shadow_jumbo_2122.model\n",
      "shadow_benign_2053.model\n",
      "shadow_jumbo_2291.model\n",
      "shadow_jumbo_2096.model\n",
      "shadow_jumbo_2154.model\n",
      "shadow_benign_2236.model\n",
      "shadow_benign_2249.model\n",
      "shadow_jumbo_2216.model\n",
      "shadow_benign_2135.model\n",
      "shadow_jumbo_2153.model\n",
      "shadow_benign_2197.model\n",
      "shadow_jumbo_2190.model\n",
      "shadow_jumbo_2259.model\n",
      "shadow_jumbo_2094.model\n",
      "shadow_jumbo_2214.model\n",
      "shadow_benign_2205.model\n",
      "shadow_benign_2082.model\n",
      "shadow_jumbo_2273.model\n",
      "shadow_benign_2272.model\n",
      "shadow_jumbo_2278.model\n",
      "shadow_jumbo_2254.model\n",
      "shadow_benign_2161.model\n",
      "shadow_jumbo_2056.model\n",
      "shadow_benign_2256.model\n",
      "shadow_benign_2112.model\n",
      "shadow_jumbo_2099.model\n",
      "shadow_benign_2131.model\n",
      "shadow_jumbo_2302.model\n",
      "shadow_benign_2254.model\n",
      "shadow_jumbo_2117.model\n",
      "shadow_benign_2275.model\n",
      "shadow_jumbo_2287.model\n",
      "shadow_benign_2208.model\n",
      "shadow_jumbo_2070.model\n",
      "shadow_benign_2299.model\n",
      "shadow_benign_2062.model\n",
      "shadow_benign_2115.model\n",
      "shadow_jumbo_2085.model\n",
      "shadow_benign_2098.model\n",
      "shadow_jumbo_2280.model\n",
      "shadow_benign_2145.model\n",
      "shadow_benign_2199.model\n",
      "shadow_benign_2273.model\n",
      "shadow_jumbo_2265.model\n",
      "shadow_benign_2240.model\n",
      "shadow_jumbo_2197.model\n",
      "shadow_jumbo_2218.model\n",
      "shadow_benign_2159.model\n",
      "shadow_benign_2201.model\n",
      "shadow_jumbo_2303.model\n",
      "shadow_benign_2244.model\n",
      "shadow_benign_2262.model\n",
      "shadow_benign_2203.model\n",
      "shadow_benign_2167.model\n",
      "shadow_benign_2095.model\n",
      "shadow_jumbo_2173.model\n",
      "shadow_jumbo_2147.model\n",
      "shadow_jumbo_2084.model\n",
      "shadow_benign_2188.model\n",
      "shadow_benign_2291.model\n",
      "shadow_benign_2171.model\n",
      "shadow_benign_2129.model\n",
      "shadow_benign_2058.model\n",
      "shadow_jumbo_2221.model\n",
      "shadow_jumbo_2232.model\n",
      "shadow_benign_2246.model\n",
      "shadow_benign_2132.model\n",
      "shadow_benign_2180.model\n",
      "shadow_benign_2266.model\n",
      "shadow_jumbo_2168.model\n",
      "shadow_benign_2166.model\n",
      "shadow_jumbo_2105.model\n",
      "shadow_jumbo_2225.model\n",
      "shadow_jumbo_2293.model\n",
      "shadow_jumbo_2268.model\n",
      "shadow_jumbo_2178.model\n",
      "shadow_benign_2089.model\n",
      "shadow_jumbo_2068.model\n",
      "shadow_jumbo_2052.model\n",
      "shadow_jumbo_2062.model\n",
      "shadow_benign_2247.model\n",
      "shadow_jumbo_2156.model\n",
      "shadow_jumbo_2131.model\n",
      "shadow_jumbo_2224.model\n",
      "shadow_jumbo_2258.model\n",
      "shadow_jumbo_2076.model\n",
      "shadow_jumbo_2144.model\n",
      "shadow_jumbo_2187.model\n",
      "shadow_jumbo_2162.model\n",
      "shadow_jumbo_2212.model\n",
      "shadow_jumbo_2053.model\n",
      "shadow_benign_2225.model\n",
      "shadow_jumbo_2157.model\n",
      "shadow_jumbo_2288.model\n",
      "shadow_benign_2214.model\n",
      "shadow_benign_2110.model\n",
      "shadow_benign_2079.model\n",
      "shadow_benign_2139.model\n",
      "shadow_jumbo_2065.model\n",
      "shadow_jumbo_2083.model\n",
      "shadow_benign_2103.model\n",
      "shadow_jumbo_2158.model\n",
      "shadow_jumbo_2199.model\n",
      "shadow_benign_2127.model\n",
      "shadow_benign_2196.model\n",
      "shadow_benign_2138.model\n",
      "shadow_benign_2265.model\n",
      "shadow_benign_2168.model\n",
      "shadow_jumbo_2201.model\n",
      "shadow_benign_2050.model\n",
      "shadow_benign_2125.model\n",
      "shadow_jumbo_2274.model\n",
      "shadow_jumbo_2271.model\n",
      "shadow_jumbo_2058.model\n",
      "shadow_jumbo_2253.model\n",
      "shadow_jumbo_2213.model\n",
      "shadow_benign_2303.model\n",
      "shadow_jumbo_2194.model\n",
      "shadow_benign_2253.model\n",
      "shadow_jumbo_2054.model\n",
      "shadow_jumbo_2077.model\n",
      "shadow_benign_2142.model\n",
      "shadow_benign_2150.model\n",
      "shadow_benign_2100.model\n",
      "shadow_benign_2218.model\n",
      "shadow_jumbo_2226.model\n",
      "shadow_jumbo_2079.model\n",
      "shadow_benign_2102.model\n",
      "shadow_jumbo_2149.model\n",
      "shadow_jumbo_2281.model\n",
      "shadow_jumbo_2133.model\n",
      "shadow_benign_2066.model\n",
      "shadow_jumbo_2189.model\n",
      "shadow_jumbo_2063.model\n",
      "shadow_benign_2061.model\n",
      "shadow_jumbo_2295.model\n",
      "shadow_benign_2234.model\n",
      "shadow_benign_2183.model\n",
      "shadow_benign_2087.model\n",
      "shadow_jumbo_2234.model\n",
      "shadow_benign_2237.model\n",
      "shadow_benign_2295.model\n",
      "shadow_jumbo_2088.model\n",
      "shadow_benign_2113.model\n",
      "shadow_jumbo_2272.model\n",
      "shadow_benign_2192.model\n",
      "shadow_jumbo_2193.model\n",
      "shadow_benign_2252.model\n",
      "shadow_benign_2301.model\n",
      "shadow_benign_2277.model\n",
      "shadow_jumbo_2260.model\n",
      "shadow_jumbo_2104.model\n",
      "shadow_jumbo_2067.model\n",
      "shadow_benign_2117.model\n",
      "shadow_jumbo_2170.model\n",
      "shadow_jumbo_2082.model\n",
      "shadow_jumbo_2090.model\n",
      "shadow_benign_2118.model\n",
      "shadow_jumbo_2202.model\n",
      "shadow_jumbo_2066.model\n",
      "shadow_jumbo_2250.model\n",
      "shadow_benign_2242.model\n",
      "shadow_benign_2081.model\n",
      "shadow_jumbo_2300.model\n",
      "shadow_benign_2175.model\n",
      "shadow_jumbo_2148.model\n",
      "shadow_benign_2092.model\n",
      "shadow_jumbo_2204.model\n",
      "shadow_benign_2156.model\n",
      "shadow_benign_2239.model\n",
      "shadow_jumbo_2142.model\n",
      "shadow_jumbo_2235.model\n",
      "shadow_benign_2227.model\n",
      "shadow_jumbo_2208.model\n",
      "shadow_jumbo_2171.model\n",
      "shadow_jumbo_2127.model\n",
      "shadow_benign_2257.model\n",
      "shadow_jumbo_2109.model\n",
      "shadow_benign_2090.model\n",
      "shadow_benign_2104.model\n",
      "shadow_benign_2296.model\n",
      "shadow_jumbo_2219.model\n",
      "shadow_jumbo_2290.model\n",
      "shadow_benign_2259.model\n",
      "shadow_benign_2290.model\n",
      "shadow_jumbo_2270.model\n",
      "shadow_jumbo_2177.model\n",
      "shadow_benign_2128.model\n",
      "shadow_jumbo_2263.model\n",
      "shadow_jumbo_2080.model\n",
      "shadow_benign_2181.model\n",
      "shadow_benign_2270.model\n",
      "shadow_benign_2054.model\n",
      "shadow_jumbo_2283.model\n",
      "shadow_benign_2073.model\n",
      "shadow_jumbo_2256.model\n",
      "shadow_jumbo_2151.model\n",
      "shadow_jumbo_2111.model\n",
      "shadow_jumbo_2186.model\n",
      "shadow_jumbo_2097.model\n",
      "shadow_benign_2206.model\n",
      "shadow_jumbo_2069.model\n",
      "shadow_jumbo_2092.model\n",
      "shadow_jumbo_2296.model\n",
      "shadow_benign_2300.model\n",
      "shadow_benign_2224.model\n",
      "shadow_jumbo_2223.model\n",
      "shadow_jumbo_2191.model\n",
      "shadow_jumbo_2143.model\n",
      "shadow_jumbo_2228.model\n",
      "shadow_jumbo_2233.model\n",
      "shadow_benign_2133.model\n",
      "shadow_benign_2143.model\n",
      "shadow_benign_2147.model\n",
      "shadow_jumbo_2262.model\n",
      "shadow_jumbo_2107.model\n",
      "shadow_benign_2178.model\n",
      "shadow_benign_2281.model\n",
      "shadow_jumbo_2139.model\n",
      "shadow_jumbo_2064.model\n",
      "shadow_benign_2228.model\n",
      "shadow_jumbo_2172.model\n",
      "shadow_benign_2250.model\n",
      "shadow_jumbo_2264.model\n",
      "shadow_benign_2094.model\n",
      "shadow_jumbo_2140.model\n",
      "shadow_benign_2101.model\n",
      "shadow_jumbo_2124.model\n",
      "shadow_jumbo_2276.model\n",
      "shadow_benign_2060.model\n",
      "shadow_benign_2106.model\n",
      "shadow_jumbo_2301.model\n",
      "shadow_benign_2140.model\n",
      "shadow_jumbo_2182.model\n",
      "shadow_jumbo_2051.model\n",
      "shadow_jumbo_2141.model\n",
      "shadow_jumbo_2050.model\n",
      "shadow_benign_2108.model\n",
      "shadow_benign_2264.model\n",
      "shadow_jumbo_2210.model\n",
      "shadow_benign_2221.model\n",
      "shadow_jumbo_2165.model\n",
      "shadow_jumbo_2279.model\n",
      "shadow_jumbo_2297.model\n",
      "shadow_benign_2278.model\n",
      "shadow_jumbo_2246.model\n",
      "shadow_jumbo_2115.model\n",
      "shadow_jumbo_2114.model\n",
      "shadow_jumbo_2174.model\n",
      "shadow_benign_2179.model\n",
      "shadow_jumbo_2057.model\n",
      "shadow_jumbo_2236.model\n",
      "shadow_jumbo_2195.model\n",
      "shadow_jumbo_2093.model\n",
      "shadow_benign_2297.model\n",
      "shadow_benign_2216.model\n",
      "shadow_benign_2288.model\n",
      "shadow_jumbo_2237.model\n",
      "shadow_jumbo_2098.model\n",
      "shadow_jumbo_2269.model\n",
      "shadow_jumbo_2261.model\n",
      "shadow_benign_2076.model\n",
      "shadow_jumbo_2060.model\n",
      "shadow_benign_2078.model\n",
      "shadow_jumbo_2169.model\n",
      "shadow_benign_2151.model\n",
      "shadow_benign_2274.model\n",
      "shadow_benign_2209.model\n",
      "shadow_jumbo_2112.model\n",
      "shadow_benign_2144.model\n",
      "shadow_jumbo_2211.model\n",
      "shadow_jumbo_2249.model\n",
      "shadow_benign_2116.model\n",
      "shadow_jumbo_2161.model\n",
      "shadow_jumbo_2200.model\n",
      "shadow_benign_2121.model\n",
      "shadow_benign_2084.model\n",
      "shadow_jumbo_2138.model\n",
      "shadow_benign_2070.model\n",
      "shadow_jumbo_2164.model\n",
      "shadow_jumbo_2118.model\n",
      "shadow_benign_2172.model\n",
      "shadow_benign_2294.model\n",
      "shadow_jumbo_2222.model\n",
      "shadow_benign_2124.model\n",
      "shadow_jumbo_2181.model\n",
      "shadow_benign_2268.model\n",
      "shadow_benign_2293.model\n",
      "shadow_jumbo_2230.model\n",
      "shadow_jumbo_2106.model\n",
      "shadow_jumbo_2294.model\n",
      "shadow_benign_2232.model\n",
      "shadow_jumbo_2159.model\n",
      "shadow_benign_2241.model\n",
      "shadow_benign_2068.model\n",
      "shadow_jumbo_2087.model\n",
      "shadow_jumbo_2267.model\n",
      "shadow_benign_2126.model\n",
      "shadow_jumbo_2229.model\n",
      "shadow_jumbo_2207.model\n",
      "shadow_benign_2162.model\n",
      "shadow_benign_2263.model\n",
      "shadow_jumbo_2061.model\n",
      "shadow_benign_2233.model\n",
      "shadow_benign_2186.model\n",
      "shadow_benign_2251.model\n",
      "shadow_benign_2152.model\n",
      "shadow_jumbo_2284.model\n",
      "shadow_benign_2048.model\n",
      "shadow_jumbo_2055.model\n",
      "shadow_benign_2261.model\n",
      "shadow_jumbo_2176.model\n",
      "shadow_jumbo_2121.model\n",
      "shadow_benign_2064.model\n",
      "shadow_jumbo_2248.model\n",
      "shadow_benign_2215.model\n",
      "shadow_jumbo_2129.model\n",
      "shadow_jumbo_2185.model\n",
      "shadow_jumbo_2103.model\n",
      "shadow_benign_2154.model\n",
      "shadow_benign_2091.model\n",
      "shadow_jumbo_2123.model\n",
      "shadow_benign_2220.model\n",
      "shadow_benign_2202.model\n",
      "shadow_benign_2194.model\n",
      "shadow_jumbo_2217.model\n",
      "shadow_jumbo_2285.model\n",
      "shadow_benign_2185.model\n",
      "shadow_benign_2111.model\n",
      "shadow_jumbo_2073.model\n",
      "shadow_benign_2080.model\n",
      "shadow_benign_2096.model\n",
      "shadow_jumbo_2241.model\n",
      "shadow_benign_2072.model\n",
      "shadow_benign_2184.model\n",
      "shadow_benign_2276.model\n",
      "shadow_benign_2085.model\n",
      "shadow_jumbo_2075.model\n",
      "shadow_benign_2067.model\n",
      "shadow_benign_2155.model\n",
      "shadow_benign_2164.model\n",
      "shadow_jumbo_2078.model\n",
      "shadow_jumbo_2108.model\n",
      "shadow_jumbo_2137.model\n",
      "shadow_benign_2243.model\n",
      "shadow_benign_2204.model\n",
      "shadow_jumbo_2289.model\n",
      "shadow_jumbo_2113.model\n",
      "shadow_jumbo_2292.model\n",
      "shadow_benign_2267.model\n",
      "shadow_benign_2292.model\n",
      "shadow_benign_2176.model\n",
      "shadow_benign_2077.model\n",
      "shadow_jumbo_2242.model\n",
      "shadow_jumbo_2086.model\n",
      "shadow_benign_2260.model\n",
      "shadow_jumbo_2188.model\n",
      "shadow_jumbo_2134.model\n",
      "shadow_benign_2134.model\n",
      "shadow_jumbo_2180.model\n",
      "shadow_jumbo_2277.model\n",
      "shadow_jumbo_2059.model\n",
      "shadow_benign_2200.model\n",
      "shadow_benign_2130.model\n",
      "shadow_jumbo_2192.model\n",
      "shadow_benign_2298.model\n",
      "shadow_benign_2141.model\n",
      "shadow_jumbo_2206.model\n",
      "shadow_jumbo_2071.model\n",
      "shadow_benign_2286.model\n",
      "shadow_benign_2056.model\n",
      "shadow_benign_2055.model\n",
      "shadow_jumbo_2257.model\n",
      "shadow_benign_2153.model\n",
      "shadow_benign_2174.model\n",
      "shadow_benign_2283.model\n",
      "shadow_jumbo_2128.model\n",
      "shadow_jumbo_2240.model\n",
      "shadow_benign_2093.model\n",
      "shadow_jumbo_2125.model\n",
      "shadow_jumbo_2198.model\n",
      "shadow_benign_2065.model\n",
      "shadow_benign_2287.model\n",
      "shadow_jumbo_2286.model\n",
      "shadow_benign_2136.model\n",
      "shadow_benign_2212.model\n",
      "shadow_benign_2207.model\n",
      "shadow_benign_2173.model\n",
      "shadow_jumbo_2091.model\n",
      "shadow_jumbo_2135.model\n",
      "shadow_benign_2235.model\n",
      "shadow_benign_2189.model\n",
      "shadow_benign_2069.model\n",
      "shadow_benign_2123.model\n",
      "shadow_jumbo_2146.model\n",
      "shadow_jumbo_2203.model\n",
      "shadow_benign_2099.model\n",
      "shadow_benign_2120.model\n",
      "shadow_benign_2198.model\n",
      "shadow_benign_2255.model\n",
      "shadow_jumbo_2227.model\n",
      "shadow_jumbo_2120.model\n",
      "shadow_jumbo_2150.model\n",
      "shadow_jumbo_2102.model\n",
      "shadow_benign_2049.model\n",
      "shadow_benign_2052.model\n",
      "shadow_jumbo_2244.model\n",
      "shadow_jumbo_2298.model\n",
      "shadow_benign_2149.model\n",
      "shadow_benign_2222.model\n",
      "shadow_jumbo_2282.model\n",
      "shadow_jumbo_2175.model\n",
      "shadow_jumbo_2074.model\n",
      "shadow_benign_2213.model\n",
      "shadow_jumbo_2184.model\n",
      "shadow_jumbo_2132.model\n",
      "shadow_benign_2160.model\n",
      "shadow_jumbo_2072.model\n",
      "shadow_benign_2226.model\n",
      "shadow_benign_2230.model\n",
      "shadow_jumbo_2110.model\n",
      "shadow_jumbo_2145.model\n",
      "shadow_jumbo_2136.model\n",
      "shadow_benign_2231.model\n",
      "shadow_jumbo_2251.model\n",
      "shadow_benign_2170.model\n",
      "shadow_jumbo_2255.model\n",
      "shadow_benign_2238.model\n",
      "shadow_benign_2051.model\n",
      "shadow_benign_2057.model\n",
      "shadow_benign_2075.model\n",
      "shadow_benign_2271.model\n",
      "shadow_benign_2165.model\n",
      "shadow_jumbo_2275.model\n",
      "shadow_benign_2211.model\n",
      "shadow_benign_2148.model\n",
      "shadow_benign_2059.model\n",
      "shadow_benign_2245.model\n",
      "shadow_benign_2285.model\n",
      "shadow_benign_2219.model\n",
      "shadow_jumbo_2238.model\n",
      "shadow_benign_2229.model\n",
      "shadow_benign_2190.model\n",
      "shadow_benign_2182.model\n",
      "shadow_benign_2279.model\n",
      "shadow_jumbo_2163.model\n",
      "shadow_jumbo_2220.model\n",
      "shadow_benign_2258.model\n",
      "shadow_benign_2074.model\n",
      "shadow_jumbo_2116.model\n",
      "shadow_jumbo_2081.model\n",
      "shadow_benign_2282.model\n",
      "shadow_benign_2169.model\n",
      "shadow_jumbo_2183.model\n",
      "shadow_benign_2248.model\n",
      "shadow_benign_2063.model\n",
      "shadow_jumbo_2231.model\n",
      "shadow_jumbo_2239.model\n",
      "shadow_benign_2157.model\n",
      "shadow_benign_2119.model\n",
      "shadow_jumbo_2152.model\n",
      "shadow_benign_2088.model\n",
      "shadow_benign_2217.model\n",
      "shadow_jumbo_2245.model\n",
      "shadow_jumbo_2126.model\n",
      "shadow_jumbo_2048.model\n",
      "shadow_benign_2187.model\n",
      "shadow_jumbo_2166.model\n",
      "shadow_jumbo_2205.model\n",
      "shadow_jumbo_2252.model\n",
      "shadow_benign_2105.model\n",
      "shadow_jumbo_2155.model\n",
      "shadow_jumbo_2266.model\n",
      "shadow_benign_2210.model\n",
      "shadow_benign_2146.model\n",
      "shadow_benign_2109.model\n",
      "shadow_benign_2114.model\n",
      "shadow_benign_2289.model\n",
      "shadow_benign_2191.model\n",
      "shadow_jumbo_2167.model\n",
      "shadow_jumbo_2179.model\n",
      "shadow_benign_2163.model\n",
      "shadow_jumbo_2101.model\n",
      "shadow_benign_2269.model\n",
      "shadow_benign_2302.model\n",
      "shadow_jumbo_2215.model\n",
      "shadow_benign_2086.model\n",
      "shadow_jumbo_2243.model\n",
      "shadow_benign_2071.model\n",
      "shadow_jumbo_2119.model\n",
      "shadow_benign_2223.model\n",
      "shadow_benign_2158.model\n",
      "shadow_jumbo_2209.model\n",
      "shadow_benign_2107.model\n",
      "shadow_jumbo_2196.model\n"
     ]
    }
   ],
   "source": [
    "from dgl.data.dgl_dataset import DGLBuiltinDataset\n",
    "from model_lib.mnist_cnn_model import Model0 as Model\n",
    "import os \n",
    "import re\n",
    "import torch\n",
    "from torch import nn\n",
    "import dgl\n",
    "\n",
    "class HomoStrucBackdoorDataset(DGLBuiltinDataset):\n",
    "    def __init__(self, mode='train', raw_dir='/home/ubuntu/date/hdd4/shadow_model_ckpt/mnist/models/',\n",
    "                 force_reload=False, verbose=False, transform=None):\n",
    "        mode = mode.lower()\n",
    "        assert mode in ['train', 'valid', 'test'], \"Mode not valid.\"\n",
    "        self.mode = mode    \n",
    "        self.x = []\n",
    "        self.y = []\n",
    "        _url = None\n",
    "        \n",
    "        super(HomoStrucBackdoorDataset, self).__init__(name='HomoBackdoorDT',\n",
    "                                           raw_dir=raw_dir,\n",
    "                                           force_reload=force_reload,\n",
    "                                           verbose=verbose,\n",
    "                                           url=_url,\n",
    "                                           transform=transform)\n",
    "        self.load()\n",
    "        \n",
    "        \n",
    "    def process(self):\n",
    "        pass\n",
    "    \n",
    "    def has_cache(self):\n",
    "        pass\n",
    "    \n",
    "    def load(self):\n",
    "        '''load dataset info'''\n",
    "        \n",
    "        for filename in os.listdir(self.raw_dir):\n",
    "            if '.model' not in filename:\n",
    "                # not a model\n",
    "                continue\n",
    "            idx_pattern = '[0-9]+'\n",
    "            idx = re.findall(idx_pattern, filename)\n",
    "            if self.mode == 'train':\n",
    "                if int(idx[0]) < 2048 and 'target' not in filename:\n",
    "                    # is a training model\n",
    "                    self.x.append(filename)\n",
    "                else:\n",
    "                    continue\n",
    "                # print(filename)\n",
    "            elif self.mode == 'valid':\n",
    "                if int(idx[0]) >= 2048 and 'target' not in filename:\n",
    "                    self.x.append(filename)\n",
    "                else:\n",
    "                    continue\n",
    "            else:\n",
    "                # self.mode == 'test'\n",
    "                if 'target' in filename:# and 'B' not in filename\n",
    "                    self.x.append(filename)\n",
    "                else:\n",
    "                    continue\n",
    "            # add co\n",
    "            if 'benign' in filename:\n",
    "                self.y.append(0)\n",
    "            else:\n",
    "                self.y.append(1)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        assert idx < len(self.x), \"Out of index when get item.\"\n",
    "        # load data, process and return\n",
    "        g, y = self.load_g(idx)\n",
    "        return g, y\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "    \n",
    "    def get_x_y(self):\n",
    "        return self.x, self.y\n",
    "    \n",
    "    def iter_y(self):\n",
    "        for y in self.y:\n",
    "            yield y\n",
    "            \n",
    "    def is_correct_labeled(self):\n",
    "        x = self.x\n",
    "        y = self.y\n",
    "        cnt = 0\n",
    "        error = 0\n",
    "        for i,j in zip(x,y):\n",
    "            if 'benign' in i and j == 0:\n",
    "                cnt += 1\n",
    "            elif 'benign' not in i and j == 1:\n",
    "                cnt += 1\n",
    "            else:\n",
    "                error += 1\n",
    "        if cnt != len(x) or error > 0:\n",
    "            return False\n",
    "        else:\n",
    "            return True\n",
    "        \n",
    "    def load_g(self, idx):\n",
    "        x = os.path.join(self.raw_dir, self.x[idx])\n",
    "        y = self.y[idx]\n",
    "    #         print(label)\n",
    "        CUDA_LAUNCH_BLOCKING=1\n",
    "        basic_model = Model().cuda()\n",
    "        t = torch.load(x)\n",
    "        t = basic_model.load_state_dict(t)\n",
    "        \n",
    "        g = None\n",
    "        with torch.no_grad():\n",
    "            # nodes_feat 512 * 513\n",
    "            nodes_feat = []\n",
    "            cnt = 0\n",
    "            # get conv1 nodes \n",
    "            conv1 = {}\n",
    "            for weight in basic_model.conv1.weight:\n",
    "                pad = nn.ZeroPad2d(padding=(254,254,253,254))\n",
    "                feat = pad(weight[0])\n",
    "                conv1[cnt] = feat\n",
    "                nodes_feat.append(feat)\n",
    "                cnt += 1\n",
    "\n",
    "            # get conv2 nodes\n",
    "            conv2 = {}\n",
    "            for weight in basic_model.conv2.weight:\n",
    "                pad = nn.ZeroPad2d(padding=(254,254,253,254))\n",
    "                feat = pad(weight[0])\n",
    "                conv2[cnt] = feat\n",
    "                nodes_feat.append(feat)\n",
    "                cnt += 1\n",
    "\n",
    "            # get conv1 -> conv2 edges\n",
    "            conv1_2 = []\n",
    "            for src in conv1.keys():\n",
    "                for dst in conv2.keys():\n",
    "                    conv1_2.append([src, dst])\n",
    "\n",
    "\n",
    "            # get fc node\n",
    "            fc_index = cnt\n",
    "            cnt += 1\n",
    "            fc_node = torch.concat([basic_model.fc.weight, basic_model.fc.bias.reshape(512, 1)], 1)\n",
    "            nodes_feat.append(fc_node)\n",
    "            # print(fc_node.shape)\n",
    "\n",
    "            # get conv2 -> fc edges\n",
    "            conv2_fc = []\n",
    "            for src in conv2.keys():\n",
    "                conv2_fc.append([src, fc_index])\n",
    "\n",
    "            # get output node\n",
    "            out_index = cnt\n",
    "            cnt += 1 \n",
    "            out = torch.concat([basic_model.output.weight, basic_model.output.bias.reshape(10, 1)], 1)\n",
    "            pad = nn.ZeroPad2d(padding=(0,0,251,251))\n",
    "            out_node = pad(out)\n",
    "            nodes_feat.append(out_node)\n",
    "\n",
    "            # print(out_node.shape)\n",
    "\n",
    "            # get fc -> output edge\n",
    "            fc_out_edge = [[fc_index, out_index]]\n",
    "\n",
    "            # get all nodes\n",
    "            nodes_feat = torch.stack(nodes_feat)\n",
    "            # print(nodes_feat.shape)\n",
    "            # get all edges\n",
    "            all_edges = torch.tensor(conv1_2 + conv2_fc + fc_out_edge).t().tolist()\n",
    "            u, v = all_edges[0], all_edges[1]\n",
    "\n",
    "\n",
    "            g = dgl.graph((u,v)).to('cuda')\n",
    "            g.ndata['x'] = nodes_feat\n",
    "        return g, y\n",
    "    \n",
    "    \n",
    "dataset = HomoStrucBackdoorDataset(mode='valid')\n",
    "print(len(dataset))\n",
    "dataset.load()\n",
    "x,y = dataset.get_x_y()\n",
    "for i in x:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9e09e42",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with DGL built-in GINConv module with a fixed epsilon = 0\n",
      "Training Procedure...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [01:45<00:00,  9.74it/s]\n",
      "100%|██████████| 1024/1024 [00:44<00:00, 22.90it/s]\n",
      "100%|██████████| 128/128 [00:11<00:00, 11.03it/s]\n",
      "100%|██████████| 192/192 [00:19<00:00, 10.01it/s]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'valid_acc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-2-9ddc4a07dcfc>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m    192\u001B[0m     \u001B[0;31m# model training/validating\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    193\u001B[0m     \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'Training Procedure...'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 194\u001B[0;31m     \u001B[0mtrain\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtrain_loader\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mval_loader\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtest_loader\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdevice\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmodel\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    195\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m<ipython-input-2-9ddc4a07dcfc>\u001B[0m in \u001B[0;36mtrain\u001B[0;34m(train_loader, val_loader, test_loader, device, model)\u001B[0m\n\u001B[1;32m    150\u001B[0m         \u001B[0minfo\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'test_acc'\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minfo\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'test_pre'\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minfo\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'test_rec'\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minfo\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'test_f1'\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtest_acc\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtest_pre\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtest_rec\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtest_f1\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    151\u001B[0m         print(\"Epoch {:05d} | Loss {:.4f} | Train Acc. {:.4f} | Validation Acc. {:.4f}| Test Acc. {:.4f} \"\n\u001B[0;32m--> 152\u001B[0;31m               . format(epoch, total_loss / (batch + 1), train_acc, valid_acc, test_acc))\n\u001B[0m\u001B[1;32m    153\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    154\u001B[0m     \u001B[0;32mfrom\u001B[0m \u001B[0mdatetime\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mdatetime\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'valid_acc' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from dgl.data import GINDataset\n",
    "from dgl.dataloading import GraphDataLoader\n",
    "from dgl.nn.pytorch.conv import GINConv\n",
    "from dgl.nn.pytorch.glob import SumPooling, AvgPooling, MaxPooling, SortPooling\n",
    "import argparse\n",
    "from tqdm import tqdm\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    \"\"\"Construct two-layer MLP-type aggreator for GIN model\"\"\"\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super().__init__()\n",
    "        self.linears = nn.ModuleList()\n",
    "        # two-layer MLP    \n",
    "        self.linears.append(nn.Linear(input_dim, hidden_dim, bias=False))\n",
    "        self.linears.append(nn.Linear(hidden_dim, output_dim, bias=False))\n",
    "        self.batch_norm = nn.BatchNorm1d((hidden_dim))\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = x\n",
    "        h = F.relu(self.batch_norm(self.linears[0](h)))\n",
    "        return self.linears[1](h)\n",
    "    \n",
    "class SGN(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, pooling='sum'):\n",
    "        super().__init__()\n",
    "        assert pooling in ['sum', 'avg', 'max'], \"Not supported pooling method.\"\n",
    "        self.ginlayers = nn.ModuleList()\n",
    "        self.batch_norms = nn.ModuleList()\n",
    "        num_layers = 2\n",
    "        # five-layer GCN with two-layer MLP aggregator and sum-neighbor-pooling scheme\n",
    "#         for layer in range(num_layers - 1): # excluding the input layer\n",
    "#             if layer == 0:\n",
    "#                 mlp = MLP(input_dim, hidden_dim, hidden_dim)\n",
    "#             else:\n",
    "#                 mlp = MLP(hidden_dim, hidden_dim, hidden_dim)\n",
    "#             self.ginlayers.append(GINConv(mlp, learn_eps=False)) # set to True if learning epsilon\n",
    "#             self.batch_norms.append(nn.BatchNorm1d(hidden_dim))\n",
    "        # linear functions for graph sum poolings of output of each layer\n",
    "        self.linear_prediction = nn.ModuleList()\n",
    "        for layer in range(num_layers):\n",
    "            if layer == 0:\n",
    "                self.linear_prediction.append(nn.Linear(input_dim, output_dim))\n",
    "            else:\n",
    "                self.linear_prediction.append(nn.Linear(hidden_dim, output_dim))\n",
    "        self.drop = nn.Dropout(0.8)\n",
    "        if pooling == 'sum':\n",
    "            self.pool = SumPooling() # change to mean readout (AvgPooling) on social network datasets\n",
    "        elif pooling == 'avg':\n",
    "            self.pool = AvgPooling()\n",
    "        else:\n",
    "            self.pool = MaxPooling()\n",
    "#         self.topK = topK\n",
    "#         self.pool = SortPooling(topK)\n",
    "#         self.pool = AvgPooling()\n",
    "        \n",
    "    def forward(self, g, h):\n",
    "        # list of hidden representation at each layer (including the input layer)\n",
    "        hidden_rep = [h]\n",
    "        for i, layer in enumerate(self.ginlayers):\n",
    "            h = layer(g, h)\n",
    "            h = self.batch_norms[i](h)\n",
    "            h = F.relu(h)\n",
    "            hidden_rep.append(h)\n",
    "        score_over_layer = 0\n",
    "        # perform graph sum pooling over all nodes in each layer\n",
    "        for i, h in enumerate(hidden_rep):\n",
    "            pooled_h = self.pool(g, h)\n",
    "            score_over_layer += self.drop(self.linear_prediction[i](pooled_h))\n",
    "        return score_over_layer\n",
    "    \n",
    "def split_fold10(labels, fold_idx=0):\n",
    "    skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=0)\n",
    "    idx_list = []\n",
    "    for idx in skf.split(np.zeros(len(labels)), labels):\n",
    "        idx_list.append(idx)\n",
    "    train_idx, valid_idx = idx_list[fold_idx]\n",
    "    return train_idx, valid_idx\n",
    "\n",
    "def evaluate(dataloader, device, model):\n",
    "    model.eval()\n",
    "    total = 0\n",
    "    total_correct = 0\n",
    "    total_tp = 0\n",
    "    total_fp = 0\n",
    "    total_tn = 0\n",
    "    total_fn = 0\n",
    "    for batch, (batched_graph, labels) in enumerate(tqdm(dataloader)):\n",
    "        batched_graph = batched_graph.to(device)\n",
    "        labels = labels.to(device)\n",
    "        feat = batched_graph.ndata.pop('x')\n",
    "        total += len(labels)\n",
    "        logits = model(batched_graph, feat.view(len(feat), -1))\n",
    "        _, predicted = torch.max(logits, 1)\n",
    "        total_correct += (predicted == labels).sum().item()\n",
    "        m = predicted + labels\n",
    "        total_tp += (m >= 2).sum().item()\n",
    "        total_tn += (m == 0).sum().item()\n",
    "        total_fp += (predicted > labels).sum().item()\n",
    "        total_fn += (predicted < labels).sum().item()\n",
    "        # print(m, predicted, labels, total_tp, total_tn, total_fp, total_fn)\n",
    "    acc = 1.0 * total_correct / total\n",
    "    pre = 1.0 * total_tp / (total_tp + total_fp)\n",
    "    rec = 1.0 * total_tp / (total_tp + total_fn)\n",
    "    f1 = 2.0 * pre * rec / (rec + rec)\n",
    "    # print(acc, pre, rec, f1)\n",
    "    return acc, pre, rec, f1\n",
    "\n",
    "def train(train_loader, val_loader, test_loader, device, model):\n",
    "    # loss function, optimizer and scheduler\n",
    "    loss_fcn = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=50, gamma=0.5)\n",
    "    info = {'train_acc':[], 'val_acc':[], 'test_acc':[], \n",
    "            'train_pre':[], 'val_pre':[], 'test_pre':[],\n",
    "            'train_rec':[], 'val_res':[], 'test_res':[],\n",
    "            'train_f1':[], 'val_f1':[], 'test_f1':[]}\n",
    "    # training loop    \n",
    "    for epoch in range(350):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        for batch, (batched_graph, labels) in enumerate(tqdm(train_loader)):\n",
    "            batched_graph = batched_graph.to(device)\n",
    "            #print(batch, labels, type(labels))\n",
    "            labels = labels.to(device)\n",
    "            # print(labels)\n",
    "            feat = batched_graph.ndata.pop('x')\n",
    "            # print(feat.view(50,-1).shape)\n",
    "            logits = model(batched_graph, feat.view(len(feat), -1))\n",
    "            # print(logits)\n",
    "            # print(logits.shape, labels.shape)\n",
    "            loss = loss_fcn(logits, labels)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        scheduler.step()\n",
    "        # acc, pre, rec, f1\n",
    "        train_acc, train_pre, train_rec, train_f1 = evaluate(train_loader, device, model)\n",
    "        info['train_acc'], info['train_pre'], info['train_rec'], info['train_f1'] = train_acc, train_pre, train_rec, train_f1\n",
    "        val_acc, val_pre, val_rec, val_f1 = evaluate(val_loader, device, model)\n",
    "        info['val_acc'], info['val_pre'], info['val_rec'], info['val_f1'] = val_acc, val_pre, val_rec, val_f1\n",
    "        test_acc, test_pre, test_rec, test_f1 = evaluate(test_loader, device, model)\n",
    "        info['test_acc'], info['test_pre'], info['test_rec'], info['test_f1'] = test_acc, test_pre, test_rec, test_f1\n",
    "        print(\"Epoch {:05d} | Loss {:.4f} | Train Acc. {:.4f} | Validation Acc. {:.4f}| Test Acc. {:.4f} \"\n",
    "              . format(epoch, total_loss / (batch + 1), train_acc, valid_acc, test_acc))\n",
    "        \n",
    "    from datetime import datetime\n",
    "    import json\n",
    "    now = datetime.now()\n",
    "    date = now.strftime(\"%Y-%m-%d-%H:%M:%S\")\n",
    "    with open('./intermediate_data/train-%s.json' % date, 'w') as f:\n",
    "        json.dump(info, f)\n",
    "        \n",
    "if __name__ == '__main__':\n",
    "#     parser = argparse.ArgumentParser()\n",
    "#     parser.add_argument('--dataset', type=str, default=\"MUTAG\",\n",
    "#                         choices=['MUTAG', 'PTC', 'NCI1', 'PROTEINS'],\n",
    "#                         help='name of dataset (default: MUTAG)')\n",
    "#     parser.add_argument('--pooling', type=str, default='sum', choices=['sum', 'avg', 'max'], help='pooling method, default:sum')\n",
    "#     args = parser.parse_args()\n",
    "    print(f'Training with DGL built-in GINConv module with a fixed epsilon = 0')\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    # load and split dataset\n",
    "    # dataset = GINDataset(args.dataset, self_loop=True, degree_as_nlabel=False) # add self_loop and disable one-hot encoding for input features\n",
    "    dataset = HomoStrucBackdoorDataset()\n",
    "    val_dataset = HomoStrucBackdoorDataset(mode='valid')\n",
    "    test_dataset = HomoStrucBackdoorDataset(mode='test')\n",
    "\n",
    "    # train_idx, val_idx = split_fold10(labels)\n",
    "    # print(train_idx, val_idx)\n",
    "    \n",
    "    # create dataloader\n",
    "    train_loader = GraphDataLoader(dataset, batch_size=4, pin_memory=torch.cuda.is_available())\n",
    "    val_loader = GraphDataLoader(val_dataset, batch_size=4, pin_memory=torch.cuda.is_available())\n",
    "    test_loader = GraphDataLoader(test_dataset, batch_size=4, pin_memory=torch.cuda.is_available())\n",
    "    \n",
    "    # create GIN model\n",
    "    in_size = 512 * 513\n",
    "    #gin_dataset = GINDataset('MUTAG', self_loop=True, degree_as_nlabel=False) # add self_loop and disable one-hot encoding for input features\n",
    "    # print(gin_dataset.dim_nfeats)\n",
    "    out_size = 2\n",
    "    model = SGN(in_size, 16, out_size).to(device)\n",
    "\n",
    "    # model training/validating\n",
    "    print('Training Procedure...')\n",
    "    train(train_loader, val_loader, test_loader, device, model)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36bfe2c3",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mntd-real",
   "language": "python",
   "name": "mntd-real"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}