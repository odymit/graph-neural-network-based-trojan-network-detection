{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "\n",
    "# POC 激活验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import dgl\n",
    "import torch\n",
    "from utils_gnn import cnn2graph_activation\n",
    "# from model_lib import mnist_cnn_model as father_model\n",
    "from utils_basic import load_spec_model\n",
    "from utils_gnn import padding, unpadding\n",
    "from dgl.data import DGLDataset\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from dgl import save_graphs, load_graphs\n",
    "import torch\n",
    "import json\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "# from model_lib.mnist_cnn_model import Model\n",
    "from random import randint\n",
    "from utils_basic import load_spec_model\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from torchinfo import summary\n",
    "import torch.nn.functional as F\n",
    "from dgl.nn.pytorch.conv import GINConv\n",
    "from dgl.nn.pytorch.glob import SumPooling, AvgPooling, MaxPooling, SortPooling\n",
    "from utils_gnn import MLP\n",
    "\n",
    "\n",
    "# x = '/home/dorian/repos/Meta-Nerual-Trojan-Detection/shadow_model_ckpt/mnist/models5/shadow_jumbo_9.model'\n",
    "x = './shadow_model_ckpt/mnist/models5/shadow_jumbo_0.model'\n",
    "# load model \n",
    "# Model = load_spec_model(father_model, '5')\n",
    "from model_lib.mnist_cnn_model import Model6 as Model\n",
    "model = Model(gpu=True)\n",
    "params = torch.load(x)\n",
    "model.load_state_dict(params)\n",
    "del params\n",
    "\n",
    "# load model detail \n",
    "model_detail = {}\n",
    "model_detail_path = \"./intermediate_data/model_detail.json\"\n",
    "import json\n",
    "with open(model_detail_path, 'r') as f:\n",
    "    model_detail = json.load(f)\n",
    "# print(model_detail)\n",
    "g = cnn2graph_activation(model, model_detail['mnist']['5'])\n",
    "dgl.save_graphs('./intermediate_data/grapj_test.bin', g)\n",
    "del model_detail\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "# from utils_gnn import SGNACT\n",
    "GPU = True\n",
    "if GPU:\n",
    "        torch.cuda.manual_seed_all(0)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "        \n",
    "transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "        ])\n",
    "BATCH_SIZE = 1\n",
    "# MNIST image dataset \n",
    "trainset = torchvision.datasets.MNIST(root='./raw_data/', train=True, download=True, transform=transform)\n",
    "dataloader = torch.utils.data.DataLoader(trainset, batch_size=BATCH_SIZE)\n",
    "\n",
    "# get a image\n",
    "image = None\n",
    "label = None\n",
    "for i, (x_in, y_in) in enumerate(dataloader):\n",
    "    image = x_in\n",
    "    model(image)\n",
    "    label = y_in\n",
    "    break\n",
    "del trainset, dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# define the init process\n",
    "cnt = 0 \n",
    "def init_conv(data, data_size, weight, bias, kernel_size, stride, padding):\n",
    "    global cnt\n",
    "    row, col = weight.size()\n",
    "    # print(weight.size())\n",
    "    # get actual conv kernel weight and bias\n",
    "    w = unpadding(weight, 1, kernel_size[0]*kernel_size[1])\n",
    "    w = w.reshape(1, 1, kernel_size[0], kernel_size[1])\n",
    "    ws = w\n",
    "    np.savetxt(\"./intermediate_data/init/weight-%d.csv\" % cnt, ws[0][0].cpu().numpy(), delimiter=',')\n",
    "    cnt += 1\n",
    "    b = unpadding(bias, 1, 1)[0]\n",
    "    np.savetxt(\"./intermediate_data/init/bias-%d.csv\" % cnt, b.cpu().numpy(), delimiter=',')\n",
    "    # get conv operator \n",
    "    # print(\"kernel_size, stride, padding:\")\n",
    "    # print(kernel_size, stride, padding)\n",
    "    operator = torch.nn.Conv2d(1, 1, kernel_size=kernel_size, \n",
    "                    stride=stride, padding=padding)\n",
    "    # set conv operator weight and bias\n",
    "    operator.weight.data = w\n",
    "    operator.bias.data = b\n",
    "    # conduct conv operation\n",
    "    # print(\"conv input size:\", data.size())\n",
    "    x = operator(data.to(\"cuda\"))\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "def initiate_node_feature(graph, image):\n",
    "    ft = None \n",
    "    mask = graph.ndata['layer_idx'] == 0\n",
    "    out_channels = int(sum(mask))\n",
    "    ft = torch.zeros((len(graph.nodes()), 1, 1, 28, 28))\n",
    "    convd_size = torch.zeros((len(graph.nodes()), 2))\n",
    "    for i in range(out_channels):\n",
    "        kernel_size, stride, padding = graph.ndata['kernel_params'][i]\n",
    "        # do conv\n",
    "        res_ft = init_conv(image, None, graph.ndata['kernel_weight'][i], graph.ndata['bias'][i],\n",
    "                kernel_size, stride, padding)\n",
    "        # do relu\n",
    "        relu_opt = torch.nn.functional.relu\n",
    "        res_ft = relu_opt(res_ft)\n",
    "\n",
    "        # do max pooling\n",
    "        pooling = graph.ndata['pooling_params'][i]\n",
    "        if pooling.all() != 0:\n",
    "            # do max_pooling\n",
    "            kernel_size, stride, pad, dilation, ceil_mode = pooling\n",
    "            max_pooling_operator = torch.nn.MaxPool2d(kernel_size=kernel_size, stride=stride, \n",
    "                padding=pad, dilation=dilation, ceil_mode=ceil_mode)\n",
    "            \n",
    "            res_ft = max_pooling_operator(res_ft)\n",
    "        _, _, r, c = res_ft.size()\n",
    "        ft[i] = res_ft\n",
    "        convd_size[i] = torch.tensor([int(r), int(c)])\n",
    "    graph.ndata['ft'] = ft.to(\"cuda\")\n",
    "    graph.ndata['ft_size'] = convd_size.to(\"cuda\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1],\n",
      "       device='cuda:0')\n",
      "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71,\n",
      "        72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# init ft feature and get subg\n",
    "with torch.no_grad():\n",
    "    initiate_node_feature(g, image)\n",
    "print(g.ndata['layer_type'])\n",
    "# get node id\n",
    "def neural_conv_nodes(nodes):\n",
    "    return nodes.data['layer_type'] == 0\n",
    "nodes_idx = g.filter_nodes(neural_conv_nodes)\n",
    "# print(nodes_idx)\n",
    "subg = dgl.node_subgraph(g, nodes_idx, relabel_nodes=True)\n",
    "print(subg.nodes())\n",
    "ft32 = None\n",
    "# got the right subg of conv layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from utils_gnn import equals, prepare_data\n",
    "import pdb\n",
    "\n",
    "def prepare_conv_data(nkernel_weight, \n",
    "                      nkernel_size, \n",
    "                      nkernel_bias, \n",
    "                      nkernel_params, \n",
    "                      channels):\n",
    "    # prepare conv kernel weight\n",
    "    _, width, height = nkernel_size\n",
    "    kernel_weight = nkernel_weight\n",
    "    kernel_weight = unpadding(kernel_weight, channels, width * height)\n",
    "    kernel_weight = kernel_weight.reshape(1, channels, width, height)\n",
    "    # prepare conv bias\n",
    "    bias = nkernel_bias\n",
    "    kernel_bias = unpadding(bias, 1, 1)[0]\n",
    "\n",
    "    # prepare conv operator\n",
    "    kernel_size, stride, pad = nkernel_params\n",
    "\n",
    "    return kernel_weight, kernel_bias, kernel_size, stride, pad\n",
    "    \n",
    "def do_operation(data, conv_opt, pooling_params):\n",
    "    # do conv\n",
    "    torch.save(data, \"./intermediate_data/reshaped_data.pt\")\n",
    "    conv_ft = conv_opt(data.to(\"cuda\")).to(\"cuda\")\n",
    "    _, _, width, height = conv_ft.size()\n",
    "    np.savetxt(\"./intermediate_data/process/conv_processed_ft.csv\", conv_ft.reshape(width, height).cpu().numpy(), delimiter=',')\n",
    "    # do relu\n",
    "    relu_ft = torch.nn.functional.relu(conv_ft)\n",
    "    np.savetxt(\"./intermediate_data/process/relu_processed_ft.csv\", relu_ft.reshape(width, height).cpu().numpy(), delimiter=',')\n",
    "    ret_ft = relu_ft\n",
    "    # do pooling\n",
    "    if pooling_params.any() != 0:\n",
    "        kernel_size, stride, pad, dilation, ceil_mode = pooling_params\n",
    "        kernel_size, stride, pad, dilation, ceil_mode = int(kernel_size), int(stride), int(pad), int(dilation), bool(ceil_mode)\n",
    "        max_pooling_operator = torch.nn.MaxPool2d(kernel_size=kernel_size, stride=stride, \n",
    "            padding=pad, dilation=dilation, ceil_mode=ceil_mode)\n",
    "        \n",
    "        ret_ft = max_pooling_operator(relu_ft)\n",
    "        _, _, width, height = ret_ft.size()\n",
    "        # np.savetxt(\"./intermediate_data/ret_ft.csv\", ret_ft.reshape(width, height).cpu().numpy(), delimiter=',')\n",
    "\n",
    "    return ret_ft\n",
    "\n",
    "\n",
    "\n",
    "def my_reduce(nodes):\n",
    "    # received data and their size\n",
    "    mfeat = nodes.mailbox['m']\n",
    "    msize = nodes.mailbox['n']\n",
    "    \n",
    "    mf_size = mfeat.size()\n",
    "    n_nodes = mf_size[0]\n",
    "    n_channels = mf_size[1]\n",
    "\n",
    "    # prepare ret_ft & ret_size, input size (1, 1, 28, 28)\n",
    "    ret_ft = torch.zeros((n_nodes, 1, 1, 28, 28)).to(\"cuda\")\n",
    "    ret_size = torch.zeros((n_nodes, 2)).to(\"cuda\")\n",
    "\n",
    "    # for each node, do conv for received data\n",
    "    for out_idx in range(n_nodes):\n",
    "\n",
    "        # prepare received data and conv weight\n",
    "        received_data = mfeat[out_idx]\n",
    "        received_size = msize[out_idx]\n",
    "        np.savetxt(\"./intermediate_data/process/rec-size-%d.csv\" % out_idx, received_size.cpu().numpy(), delimiter=',')\n",
    "        torch.save(received_data, \"./intermediate_data/process/receivec_data.pt\")\n",
    "\n",
    "        # skip if all zeros\n",
    "        if equals(received_data, zeros=True):\n",
    "            continue\n",
    "        # (n, 1, 1, 28, 28) -> (1, n, width, height)\n",
    "        data = prepare_data(received_data, received_size)\n",
    "\n",
    "        # prepare conv operator data\n",
    "        kernel_weight, kernel_bias, kernel_size, stride, pad = prepare_conv_data(nodes.data['kernel_weight'][out_idx], \n",
    "                                                                                nodes.data['kernel_size'][out_idx],\n",
    "                                                                                nodes.data['bias'][out_idx], \n",
    "                                                                                nodes.data['kernel_params'][out_idx], \n",
    "                                                                                n_channels)\n",
    "        \n",
    "        # prepare conv operator\n",
    "        conv_opt = torch.nn.Conv2d(n_channels, 1, kernel_size=kernel_size, stride=stride, padding=pad)\n",
    "        conv_opt.weight.data = kernel_weight\n",
    "        conv_opt.bias.data = kernel_bias\n",
    "        torch.save(kernel_weight, \"./intermediate_data/process/kernel_weight.pt\")\n",
    "        np.savetxt(\"./intermediate_data/process/kernel-bias-%d.csv\" % (out_idx),  kernel_bias.cpu().numpy(), delimiter=',')\n",
    "        # print(\"kernel weight size:\", kernel_weight.size(), kernel_size)\n",
    "        # print(\"kernel_bias size:\", kernel_size.size())\n",
    "\n",
    "        # do operation\n",
    "        ft = do_operation(data, conv_opt, nodes.data['pooling_params'][out_idx])\n",
    "\n",
    "        # save ft size\n",
    "        _, _, width, height = ft.size()\n",
    "        np.savetxt(\"./intermediate_data/process/ret_ft.csv\", ft.reshape(width, height).cpu().numpy(), delimiter=',')\n",
    "        pad_ft = padding(ft.reshape(width, height), 28, 28)\n",
    "        np.savetxt(\"./intermediate_data/process/pad_ft.csv\", pad_ft.cpu().numpy(), delimiter=',')\n",
    "        reshaped_ft = pad_ft.reshape(1, 1, 28, 28)\n",
    "        # update return data\n",
    "        ret_ft[out_idx] = reshaped_ft\n",
    "        ret_size[out_idx] = torch.tensor([width, height]).to(\"cuda\")\n",
    "        # a_break = input(\"go next?\")\n",
    "        \n",
    "    # return size is [n, 1, 1, 28, 28], reduced from [n, m, 1, 1, 28, 28]\n",
    "    return {'h': ret_ft, 'g': ret_size}\n",
    "\n",
    "def my_message(edges):\n",
    "    return {'m': edges.src['ft'], 'n': edges.src['ft_size']}\n",
    "\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    # 当最后一个节点尚未传播到的时候，继续执行传播操作\n",
    "    while equals(subg.ndata['ft_size'][-1], zeros=True):\n",
    "        subg.update_all(my_message, my_reduce)\n",
    "        for idx in range(len(subg.ndata['ft'])):\n",
    "            if equals(subg.ndata['ft'][idx], zeros=True):\n",
    "                subg.ndata['ft'][idx] = subg.ndata['h'][idx]\n",
    "            if equals(subg.ndata['ft_size'][idx], zeros=True):\n",
    "                subg.ndata['ft_size'][idx] = subg.ndata['g'][idx]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([88, 1, 1, 28, 28])\n",
      "torch.Size([88, 2])\n"
     ]
    }
   ],
   "source": [
    "print(subg.ndata['ft'].size())\n",
    "print(subg.ndata['ft_size'].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ft: \n",
      "zeros -  [46, 47, 49, 57, 65, 72, 73, 75]\n",
      "nonzeros -  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 48, 50, 51, 52, 53, 54, 55, 56, 58, 59, 60, 61, 62, 63, 64, 66, 67, 68, 69, 70, 71, 74, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87]\n",
      "h: \n",
      "zeros -  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 46, 47, 49, 57, 65, 72, 73, 75]\n",
      "nonzeros -  [32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 48, 50, 51, 52, 53, 54, 55, 56, 58, 59, 60, 61, 62, 63, 64, 66, 67, 68, 69, 70, 71, 74, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87]\n",
      "ft_size: \n",
      "zeros -  []\n",
      "nonzeros -  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87]\n",
      "g: \n",
      "zeros -  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31]\n",
      "nonzeros -  [32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87]\n"
     ]
    }
   ],
   "source": [
    "def print_zeros_in_feat(key):\n",
    "    print(key + \": \")\n",
    "    zeros = []\n",
    "    nonzero = []\n",
    "    for id in subg.nodes():\n",
    "        id = int(id)\n",
    "        feat = subg.nodes[id].data[key]\n",
    "        if torch.eq(feat, torch.zeros(feat.size()).to(\"cuda\")).all() == True:\n",
    "            zeros.append(id)\n",
    "        else:\n",
    "            nonzero.append(id)\n",
    "    print(\"zeros - \", zeros)\n",
    "    print(\"nonzeros - \", nonzero)\n",
    "\n",
    "print_zeros_in_feat('ft')\n",
    "print_zeros_in_feat('h')\n",
    "print_zeros_in_feat('ft_size')\n",
    "print_zeros_in_feat('g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([7., 7.], device='cuda:0') 7 7\n",
      "tensor([[ 1.7792,  0.0000,  0.0000,  0.0000,  0.0000,  1.1611,  6.6959],\n",
      "        [ 5.1518,  1.1776,  0.0000,  3.3811,  9.1028,  5.7674,  7.4037],\n",
      "        [ 5.1297,  6.2894,  0.0000, 12.7424, 16.8882,  6.2509,  0.0445],\n",
      "        [ 1.4539,  8.4813,  6.2850,  0.0000,  8.7977, 20.9802,  0.1473],\n",
      "        [ 1.3156,  0.3564,  0.0000,  0.0000,  9.1116, 21.8856,  0.0572],\n",
      "        [ 2.9410,  0.0000,  2.2457, 11.6646,  9.9770,  7.0505,  0.0000],\n",
      "        [ 4.3832,  0.1667,  6.2607,  7.3015,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "size = subg.ndata['ft_size'][87]\n",
    "w, h = size\n",
    "\n",
    "w, h = int(w), int(h)\n",
    "\n",
    "print(size, w, h)\n",
    "\n",
    "res = unpadding(subg.ndata['ft'][85].reshape(28, 28), w, h)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt = 0\n",
    "ft_list = []\n",
    "for f,s in zip(subg.ndata['ft'], subg.ndata['ft_size']):\n",
    "    w, h = s\n",
    "    w, h = int(w), int(h)\n",
    "    data = unpadding(f.reshape(28, 28), w, h)\n",
    "    # print(w, h, cnt)\n",
    "    ft_list.append(data)\n",
    "    np.savetxt(\"./intermediate_data/graph_results/node-%d.csv\" % cnt, data.cpu(), delimiter=',')\n",
    "    cnt += 1\n",
    "\n",
    "cnt = 0\n",
    "cnn_params = None \n",
    "with open(\"./intermediate_data/params.json\", \"r\") as f:\n",
    "    cnn_params = json.load(f)\n",
    "from torch.nn.functional import relu\n",
    "from utils_gnn import unpadding\n",
    "conv1 = torch.tensor(cnn_params['conv1'])\n",
    "conv2 = torch.tensor(cnn_params['conv2'])\n",
    "conv3 = torch.tensor(cnn_params['conv3'])\n",
    "conv4 = torch.tensor(cnn_params['conv4'])\n",
    "l = [conv1, conv2, conv3, conv4]\n",
    "neural_list = []\n",
    "for layer in l:\n",
    "    for neural in layer[0]:\n",
    "        neural_list.append(neural)\n",
    "        np.savetxt(\"./intermediate_data/model_results/node-%d.csv\" % cnt, neural.cpu(), delimiter=',')\n",
    "        cnt += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0000,  0.9805,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000, 16.5474, 34.7467, 25.6497, 23.0430, 23.0015, 12.2277],\n",
      "        [ 0.0000,  2.5368, 39.6762, 26.9853,  3.7355,  4.5688,  4.2940],\n",
      "        [ 0.0000,  0.0000,  4.3969, 28.0040, 25.0063,  0.0000,  0.2286],\n",
      "        [ 0.0000,  0.0000,  0.0000, 11.7499, 20.8333, 16.8679,  1.9555],\n",
      "        [ 8.7424, 24.6951, 27.1628, 18.3077, 18.5936, 10.5977,  0.9699],\n",
      "        [ 0.0000, 10.9583, 13.3883,  5.1577,  0.0000,  0.0000,  0.2703]],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# add message transmitted ndata to original graph \n",
    "g.ndata['ft'][:len(subg.ndata['ft'])] = subg.ndata['ft']\n",
    "g.ndata['ft_size'][:len(subg.ndata['ft_size'])] = subg.ndata['ft_size']\n",
    "print(unpadding(g.ndata['ft'][87].reshape(28, 28), 7, 7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([88, 89, 90], device='cuda:0')\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 4, 5, 6],\n",
      "       device='cuda:0')\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# split full connected neurals\n",
    "def neural_fc_nodes(nodes):\n",
    "    layer_mask = nodes.data['layer_type'] == 1\n",
    "    layer_idxs = nodes.data['layer_idx'][layer_mask]\n",
    "    n = layer_idxs[0] \n",
    "    return nodes.data['layer_idx'] >= n\n",
    "fc_nodes = g.filter_nodes(neural_fc_nodes)\n",
    "print(fc_nodes)\n",
    "print(g.ndata['layer_idx'])\n",
    "print(g.ndata['layer_type'])\n",
    "subfcg = dgl.node_subgraph(g, fc_nodes, relabel_nodes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_fc_feat(data):\n",
    "    # data shape = (1, n)\n",
    "    data = padding(data, 1, 23 * 23)\n",
    "    ret = torch.zeros([23, 1, 23]).to(\"cuda\")\n",
    "    start = 0\n",
    "    end = 23\n",
    "    idx = 0\n",
    "    while end <= 23 * 23:\n",
    "        cur_data = data[0][start:end]\n",
    "        ret[idx] = cur_data.view(1, 23)\n",
    "        idx += 1\n",
    "        start += 23 \n",
    "        end += 23\n",
    "    # reshape (23, 1, 23) to (1, 1, 28, 28)\n",
    "    ret = padding(ret.reshape(23, 23), 28, 28)\n",
    "    return ret.reshape(1, 1, 28, 28)\n",
    "\n",
    "def  decode_fc_feat(data, n):\n",
    "    # data shape = (1, 1, 28, 28)\n",
    "    ret = unpadding(data.reshape(28, 28), 23, 23) # (23, 23)\n",
    "    ret = torch.cat([ret[i] for i in range(len(ret))]) # (23*23)\n",
    "    ret = ret.reshape(1, 23*23)\n",
    "    ret = unpadding(ret, 1, n)\n",
    "    return ret\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear params:  392 512\n",
      "torch.Size([512, 392]) torch.Size([512, 392])\n",
      "data size:  torch.Size([8, 7, 7]) torch.Size([1, 392])\n",
      "torch.Size([1, 512])\n"
     ]
    }
   ],
   "source": [
    "# get conv feat before first fc layer \n",
    "def neural_nodes_before_fc(nodes):\n",
    "    layer_mask = nodes.data['layer_type'] == 1\n",
    "    layer_idxs = nodes.data['layer_idx'][layer_mask]\n",
    "    n = layer_idxs[0] \n",
    "    return nodes.data['layer_idx'] == n - 1 \n",
    "pre_nodes_idx = g.filter_nodes(neural_nodes_before_fc)\n",
    "# print(pre_nodes_idx)\n",
    "# get feats and reshape to (1, channels, width, height)\n",
    "prefg = dgl.node_subgraph(g, pre_nodes_idx, relabel_nodes=True)\n",
    "pre_feats = prefg.ndata['ft']\n",
    "# (8, 1, 1, 28, 28)\n",
    "# print(pre_feats.shape)\n",
    "n_pre_nodes = len(pre_nodes_idx)\n",
    "shape = prefg.ndata['ft_size'][0]\n",
    "w, h = shape\n",
    "w, h = int(w), int(h)\n",
    "del prefg\n",
    "# reshape to (1, 8, 7, 7)\n",
    "feats = torch.zeros([n_pre_nodes, w, h])\n",
    "for idx in range(n_pre_nodes):\n",
    "    cur_data = pre_feats[idx]\n",
    "    cur_data = cur_data.reshape(28, 28)\n",
    "    res_data = unpadding(cur_data, w, h)\n",
    "    # print(\"res_data size:\", res_data.size())\n",
    "    feats[idx] = res_data\n",
    "data = feats\n",
    "# print(\"data size: \", data.shape)\n",
    "\n",
    "# concat weight\n",
    "def neural_concat_nodes(nodes):\n",
    "    layer_mask = nodes.data['layer_type'] == 1\n",
    "    layer_idxs = nodes.data['layer_idx'][layer_mask]\n",
    "    n = layer_idxs[0] \n",
    "    return nodes.data['layer_idx'] == n\n",
    "n = g.filter_nodes(neural_concat_nodes)\n",
    "n = int(n)\n",
    "# print(n, g.ndata['kernel_size'][n])\n",
    "in_dim = g.ndata['kernel_size'][n][1]\n",
    "out_dim = g.ndata['kernel_size'][n][2]\n",
    "in_dim, out_dim = int(in_dim), int(out_dim)\n",
    "# print(n, \" in_dim:\", in_dim, \" out_dim:\", out_dim)\n",
    "from torch.nn.parameter import Parameter\n",
    "fc_concat_weight = g.ndata['kernel_weight'][n]\n",
    "# reshape fc weight to (in_dim, out_dim)\n",
    "fc_concat_weight = unpadding(fc_concat_weight, in_dim, out_dim).t()\n",
    "# bias\n",
    "fc_concat_bias = g.ndata['bias'][n]\n",
    "bias_size = g.ndata['bias_size'][n]\n",
    "# print(bias_size)\n",
    "r, c = bias_size\n",
    "r, c = int(r), int(c)\n",
    "# reshape\n",
    "# print(fc_concat_bias.shape)\n",
    "fc_concat_bias = unpadding(fc_concat_bias, r, c)\n",
    "# init fc layer\n",
    "print(\"Linear params: \", in_dim, out_dim)\n",
    "concat_opt = torch.nn.Linear(in_dim, out_dim)\n",
    "print(concat_opt.weight.data.shape, fc_concat_weight.shape)\n",
    "concat_opt.weight = Parameter(fc_concat_weight)\n",
    "concat_opt.bias.data = Parameter(fc_concat_bias.reshape(512))\n",
    "\n",
    "# do concat\n",
    "print(\"data size: \", data.shape, data.view(1, in_dim).shape)\n",
    "fc_concat_result = torch.nn.functional.relu(concat_opt(data.view(1, in_dim).to(\"cuda\")))\n",
    "shape = fc_concat_result.size()\n",
    "r, c = shape\n",
    "r, c = int(r), int(c)\n",
    "\n",
    "print(fc_concat_result.shape)\n",
    "\n",
    "# set init fc feat\n",
    "g.ndata['ft'][n] = encode_fc_feat(fc_concat_result)\n",
    "g.ndata['ft_size'][n] = torch.tensor([r, c], dtype=torch.float32).to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_linear_opt(nodes, idx, data, size):\n",
    "    # prepare weight\n",
    "    in_dim = nodes.data['kernel_size'][idx][1]\n",
    "    out_dim = nodes.data['kernel_size'][idx][2]\n",
    "    in_dim, out_dim = int(in_dim), int(out_dim)\n",
    "    weight = nodes.data['kernel_weight'][idx]\n",
    "    # (out_dim, in_dim) for calculation optimization\n",
    "    weight = unpadding(weight, in_dim, out_dim).t()\n",
    "    # prepare bias\n",
    "    bias_size = nodes.data['bias_size'][idx]\n",
    "    r, c = bias_size\n",
    "    r, c = int(r), int(c)\n",
    "    bias = nodes.data['bias'][idx] # (1, 512) -> (r, c)\n",
    "    bias = unpadding(bias, r, c)\n",
    "    # prepare Linear layer\n",
    "    fc_opt = torch.nn.Linear(in_dim, out_dim)\n",
    "    fc_opt.weight = Parameter(weight)\n",
    "    fc_opt.bias = Parameter(bias.reshape(c))\n",
    "    # prepare data (1, 1, 28, 28) -> (1, n)\n",
    "    _, n = size[0]\n",
    "    data = decode_fc_feat(data, n)\n",
    "\n",
    "    # do Linear operation\n",
    "    ret = torch.nn.functional.relu(fc_opt(data.view(1, in_dim).to(\"cuda\")))\n",
    "    return ret\n",
    "\n",
    "\n",
    "def my_fc_message(edges):\n",
    "    return {'mf': edges.src['ft'], 'ms': edges.src['ft_size']}\n",
    "def my_fc_reduce(nodes):\n",
    "    mfeat = nodes.mailbox['mf']\n",
    "    msize = nodes.mailbox['ms']\n",
    "    \n",
    "    n_nodes = len(mfeat)\n",
    "    ret_ft = torch.zeros((n_nodes, 1, 1, 28, 28)).to(\"cuda\")\n",
    "    ret_size = torch.zeros((n_nodes, 2)).to(\"cuda\") \n",
    "\n",
    "    for out_idx in range(n_nodes):\n",
    "        received_data = mfeat[out_idx]\n",
    "        received_size = msize[out_idx]\n",
    "\n",
    "        # skip if all zeros, that is not transformed\n",
    "        if equals(received_size, zeros=True):\n",
    "            continue\n",
    "        # do Linear opt \n",
    "        ret = do_linear_opt(nodes, out_idx, received_data, received_size)\n",
    "        np.savetxt(\"./intermediate_data/process/ret_fc_ft-%d.csv\" % out_idx, ret.cpu().numpy(), delimiter=',')\n",
    "\n",
    "        shape = ret.size()\n",
    "        r, c = shape\n",
    "        r, c = int(r), int(c)\n",
    "\n",
    "        # set ret feat\n",
    "        ret_ft[out_idx] = encode_fc_feat(ret)\n",
    "        ret_size[out_idx] = torch.tensor([r, c], dtype=torch.float32).to(\"cuda\")\n",
    "    return {'h': ret_ft, 'g':ret_size}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    while equals(subfcg.ndata['ft_size'][-1], zeros=True):\n",
    "        subfcg.update_all(my_fc_message, my_fc_reduce)\n",
    "        for idx in range(len(subfcg.ndata['ft'])):\n",
    "            if equals(subfcg.ndata['ft'][idx], zeros=True):\n",
    "                subfcg.ndata['ft'][idx] = subfcg.ndata['h'][idx]\n",
    "            if equals(subfcg.ndata['ft_size'][idx], zeros=True):\n",
    "                subfcg.ndata['ft_size'][idx] = subfcg.ndata['g'][idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ft: \n",
      "zeros -  []\n",
      "nonzeros -  [0, 1, 2]\n",
      "h: \n",
      "zeros -  [0]\n",
      "nonzeros -  [1, 2]\n",
      "ft_size: \n",
      "zeros -  []\n",
      "nonzeros -  [0, 1, 2]\n",
      "g: \n",
      "zeros -  [0]\n",
      "nonzeros -  [1, 2]\n"
     ]
    }
   ],
   "source": [
    "def print_zeros_in_feat(key):\n",
    "    print(key + \": \")\n",
    "    zeros = []\n",
    "    nonzero = []\n",
    "    for id in subfcg.nodes():\n",
    "        id = int(id)\n",
    "        feat = subfcg.nodes[id].data[key]\n",
    "        if torch.eq(feat, torch.zeros(feat.size()).to(\"cuda\")).all() == True:\n",
    "            zeros.append(id)\n",
    "        else:\n",
    "            nonzero.append(id)\n",
    "    print(\"zeros - \", zeros)\n",
    "    print(\"nonzeros - \", nonzero)\n",
    "\n",
    "print_zeros_in_feat('ft')\n",
    "print_zeros_in_feat('h')\n",
    "print_zeros_in_feat('ft_size')\n",
    "print_zeros_in_feat('g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 512]) torch.Size([1, 128])\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "cnn_params = None \n",
    "with open(\"./intermediate_data/params.json\", \"r\") as f:\n",
    "    cnn_params = json.load(f)\n",
    "\n",
    "fc1 = torch.tensor(cnn_params['fc1']).to(\"cuda\")\n",
    "fc2 = torch.tensor(cnn_params['fc2'])\n",
    "print(fc1.shape, fc2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 7, 7]) torch.Size([1, 8, 7, 7])\n",
      "is input the same: True\n",
      "torch.Size([512, 392]) torch.Size([512, 392])\n",
      "is the fc1 weight the same: True\n",
      "tensor(True, device='cuda:0')\n",
      "torch.Size([1, 512]) torch.Size([512])\n",
      "is the fc1 bias the same: True\n",
      "tensor(True, device='cuda:0')\n",
      "torch.Size([1, 512]) torch.Size([1, 512])\n",
      "is the output the same: True\n",
      "tensor(False, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# compare fc1 out\n",
    "print(data.shape, conv4.shape)\n",
    "print(\"is input the same:\", equals(data, conv4.reshape(8, 7, 7)))\n",
    "print(concat_opt.weight.shape, model.fc1.weight.shape)\n",
    "print(\"is the fc1 weight the same:\", equals(concat_opt.weight, model.fc1.weight))\n",
    "print((fc_concat_weight == model.fc1.weight).all() == True)\n",
    "print(fc_concat_bias.shape, model.fc1.bias.shape)\n",
    "print(\"is the fc1 bias the same:\", equals(fc_concat_bias.reshape(512), model.fc1.bias))\n",
    "print((fc_concat_bias == model.fc1.bias).all() == True)\n",
    "print(fc_concat_result.shape, fc1.shape)\n",
    "print(\"is the output the same:\", equals(fc_concat_result, fc1))\n",
    "print((fc_concat_result == fc1).all() == True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 128]) torch.Size([1, 128])\n",
      "is fc2 out the same: True\n"
     ]
    }
   ],
   "source": [
    "# compare fc2 out\n",
    "data = subfcg.ndata['ft'][-2]\n",
    "_, n = subfcg.ndata['ft_size'][-2]\n",
    "data = decode_fc_feat(data, n)\n",
    "print(data.shape, fc2.shape)\n",
    "print(\"is fc2 out the same:\", equals(data.cpu(), fc2, precision=1e-5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 10]) torch.Size([1, 10])\n",
      "is fc2 out the same: True\n"
     ]
    }
   ],
   "source": [
    "# compare output layer out\n",
    "data = subfcg.ndata['ft'][-1]\n",
    "_, n = subfcg.ndata['ft_size'][-1]\n",
    "data = decode_fc_feat(data, n)\n",
    "ret, _ = model(image)\n",
    "print(data.shape, ret.shape)\n",
    "print(\"is output layer out the same:\", equals(data, torch.nn.functional.relu(ret), precision=1e-4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0000,  0.0000,  2.1183, 18.8971,  7.8918, 11.7048,  0.0000,  0.0000,\n",
      "          0.0000,  5.8714]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0000,  0.0000,  2.1183, 18.8971,  7.8918, 11.7048,  0.0000,  0.0000,\n",
      "          0.0000,  5.8714]], device='cuda:0', grad_fn=<ReluBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(torch.nn.functional.relu(ret))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.13 ('mntd')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2d7768e61f5674adf4efa61c7b8cc3ee2c06ae8f502b5df709cd3e31381a4347"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
