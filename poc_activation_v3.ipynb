{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "\n",
    "# POC 激活验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import dgl\n",
    "import torch\n",
    "from utils_gnn import cnn2graph_activation\n",
    "# from model_lib import mnist_cnn_model as father_model\n",
    "from utils_basic import load_spec_model\n",
    "from utils_gnn import padding, unpadding\n",
    "from dgl.data import DGLDataset\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from dgl import save_graphs, load_graphs\n",
    "import torch\n",
    "import json\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "# from model_lib.mnist_cnn_model import Model\n",
    "from random import randint\n",
    "from utils_basic import load_spec_model\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from torchinfo import summary\n",
    "import torch.nn.functional as F\n",
    "from dgl.nn.pytorch.conv import GINConv\n",
    "from dgl.nn.pytorch.glob import SumPooling, AvgPooling, MaxPooling, SortPooling\n",
    "from utils_gnn import MLP\n",
    "\n",
    "\n",
    "# x = '/home/dorian/repos/Meta-Nerual-Trojan-Detection/shadow_model_ckpt/mnist/models5/shadow_jumbo_9.model'\n",
    "x = './shadow_model_ckpt/mnist/models5/shadow_jumbo_0.model'\n",
    "# load model \n",
    "# Model = load_spec_model(father_model, '5')\n",
    "from model_lib.mnist_cnn_model import Model6 as Model\n",
    "model = Model(gpu=True)\n",
    "params = torch.load(x)\n",
    "model.load_state_dict(params)\n",
    "del params\n",
    "\n",
    "# load model detail \n",
    "model_detail = {}\n",
    "model_detail_path = \"./intermediate_data/model_detail.json\"\n",
    "import json\n",
    "with open(model_detail_path, 'r') as f:\n",
    "    model_detail = json.load(f)\n",
    "# print(model_detail)\n",
    "g = cnn2graph_activation(model, model_detail['mnist']['5'])\n",
    "dgl.save_graphs('./intermediate_data/grapj_test.bin', g)\n",
    "del model_detail\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "# from utils_gnn import SGNACT\n",
    "GPU = True\n",
    "if GPU:\n",
    "        torch.cuda.manual_seed_all(0)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "        \n",
    "transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "        ])\n",
    "BATCH_SIZE = 1\n",
    "# MNIST image dataset \n",
    "trainset = torchvision.datasets.MNIST(root='./raw_data/', train=True, download=True, transform=transform)\n",
    "dataloader = torch.utils.data.DataLoader(trainset, batch_size=BATCH_SIZE)\n",
    "\n",
    "# get a image\n",
    "image = None\n",
    "label = None\n",
    "for i, (x_in, y_in) in enumerate(dataloader):\n",
    "    image = x_in\n",
    "    model(image)\n",
    "    label = y_in\n",
    "    break\n",
    "del trainset, dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# define the init process\n",
    "cnt = 0 \n",
    "def init_conv(data, data_size, weight, bias, kernel_size, stride, padding):\n",
    "    global cnt\n",
    "    row, col = weight.size()\n",
    "    # print(weight.size())\n",
    "    # get actual conv kernel weight and bias\n",
    "    w = unpadding(weight, 1, kernel_size[0]*kernel_size[1])\n",
    "    w = w.reshape(1, 1, kernel_size[0], kernel_size[1])\n",
    "    ws = w\n",
    "    np.savetxt(\"./intermediate_data/init/weight-%d.csv\" % cnt, ws[0][0].cpu().numpy(), delimiter=',')\n",
    "    cnt += 1\n",
    "    b = unpadding(bias, 1, 1)[0]\n",
    "    np.savetxt(\"./intermediate_data/init/bias-%d.csv\" % cnt, b.cpu().numpy(), delimiter=',')\n",
    "    # get conv operator \n",
    "    # print(\"kernel_size, stride, padding:\")\n",
    "    # print(kernel_size, stride, padding)\n",
    "    operator = torch.nn.Conv2d(1, 1, kernel_size=kernel_size, \n",
    "                    stride=stride, padding=padding)\n",
    "    # set conv operator weight and bias\n",
    "    operator.weight.data = w\n",
    "    operator.bias.data = b\n",
    "    # conduct conv operation\n",
    "    # print(\"conv input size:\", data.size())\n",
    "    x = operator(data.to(\"cuda\"))\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "def initiate_node_feature(graph, image):\n",
    "    ft = None \n",
    "    mask = graph.ndata['layer_idx'] == 0\n",
    "    out_channels = int(sum(mask))\n",
    "    ft = torch.zeros((len(graph.nodes()), 1, 1, 28, 28))\n",
    "    convd_size = torch.zeros((len(graph.nodes()), 2))\n",
    "    for i in range(out_channels):\n",
    "        kernel_size, stride, padding = graph.ndata['kernel_params'][i]\n",
    "        # do conv\n",
    "        res_ft = init_conv(image, None, graph.ndata['kernel_weight'][i], graph.ndata['bias'][i],\n",
    "                kernel_size, stride, padding)\n",
    "        # do relu\n",
    "        relu_opt = torch.nn.functional.relu\n",
    "        res_ft = relu_opt(res_ft)\n",
    "\n",
    "        # do max pooling\n",
    "        pooling = graph.ndata['pooling_params'][i]\n",
    "        if pooling.all() != 0:\n",
    "            # do max_pooling\n",
    "            kernel_size, stride, pad, dilation, ceil_mode = pooling\n",
    "            max_pooling_operator = torch.nn.MaxPool2d(kernel_size=kernel_size, stride=stride, \n",
    "                padding=pad, dilation=dilation, ceil_mode=ceil_mode)\n",
    "            \n",
    "            res_ft = max_pooling_operator(res_ft)\n",
    "        _, _, r, c = res_ft.size()\n",
    "        ft[i] = res_ft\n",
    "        convd_size[i] = torch.tensor([int(r), int(c)])\n",
    "    graph.ndata['ft'] = ft.to(\"cuda\")\n",
    "    graph.ndata['ft_size'] = convd_size.to(\"cuda\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1],\n",
      "       device='cuda:0')\n",
      "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71,\n",
      "        72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# init ft feature and get subg\n",
    "with torch.no_grad():\n",
    "    initiate_node_feature(g, image)\n",
    "print(g.ndata['layer_type'])\n",
    "# get node id\n",
    "def neural_conv_nodes(nodes):\n",
    "    return nodes.data['layer_type'] == 0\n",
    "nodes_idx = g.filter_nodes(neural_conv_nodes)\n",
    "# print(nodes_idx)\n",
    "subg = dgl.node_subgraph(g, nodes_idx, relabel_nodes=True)\n",
    "print(subg.nodes())\n",
    "ft32 = None\n",
    "# got the right subg of conv layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from utils_gnn import equals, prepare_data\n",
    "import pdb\n",
    "\n",
    "def prepare_conv_data(nkernel_weight, \n",
    "                      nkernel_size, \n",
    "                      nkernel_bias, \n",
    "                      nkernel_params, \n",
    "                      channels):\n",
    "    # prepare conv kernel weight\n",
    "    _, width, height = nkernel_size\n",
    "    kernel_weight = nkernel_weight\n",
    "    kernel_weight = unpadding(kernel_weight, channels, width * height)\n",
    "    kernel_weight = kernel_weight.reshape(1, channels, width, height)\n",
    "    # prepare conv bias\n",
    "    bias = nkernel_bias\n",
    "    kernel_bias = unpadding(bias, 1, 1)[0]\n",
    "\n",
    "    # prepare conv operator\n",
    "    kernel_size, stride, pad = nkernel_params\n",
    "\n",
    "    return kernel_weight, kernel_bias, kernel_size, stride, pad\n",
    "    \n",
    "def do_operation(data, conv_opt, pooling_params):\n",
    "    # do conv\n",
    "    torch.save(data, \"./intermediate_data/reshaped_data.pt\")\n",
    "    conv_ft = conv_opt(data.to(\"cuda\")).to(\"cuda\")\n",
    "    _, _, width, height = conv_ft.size()\n",
    "    np.savetxt(\"./intermediate_data/process/conv_processed_ft.csv\", conv_ft.reshape(width, height).cpu().numpy(), delimiter=',')\n",
    "    # do relu\n",
    "    relu_ft = torch.nn.functional.relu(conv_ft)\n",
    "    np.savetxt(\"./intermediate_data/process/relu_processed_ft.csv\", relu_ft.reshape(width, height).cpu().numpy(), delimiter=',')\n",
    "    ret_ft = relu_ft\n",
    "    # do pooling\n",
    "    if pooling_params.any() != 0:\n",
    "        kernel_size, stride, pad, dilation, ceil_mode = pooling_params\n",
    "        kernel_size, stride, pad, dilation, ceil_mode = int(kernel_size), int(stride), int(pad), int(dilation), bool(ceil_mode)\n",
    "        max_pooling_operator = torch.nn.MaxPool2d(kernel_size=kernel_size, stride=stride, \n",
    "            padding=pad, dilation=dilation, ceil_mode=ceil_mode)\n",
    "        \n",
    "        ret_ft = max_pooling_operator(relu_ft)\n",
    "        _, _, width, height = ret_ft.size()\n",
    "        # np.savetxt(\"./intermediate_data/ret_ft.csv\", ret_ft.reshape(width, height).cpu().numpy(), delimiter=',')\n",
    "\n",
    "    return ret_ft\n",
    "\n",
    "\n",
    "\n",
    "def my_reduce(nodes):\n",
    "    # received data and their size\n",
    "    mfeat = nodes.mailbox['m']\n",
    "    msize = nodes.mailbox['n']\n",
    "    \n",
    "    mf_size = mfeat.size()\n",
    "    n_nodes = mf_size[0]\n",
    "    n_channels = mf_size[1]\n",
    "\n",
    "    # prepare ret_ft & ret_size, input size (1, 1, 28, 28)\n",
    "    ret_ft = torch.zeros((n_nodes, 1, 1, 28, 28)).to(\"cuda\")\n",
    "    ret_size = torch.zeros((n_nodes, 2)).to(\"cuda\")\n",
    "\n",
    "    # for each node, do conv for received data\n",
    "    for out_idx in range(n_nodes):\n",
    "\n",
    "        # prepare received data and conv weight\n",
    "        received_data = mfeat[out_idx]\n",
    "        received_size = msize[out_idx]\n",
    "        np.savetxt(\"./intermediate_data/process/rec-size-%d.csv\" % out_idx, received_size.cpu().numpy(), delimiter=',')\n",
    "        torch.save(received_data, \"./intermediate_data/process/receivec_data.pt\")\n",
    "\n",
    "        # skip if all zeros\n",
    "        if equals(received_data, zeros=True):\n",
    "            continue\n",
    "        # (n, 1, 1, 28, 28) -> (1, n, width, height)\n",
    "        data = prepare_data(received_data, received_size)\n",
    "\n",
    "        # prepare conv operator data\n",
    "        kernel_weight, kernel_bias, kernel_size, stride, pad = prepare_conv_data(nodes.data['kernel_weight'][out_idx], \n",
    "                                                                                nodes.data['kernel_size'][out_idx],\n",
    "                                                                                nodes.data['bias'][out_idx], \n",
    "                                                                                nodes.data['kernel_params'][out_idx], \n",
    "                                                                                n_channels)\n",
    "        \n",
    "        # prepare conv operator\n",
    "        conv_opt = torch.nn.Conv2d(n_channels, 1, kernel_size=kernel_size, stride=stride, padding=pad)\n",
    "        conv_opt.weight.data = kernel_weight\n",
    "        conv_opt.bias.data = kernel_bias\n",
    "        torch.save(kernel_weight, \"./intermediate_data/process/kernel_weight.pt\")\n",
    "        np.savetxt(\"./intermediate_data/process/kernel-bias-%d.csv\" % (out_idx),  kernel_bias.cpu().numpy(), delimiter=',')\n",
    "        # print(\"kernel weight size:\", kernel_weight.size(), kernel_size)\n",
    "        # print(\"kernel_bias size:\", kernel_size.size())\n",
    "\n",
    "        # do operation\n",
    "        ft = do_operation(data, conv_opt, nodes.data['pooling_params'][out_idx])\n",
    "\n",
    "        # save ft size\n",
    "        _, _, width, height = ft.size()\n",
    "        np.savetxt(\"./intermediate_data/process/ret_ft.csv\", ft.reshape(width, height).cpu().numpy(), delimiter=',')\n",
    "        pad_ft = padding(ft.reshape(width, height), 28, 28)\n",
    "        np.savetxt(\"./intermediate_data/process/pad_ft.csv\", pad_ft.cpu().numpy(), delimiter=',')\n",
    "        reshaped_ft = pad_ft.reshape(1, 1, 28, 28)\n",
    "        # update return data\n",
    "        ret_ft[out_idx] = reshaped_ft\n",
    "        ret_size[out_idx] = torch.tensor([width, height]).to(\"cuda\")\n",
    "        # a_break = input(\"go next?\")\n",
    "        \n",
    "    # return size is [n, 1, 1, 28, 28], reduced from [n, m, 1, 1, 28, 28]\n",
    "    return {'h': ret_ft, 'g': ret_size}\n",
    "\n",
    "def my_message(edges):\n",
    "    return {'m': edges.src['ft'], 'n': edges.src['ft_size']}\n",
    "\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    # 当最后一个节点尚未传播到的时候，继续执行传播操作\n",
    "    while equals(subg.ndata['ft_size'][-1], zeros=True):\n",
    "        subg.update_all(my_message, my_reduce)\n",
    "        for idx in range(len(subg.ndata['ft'])):\n",
    "            if equals(subg.ndata['ft'][idx], zeros=True):\n",
    "                subg.ndata['ft'][idx] = subg.ndata['h'][idx]\n",
    "            if equals(subg.ndata['ft_size'][idx], zeros=True):\n",
    "                subg.ndata['ft_size'][idx] = subg.ndata['g'][idx]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([88, 1, 1, 28, 28])\n",
      "torch.Size([88, 2])\n"
     ]
    }
   ],
   "source": [
    "print(subg.ndata['ft'].size())\n",
    "print(subg.ndata['ft_size'].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ft: \n",
      "zeros -  [46, 47, 49, 57, 65, 72, 73, 75]\n",
      "nonzeros -  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 48, 50, 51, 52, 53, 54, 55, 56, 58, 59, 60, 61, 62, 63, 64, 66, 67, 68, 69, 70, 71, 74, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87]\n",
      "h: \n",
      "zeros -  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 46, 47, 49, 57, 65, 72, 73, 75]\n",
      "nonzeros -  [32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 48, 50, 51, 52, 53, 54, 55, 56, 58, 59, 60, 61, 62, 63, 64, 66, 67, 68, 69, 70, 71, 74, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87]\n",
      "ft_size: \n",
      "zeros -  []\n",
      "nonzeros -  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87]\n",
      "g: \n",
      "zeros -  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31]\n",
      "nonzeros -  [32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87]\n"
     ]
    }
   ],
   "source": [
    "def print_zeros_in_feat(key):\n",
    "    print(key + \": \")\n",
    "    zeros = []\n",
    "    nonzero = []\n",
    "    for id in subg.nodes():\n",
    "        id = int(id)\n",
    "        feat = subg.nodes[id].data[key]\n",
    "        if torch.eq(feat, torch.zeros(feat.size()).to(\"cuda\")).all() == True:\n",
    "            zeros.append(id)\n",
    "        else:\n",
    "            nonzero.append(id)\n",
    "    print(\"zeros - \", zeros)\n",
    "    print(\"nonzeros - \", nonzero)\n",
    "\n",
    "print_zeros_in_feat('ft')\n",
    "print_zeros_in_feat('h')\n",
    "print_zeros_in_feat('ft_size')\n",
    "print_zeros_in_feat('g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([7., 7.], device='cuda:0') 7 7\n",
      "tensor([[ 1.7792,  0.0000,  0.0000,  0.0000,  0.0000,  1.1611,  6.6959],\n",
      "        [ 5.1518,  1.1776,  0.0000,  3.3811,  9.1028,  5.7674,  7.4037],\n",
      "        [ 5.1297,  6.2894,  0.0000, 12.7424, 16.8882,  6.2509,  0.0445],\n",
      "        [ 1.4539,  8.4813,  6.2850,  0.0000,  8.7977, 20.9802,  0.1473],\n",
      "        [ 1.3156,  0.3564,  0.0000,  0.0000,  9.1116, 21.8856,  0.0572],\n",
      "        [ 2.9410,  0.0000,  2.2457, 11.6646,  9.9770,  7.0505,  0.0000],\n",
      "        [ 4.3832,  0.1667,  6.2607,  7.3015,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "size = subg.ndata['ft_size'][87]\n",
    "w, h = size\n",
    "\n",
    "w, h = int(w), int(h)\n",
    "\n",
    "print(size, w, h)\n",
    "\n",
    "res = unpadding(subg.ndata['ft'][85].reshape(28, 28), w, h)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt = 0\n",
    "ft_list = []\n",
    "for f,s in zip(subg.ndata['ft'], subg.ndata['ft_size']):\n",
    "    w, h = s\n",
    "    w, h = int(w), int(h)\n",
    "    data = unpadding(f.reshape(28, 28), w, h)\n",
    "    # print(w, h, cnt)\n",
    "    ft_list.append(data)\n",
    "    np.savetxt(\"./intermediate_data/graph_results/node-%d.csv\" % cnt, data.cpu(), delimiter=',')\n",
    "    cnt += 1\n",
    "\n",
    "cnt = 0\n",
    "cnn_params = None \n",
    "with open(\"./intermediate_data/params.json\", \"r\") as f:\n",
    "    cnn_params = json.load(f)\n",
    "from torch.nn.functional import relu\n",
    "from utils_gnn import unpadding\n",
    "conv1 = torch.tensor(cnn_params['conv1'])\n",
    "conv2 = torch.tensor(cnn_params['conv2'])\n",
    "conv3 = torch.tensor(cnn_params['conv3'])\n",
    "conv4 = torch.tensor(cnn_params['conv4'])\n",
    "l = [conv1, conv2, conv3, conv4]\n",
    "neural_list = []\n",
    "for layer in l:\n",
    "    for neural in layer[0]:\n",
    "        neural_list.append(neural)\n",
    "        np.savetxt(\"./intermediate_data/model_results/node-%d.csv\" % cnt, neural.cpu(), delimiter=',')\n",
    "        cnt += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0000,  0.9805,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000, 16.5474, 34.7467, 25.6497, 23.0430, 23.0015, 12.2277],\n",
      "        [ 0.0000,  2.5368, 39.6762, 26.9853,  3.7355,  4.5688,  4.2940],\n",
      "        [ 0.0000,  0.0000,  4.3969, 28.0040, 25.0063,  0.0000,  0.2286],\n",
      "        [ 0.0000,  0.0000,  0.0000, 11.7499, 20.8333, 16.8679,  1.9555],\n",
      "        [ 8.7424, 24.6951, 27.1628, 18.3077, 18.5936, 10.5977,  0.9699],\n",
      "        [ 0.0000, 10.9583, 13.3883,  5.1577,  0.0000,  0.0000,  0.2703]],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# add message transmitted ndata to original graph \n",
    "g.ndata['ft'][:len(subg.ndata['ft'])] = subg.ndata['ft']\n",
    "g.ndata['ft_size'][:len(subg.ndata['ft_size'])] = subg.ndata['ft_size']\n",
    "print(unpadding(g.ndata['ft'][87].reshape(28, 28), 7, 7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([88, 89, 90], device='cuda:0')\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 4, 5, 6],\n",
      "       device='cuda:0')\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# split full connected neurals\n",
    "def neural_fc_nodes(nodes):\n",
    "    layer_mask = nodes.data['layer_type'] == 1\n",
    "    layer_idxs = nodes.data['layer_idx'][layer_mask]\n",
    "    n = layer_idxs[0] \n",
    "    return nodes.data['layer_idx'] >= n\n",
    "fc_nodes = g.filter_nodes(neural_fc_nodes)\n",
    "print(fc_nodes)\n",
    "print(g.ndata['layer_idx'])\n",
    "print(g.ndata['layer_type'])\n",
    "subfcg = dgl.node_subgraph(g, fc_nodes, relabel_nodes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_fc_feat(data):\n",
    "    # data shape = (1, n)\n",
    "    data = padding(data, 1, 23 * 23)\n",
    "    ret = torch.zeros([23, 1, 23]).to(\"cuda\")\n",
    "    start = 0\n",
    "    end = 23\n",
    "    idx = 0\n",
    "    while end <= 23 * 23:\n",
    "        cur_data = data[0][start:end]\n",
    "        ret[idx] = cur_data.view(1, 23)\n",
    "        idx += 1\n",
    "        start += 23 \n",
    "        end += 23\n",
    "    # reshape (23, 1, 23) to (1, 1, 28, 28)\n",
    "    ret = padding(ret.reshape(23, 23), 28, 28)\n",
    "    return ret.reshape(1, 1, 28, 28)\n",
    "\n",
    "def  decode_fc_feat(data, n):\n",
    "    # data shape = (1, 1, 28, 28)\n",
    "    ret = unpadding(data.reshape(28, 28), 23, 23) # (23, 23)\n",
    "    ret = torch.cat([ret[i] for i in range(len(ret))]) # (23*23)\n",
    "    ret = ret.reshape(1, 23*23)\n",
    "    ret = unpadding(ret, 1, n)\n",
    "    return ret\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear params:  392 512\n",
      "torch.Size([512, 392]) torch.Size([512, 392])\n",
      "data size:  torch.Size([8, 7, 7]) torch.Size([1, 392])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from torch.nn.parameter import Parameter\n",
    "# get conv feat before first fc layer \n",
    "def get_fc_first_ft(g):\n",
    "    def neural_nodes_before_fc(nodes):\n",
    "        layer_mask = nodes.data['layer_type'] == 1\n",
    "        layer_idxs = nodes.data['layer_idx'][layer_mask]\n",
    "        n = layer_idxs[0] \n",
    "        return nodes.data['layer_idx'] == n - 1 \n",
    "    pre_nodes_idx = g.filter_nodes(neural_nodes_before_fc)\n",
    "    # print(pre_nodes_idx)\n",
    "    # get feats and reshape to (1, channels, width, height)\n",
    "    prefg = dgl.node_subgraph(g, pre_nodes_idx, relabel_nodes=True)\n",
    "    pre_feats = prefg.ndata['ft']\n",
    "    # (8, 1, 1, 28, 28)\n",
    "    # print(pre_feats.shape)\n",
    "    n_pre_nodes = len(pre_nodes_idx)\n",
    "    shape = prefg.ndata['ft_size'][0]\n",
    "    w, h = shape\n",
    "    w, h = int(w), int(h)\n",
    "    del prefg\n",
    "    # reshape to (1, 8, 7, 7)\n",
    "    feats = torch.zeros([n_pre_nodes, w, h])\n",
    "    for idx in range(n_pre_nodes):\n",
    "        cur_data = pre_feats[idx]\n",
    "        cur_data = cur_data.reshape(28, 28)\n",
    "        res_data = unpadding(cur_data, w, h)\n",
    "        # print(\"res_data size:\", res_data.size())\n",
    "        feats[idx] = res_data\n",
    "    data = feats\n",
    "    # print(\"data size: \", data.shape)\n",
    "\n",
    "    # concat weight\n",
    "    def neural_concat_nodes(nodes):\n",
    "        layer_mask = nodes.data['layer_type'] == 1\n",
    "        layer_idxs = nodes.data['layer_idx'][layer_mask]\n",
    "        n = layer_idxs[0] \n",
    "        return nodes.data['layer_idx'] == n\n",
    "    n = g.filter_nodes(neural_concat_nodes)\n",
    "    n = int(n)\n",
    "    # print(n, g.ndata['kernel_size'][n])\n",
    "    in_dim = g.ndata['kernel_size'][n][1]\n",
    "    out_dim = g.ndata['kernel_size'][n][2]\n",
    "    in_dim, out_dim = int(in_dim), int(out_dim)\n",
    "    # print(n, \" in_dim:\", in_dim, \" out_dim:\", out_dim)\n",
    "    fc_concat_weight = g.ndata['kernel_weight'][n]\n",
    "    # reshape fc weight to (in_dim, out_dim)\n",
    "    fc_concat_weight = unpadding(fc_concat_weight, in_dim, out_dim).t()\n",
    "    # bias\n",
    "    fc_concat_bias = g.ndata['bias'][n]\n",
    "    bias_size = g.ndata['bias_size'][n]\n",
    "    # print(bias_size)\n",
    "    r, c = bias_size\n",
    "    r, c = int(r), int(c)\n",
    "    # reshape\n",
    "    # print(fc_concat_bias.shape)\n",
    "    fc_concat_bias = unpadding(fc_concat_bias, r, c)\n",
    "    # init fc layer\n",
    "    # print(\"Linear params: \", in_dim, out_dim)\n",
    "    concat_opt = torch.nn.Linear(in_dim, out_dim)\n",
    "    # print(concat_opt.weight.data.shape, fc_concat_weight.shape)\n",
    "    concat_opt.weight = Parameter(fc_concat_weight)\n",
    "    concat_opt.bias.data = Parameter(fc_concat_bias.reshape(512))\n",
    "\n",
    "    # do concat\n",
    "    # print(\"data size: \", data.shape, data.view(1, in_dim).shape)\n",
    "    fc_concat_result = torch.nn.functional.relu(concat_opt(data.view(1, in_dim).to(\"cuda\")))\n",
    "    shape = fc_concat_result.size()\n",
    "    r, c = shape\n",
    "    r, c = int(r), int(c)\n",
    "    return n, fc_concat_result, r, c\n",
    "\n",
    "n, fc_concat_result, r, c = get_fc_first_ft(g)\n",
    "# set init fc feat\n",
    "g.ndata['ft'][n] = encode_fc_feat(fc_concat_result)\n",
    "g.ndata['ft_size'][n] = torch.tensor([r, c], dtype=torch.float32).to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_linear_opt(nodes, idx, data, size):\n",
    "    # prepare weight\n",
    "    in_dim = nodes.data['kernel_size'][idx][1]\n",
    "    out_dim = nodes.data['kernel_size'][idx][2]\n",
    "    in_dim, out_dim = int(in_dim), int(out_dim)\n",
    "    weight = nodes.data['kernel_weight'][idx]\n",
    "    # (out_dim, in_dim) for calculation optimization\n",
    "    weight = unpadding(weight, in_dim, out_dim).t()\n",
    "    # prepare bias\n",
    "    bias_size = nodes.data['bias_size'][idx]\n",
    "    r, c = bias_size\n",
    "    r, c = int(r), int(c)\n",
    "    bias = nodes.data['bias'][idx] # (1, 512) -> (r, c)\n",
    "    bias = unpadding(bias, r, c)\n",
    "    # prepare Linear layer\n",
    "    fc_opt = torch.nn.Linear(in_dim, out_dim)\n",
    "    fc_opt.weight = Parameter(weight)\n",
    "    fc_opt.bias = Parameter(bias.reshape(c))\n",
    "    # prepare data (1, 1, 28, 28) -> (1, n)\n",
    "    _, n = size[0]\n",
    "    data = decode_fc_feat(data, n)\n",
    "\n",
    "    # do Linear operation\n",
    "    ret = torch.nn.functional.relu(fc_opt(data.view(1, in_dim).to(\"cuda\")))\n",
    "    return ret\n",
    "\n",
    "\n",
    "def my_fc_message(edges):\n",
    "    return {'mf': edges.src['ft'], 'ms': edges.src['ft_size']}\n",
    "def my_fc_reduce(nodes):\n",
    "    mfeat = nodes.mailbox['mf']\n",
    "    msize = nodes.mailbox['ms']\n",
    "    \n",
    "    n_nodes = len(mfeat)\n",
    "    ret_ft = torch.zeros((n_nodes, 1, 1, 28, 28)).to(\"cuda\")\n",
    "    ret_size = torch.zeros((n_nodes, 2)).to(\"cuda\") \n",
    "\n",
    "    for out_idx in range(n_nodes):\n",
    "        received_data = mfeat[out_idx]\n",
    "        received_size = msize[out_idx]\n",
    "\n",
    "        # skip if all zeros, that is not transformed\n",
    "        if equals(received_size, zeros=True):\n",
    "            continue\n",
    "        # do Linear opt \n",
    "        ret = do_linear_opt(nodes, out_idx, received_data, received_size)\n",
    "        np.savetxt(\"./intermediate_data/process/ret_fc_ft-%d.csv\" % out_idx, ret.cpu().numpy(), delimiter=',')\n",
    "\n",
    "        shape = ret.size()\n",
    "        r, c = shape\n",
    "        r, c = int(r), int(c)\n",
    "\n",
    "        # set ret feat\n",
    "        ret_ft[out_idx] = encode_fc_feat(ret)\n",
    "        ret_size[out_idx] = torch.tensor([r, c], dtype=torch.float32).to(\"cuda\")\n",
    "    return {'h': ret_ft, 'g':ret_size}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    while equals(subfcg.ndata['ft_size'][-1], zeros=True):\n",
    "        subfcg.update_all(my_fc_message, my_fc_reduce)\n",
    "        for idx in range(len(subfcg.ndata['ft'])):\n",
    "            if equals(subfcg.ndata['ft'][idx], zeros=True):\n",
    "                subfcg.ndata['ft'][idx] = subfcg.ndata['h'][idx]\n",
    "            if equals(subfcg.ndata['ft_size'][idx], zeros=True):\n",
    "                subfcg.ndata['ft_size'][idx] = subfcg.ndata['g'][idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ft: \n",
      "zeros -  []\n",
      "nonzeros -  [0, 1, 2]\n",
      "h: \n",
      "zeros -  [0]\n",
      "nonzeros -  [1, 2]\n",
      "ft_size: \n",
      "zeros -  []\n",
      "nonzeros -  [0, 1, 2]\n",
      "g: \n",
      "zeros -  [0]\n",
      "nonzeros -  [1, 2]\n"
     ]
    }
   ],
   "source": [
    "def print_zeros_in_feat(key):\n",
    "    print(key + \": \")\n",
    "    zeros = []\n",
    "    nonzero = []\n",
    "    for id in subfcg.nodes():\n",
    "        id = int(id)\n",
    "        feat = subfcg.nodes[id].data[key]\n",
    "        if torch.eq(feat, torch.zeros(feat.size()).to(\"cuda\")).all() == True:\n",
    "            zeros.append(id)\n",
    "        else:\n",
    "            nonzero.append(id)\n",
    "    print(\"zeros - \", zeros)\n",
    "    print(\"nonzeros - \", nonzero)\n",
    "\n",
    "print_zeros_in_feat('ft')\n",
    "print_zeros_in_feat('h')\n",
    "print_zeros_in_feat('ft_size')\n",
    "print_zeros_in_feat('g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 512]) torch.Size([1, 128])\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "cnn_params = None \n",
    "with open(\"./intermediate_data/params.json\", \"r\") as f:\n",
    "    cnn_params = json.load(f)\n",
    "\n",
    "fc1 = torch.tensor(cnn_params['fc1']).to(\"cuda\")\n",
    "fc2 = torch.tensor(cnn_params['fc2'])\n",
    "print(fc1.shape, fc2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([7, 7]) torch.Size([1, 8, 7, 7])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-97aeb07688de>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# compare fc1 out\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconv4\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"is input the same:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mequals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconv4\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconcat_opt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"is the fc1 weight the same:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mequals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconcat_opt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Meta-Nerual-Trojan-Detection/utils_gnn.py\u001b[0m in \u001b[0;36mequals\u001b[0;34m(x, y, zeros, precision)\u001b[0m\n\u001b[1;32m    504\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cuda\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    505\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 506\u001b[0;31m     \u001b[0mcmp_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    507\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcmp_results\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mprecision\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    508\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!"
     ]
    }
   ],
   "source": [
    "# compare fc1 out\n",
    "print(data.shape, conv4.shape)\n",
    "print(\"is input the same:\", equals(data, conv4.reshape(8, 7, 7)))\n",
    "print(concat_opt.weight.shape, model.fc1.weight.shape)\n",
    "print(\"is the fc1 weight the same:\", equals(concat_opt.weight, model.fc1.weight))\n",
    "print((fc_concat_weight == model.fc1.weight).all() == True)\n",
    "print(fc_concat_bias.shape, model.fc1.bias.shape)\n",
    "print(\"is the fc1 bias the same:\", equals(fc_concat_bias.reshape(512), model.fc1.bias))\n",
    "print((fc_concat_bias == model.fc1.bias).all() == True)\n",
    "print(fc_concat_result.shape, fc1.shape)\n",
    "print(\"is the output the same:\", equals(fc_concat_result, fc1))\n",
    "print((fc_concat_result == fc1).all() == True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 128]) torch.Size([1, 128])\n",
      "is fc2 out the same: True\n"
     ]
    }
   ],
   "source": [
    "# compare fc2 out\n",
    "data = subfcg.ndata['ft'][-2]\n",
    "_, n = subfcg.ndata['ft_size'][-2]\n",
    "data = decode_fc_feat(data, n)\n",
    "print(data.shape, fc2.shape)\n",
    "print(\"is fc2 out the same:\", equals(data.cpu(), fc2, precision=1e-5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 10]) torch.Size([1, 10])\n",
      "is output layer out the same: True\n"
     ]
    }
   ],
   "source": [
    "# compare output layer out\n",
    "data = subfcg.ndata['ft'][-1]\n",
    "_, n = subfcg.ndata['ft_size'][-1]\n",
    "data = decode_fc_feat(data, n)\n",
    "ret, _ = model(image)\n",
    "print(data.shape, ret.shape)\n",
    "print(\"is output layer out the same:\", equals(data, torch.nn.functional.relu(ret), precision=1e-4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "g.ndata['ft'][-len(subfcg.ndata['ft']):] = subfcg.ndata['ft']\n",
    "g.ndata['ft_size'][-len(subfcg.ndata['ft_size']):] = subfcg.ndata['ft_size']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all equals\n"
     ]
    }
   ],
   "source": [
    "for idx in range(len(g.ndata['ft'])):\n",
    "    g_ft = g.ndata['ft'][idx]\n",
    "    g_ft_size = g.ndata['ft_size'][idx]\n",
    "    if idx < len(subg.ndata['ft']):\n",
    "       m_ft = subg.ndata['ft'][idx]\n",
    "       m_ft_size = subg.ndata['ft_size'][idx]\n",
    "    else:\n",
    "       m_ft = subfcg.ndata['ft'][idx-len(subg.ndata['ft'])]\n",
    "       m_ft_size = subfcg.ndata['ft_size'][idx-len(subg.ndata['ft'])]\n",
    "    if not equals(g_ft, m_ft):\n",
    "        print(\"feature not equals\")\n",
    "    if not equals(g_ft_size, m_ft_size):\n",
    "        print(\"feature size not equals\")\n",
    "else:\n",
    "    print(\"all equals\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0000,  0.0000,  2.1183, 18.8971,  7.8918, 11.7048,  0.0000,  0.0000,\n",
      "          0.0000,  5.8714]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0000,  0.0000,  2.1183, 18.8971,  7.8918, 11.7048,  0.0000,  0.0000,\n",
      "          0.0000,  5.8714]], device='cuda:0', grad_fn=<ReluBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(torch.nn.functional.relu(ret))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def activation_passing(img, g):\n",
    "    # init ft feature on first conv layer and get conv subg\n",
    "    with torch.no_grad():\n",
    "        initiate_node_feature(g, img)\n",
    "    \n",
    "    def neural_conv_nodes(nodes):\n",
    "        return nodes.data['layer_type'] == 0\n",
    "    nodes_idx = g.filter_nodes(neural_conv_nodes)\n",
    "    subg = dgl.node_subgraph(g, nodes_idx, relabel_nodes=True)\n",
    "    # message passing on conv layers\n",
    "    with torch.no_grad():\n",
    "        # 当最后一个节点尚未传播到的时候，继续执行传播操作\n",
    "        while equals(subg.ndata['ft_size'][-1], zeros=True):\n",
    "            subg.update_all(my_message, my_reduce)\n",
    "            for idx in range(len(subg.ndata['ft'])):\n",
    "                if equals(subg.ndata['ft'][idx], zeros=True):\n",
    "                    subg.ndata['ft'][idx] = subg.ndata['h'][idx]\n",
    "                if equals(subg.ndata['ft_size'][idx], zeros=True):\n",
    "                    subg.ndata['ft_size'][idx] = subg.ndata['g'][idx]\n",
    "    # add message passing ndata on conv layers to original graph \n",
    "    g.ndata['ft'][:len(subg.ndata['ft'])] = subg.ndata['ft']\n",
    "    g.ndata['ft_size'][:len(subg.ndata['ft_size'])] = subg.ndata['ft_size']\n",
    "    # get fc subg \n",
    "    def neural_fc_nodes(nodes):\n",
    "        layer_mask = nodes.data['layer_type'] == 1\n",
    "        layer_idxs = nodes.data['layer_idx'][layer_mask]\n",
    "        n = layer_idxs[0] \n",
    "        return nodes.data['layer_idx'] >= n\n",
    "    fc_nodes = g.filter_nodes(neural_fc_nodes)\n",
    "    subfcg = dgl.node_subgraph(g, fc_nodes, relabel_nodes=True)\n",
    "    # init ft on first fc layer\n",
    "    n, fc_concat_result, r, c = get_fc_first_ft(g)\n",
    "    g.ndata['ft'][n] = encode_fc_feat(fc_concat_result)\n",
    "    g.ndata['ft_size'][n] = torch.tensor([r, c], dtype=torch.float32).to(\"cuda\")\n",
    "    # message passing on fc layers \n",
    "    with torch.no_grad():\n",
    "        while equals(subfcg.ndata['ft_size'][-1], zeros=True):\n",
    "            subfcg.update_all(my_fc_message, my_fc_reduce)\n",
    "            for idx in range(len(subfcg.ndata['ft'])):\n",
    "                if equals(subfcg.ndata['ft'][idx], zeros=True):\n",
    "                    subfcg.ndata['ft'][idx] = subfcg.ndata['h'][idx]\n",
    "                if equals(subfcg.ndata['ft_size'][idx], zeros=True):\n",
    "                    subfcg.ndata['ft_size'][idx] = subfcg.ndata['g'][idx]\n",
    "    # add message passing ndata on fc layers to original graph\n",
    "    g.ndata['ft'][-len(subfcg.ndata['ft']):] = subfcg.ndata['ft']\n",
    "    g.ndata['ft_size'][-len(subfcg.ndata['ft_size']):] = subfcg.ndata['ft_size']\n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear params:  392 512\n",
      "torch.Size([512, 392]) torch.Size([512, 392])\n",
      "data size:  torch.Size([8, 7, 7]) torch.Size([1, 392])\n",
      "torch.Size([1, 10]) torch.Size([1, 10])\n",
      "0\n",
      "Linear params:  392 512\n",
      "torch.Size([512, 392]) torch.Size([512, 392])\n",
      "data size:  torch.Size([8, 7, 7]) torch.Size([1, 392])\n",
      "torch.Size([1, 10]) torch.Size([1, 10])\n",
      "1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-50-77373bffcdda>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m \u001b[0mtest_activation_passing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-50-77373bffcdda>\u001b[0m in \u001b[0;36mtest_activation_passing\u001b[0;34m()\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0mmodel_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m         \u001b[0mpassed_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mactivation_passing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m         \u001b[0mgraph_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpassed_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ft'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpassed_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ft_size'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-48-2267d236581f>\u001b[0m in \u001b[0;36mactivation_passing\u001b[0;34m(img, g)\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;31m# 当最后一个节点尚未传播到的时候，继续执行传播操作\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mequals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ft_size'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzeros\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m             \u001b[0msubg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmy_message\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmy_reduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ft'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mequals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ft'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzeros\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/envs/mntd/lib/python3.6/site-packages/dgl/heterograph.py\u001b[0m in \u001b[0;36mupdate_all\u001b[0;34m(self, message_func, reduce_func, apply_node_func, etype)\u001b[0m\n\u001b[1;32m   4893\u001b[0m             \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetagraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_edge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4894\u001b[0m             \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0metype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4895\u001b[0;31m             \u001b[0mndata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage_passing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapply_node_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4896\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_builtin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduce_func\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mreduce_func\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'min'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'max'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mndata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4897\u001b[0m                 \u001b[0;31m# Replace infinity with zero for isolated nodes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/envs/mntd/lib/python3.6/site-packages/dgl/core.py\u001b[0m in \u001b[0;36mmessage_passing\u001b[0;34m(g, mfunc, rfunc, afunc)\u001b[0m\n\u001b[1;32m    370\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    371\u001b[0m             \u001b[0morig_nid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdstdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNID\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 372\u001b[0;31m             \u001b[0mndata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minvoke_udf_reduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsgdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morig_nid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morig_nid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    373\u001b[0m     \u001b[0;31m# apply phase\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    374\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mafunc\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/envs/mntd/lib/python3.6/site-packages/dgl/core.py\u001b[0m in \u001b[0;36minvoke_udf_reduce\u001b[0;34m(graph, func, msgdata, orig_nid)\u001b[0m\n\u001b[1;32m    141\u001b[0m         \u001b[0;31m# invoke udf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m         \u001b[0mnbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNodeBatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morig_nid_bkt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mntype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mndata_bkt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsgs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmaildata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m         \u001b[0mbkt_rsts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[0;31m# prepare a result frame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-23-1b98dcf270d6>\u001b[0m in \u001b[0;36mmy_reduce\u001b[0;34m(nodes)\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0mconv_opt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkernel_weight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0mconv_opt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkernel_bias\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkernel_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"./intermediate_data/process/kernel_weight.pt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msavetxt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./intermediate_data/process/kernel-bias-%d.csv\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mout_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mkernel_bias\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;31m# print(\"kernel weight size:\", kernel_weight.size(), kernel_size)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/envs/mntd/lib/python3.6/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization)\u001b[0m\n\u001b[1;32m    374\u001b[0m     \u001b[0m_check_dill_version\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpickle_module\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 376\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    377\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_use_new_zipfile_serialization\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0m_open_zipfile_writer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/envs/mntd/lib/python3.6/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'w'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/envs/mntd/lib/python3.6/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_open_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def test_activation_passing():\n",
    "    def get_model():\n",
    "        x = './shadow_model_ckpt/mnist/models5/shadow_jumbo_0.model'\n",
    "        # load model \n",
    "        # Model = load_spec_model(father_model, '5')\n",
    "        from model_lib.mnist_cnn_model import Model6 as Model\n",
    "        model = Model(gpu=True)\n",
    "        params = torch.load(x)\n",
    "        model.load_state_dict(params)\n",
    "        del params\n",
    "        return model\n",
    "    def get_graph():\n",
    "        # load model detail \n",
    "        model_detail = {}\n",
    "        model_detail_path = \"./intermediate_data/model_detail.json\"\n",
    "        import json\n",
    "        with open(model_detail_path, 'r') as f:\n",
    "            model_detail = json.load(f)\n",
    "        # print(model_detail)\n",
    "        g = cnn2graph_activation(model, model_detail['mnist']['5'])\n",
    "        dgl.save_graphs('./intermediate_data/grapj_test.bin', g)\n",
    "        del model_detail\n",
    "        return g \n",
    "    def get_image_dataset():\n",
    "        # from utils_gnn import SGNACT\n",
    "        GPU = True\n",
    "        if GPU:\n",
    "                torch.cuda.manual_seed_all(0)\n",
    "                torch.backends.cudnn.deterministic = True\n",
    "                torch.backends.cudnn.benchmark = False\n",
    "                \n",
    "        transform = transforms.Compose([\n",
    "                    transforms.ToTensor(),\n",
    "                ])\n",
    "        BATCH_SIZE = 1\n",
    "        # MNIST image dataset \n",
    "        trainset = torchvision.datasets.MNIST(root='./raw_data/', train=True, download=True, transform=transform)\n",
    "        dataloader = torch.utils.data.DataLoader(trainset, batch_size=BATCH_SIZE)\n",
    "        return dataloader\n",
    "    model = get_model()\n",
    "    g = get_graph()\n",
    "    dataloader = get_image_dataset()\n",
    "    for i, (x_in, y_in) in enumerate(dataloader):\n",
    "        img = x_in\n",
    "        label = y_in\n",
    "\n",
    "        model_result, _ = model(img)\n",
    "        passed_graph = activation_passing(img, g)\n",
    "        graph_result = passed_graph.ndata['ft'][-1]\n",
    "        _, n = passed_graph.ndata['ft_size'][-1]\n",
    "        relu = torch.nn.functional.relu\n",
    "        graph_result = relu(decode_fc_feat(graph_result, n))\n",
    "        assert equals(model_result, graph_result), \"output diffs: %d pic\" % i\n",
    "        if i > 100:\n",
    "            break\n",
    "\n",
    "test_activation_passing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.13 ('mntd')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2d7768e61f5674adf4efa61c7b8cc3ee2c06ae8f502b5df709cd3e31381a4347"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
