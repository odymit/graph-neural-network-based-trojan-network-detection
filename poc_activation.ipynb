{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# POC 激活验证"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 同构激活图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dorian/.conda/envs/mntd/lib/python3.6/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model5(\n",
      "  (conv1): Conv2d(1, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (conv2): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (conv3): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv4): Conv2d(16, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (max_pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc1): Linear(in_features=392, out_features=512, bias=True)\n",
      "  (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
      "  (output): Linear(in_features=128, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "params = torch.load('./shadow_model_ckpt/mnist/models5/shadow_benign_0.model')\n",
    "from model_lib.mnist_cnn_model import Model5 as Model\n",
    "m = Model()\n",
    "m.load_state_dict(params)\n",
    "print(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dgl\n",
    "import torch\n",
    "from model_lib.hetero_struct_backdoor_dataset import HeteroStrucBackdoorDataset\n",
    "from utils_gnn import all_u_to_v\n",
    "\n",
    "\n",
    "def cnn2graph_activation(model, model_info):\n",
    "    # convert cnn model to a dgl graph\n",
    "    # model: model weight data\n",
    "    # model_info: model struct info\n",
    "    \n",
    "    layers = []\n",
    "    all_edges = []\n",
    "\n",
    "\n",
    "    node_layer_idx = []\n",
    "    all_node_feats = []\n",
    "    pre_node_size = []\n",
    "    node_params = []\n",
    "    all_bias_feats = []\n",
    "    pre_bias_size = []\n",
    "    node_layer_num = []\n",
    "\n",
    "    pooling = []\n",
    "    \n",
    "    input_layer = True\n",
    "    concat_layer = True\n",
    "    idx = 0\n",
    "    cnt = 0\n",
    "    with torch.no_grad():\n",
    "        for i in range(len(model_info)):\n",
    "            cur_layer_info = model_info[i]\n",
    "            pooling_info = cur_layer_info['maxpool']\n",
    "            print(pooling_info)\n",
    "            cur_layer_node = []\n",
    "            if not input_layer and idx == 0:\n",
    "                idx += 1\n",
    "            if input_layer:\n",
    "                input_layer = False\n",
    "            if 'conv' in cur_layer_info['name']:\n",
    "                # construct cur layer nodes\n",
    "                for weight, bias in zip(model.get_submodule(cur_layer_info['name']).weight, \n",
    "                                        model.get_submodule(cur_layer_info['name']).bias):\n",
    "                    # print(\"cur layer info:\", model.get_submodule(cur_layer_info['name']))\n",
    "                    cur_layer_node.append(cnt)\n",
    "                    cnt += 1\n",
    "                    if pooling_info:\n",
    "                        pooling.append([pooling_info['kernel_size'], pooling_info['stride'],\n",
    "                        pooling_info['padding'], pooling_info['dilation'], int(pooling_info['ceil_mode'])])\n",
    "                    else:\n",
    "                        pooling.append([0, 0, 0, 0, 0])\n",
    "                    node_layer_idx.append(idx)\n",
    "                    node_layer_num.append(0)\n",
    "                    # params \n",
    "                    conv = model.get_submodule(cur_layer_info['name'])\n",
    "                    params = [conv.kernel_size, conv.stride, conv.padding]\n",
    "                    node_params.append(params)\n",
    "                    # print(params)\n",
    "                    # featue resize?\n",
    "                    w = weight[0]\n",
    "                    r, c = w.size()\n",
    "                    pre_node_size.append([r, c])\n",
    "                    all_node_feats.append(padding(w, 512, 512))\n",
    "                    b = bias.expand(1,1)\n",
    "                    r, c = b.size()\n",
    "                    # print(\"size:\", b.size())\n",
    "                    pre_bias_size.append([r, c])\n",
    "                    all_bias_feats.append(padding(b, 1, 512))\n",
    "                    # print(\"conv weight:\", w.shape)\n",
    "                    # bias\n",
    "                    # print(\"conv bias:\", bias)\n",
    "            else:\n",
    "                # construct dense layer node\n",
    "                pooling.append([0, 0, 0, 0, 0])\n",
    "                node_layer_num.append(1)\n",
    "                cur_layer_node.append(cnt)\n",
    "                cnt += 1\n",
    "                if concat_layer:\n",
    "                    idx += 1\n",
    "                    concat_layer = False\n",
    "                    node_layer_idx.append(idx)\n",
    "                    idx += 1\n",
    "                else:\n",
    "                    node_layer_idx.append(idx)\n",
    "                params = [(0, 0), (0, 0), (0, 0)]\n",
    "                node_params.append(params)\n",
    "                # feature resize?\n",
    "                weight = model.get_submodule(cur_layer_info['name']).weight.t()\n",
    "                bias = model.get_submodule(cur_layer_info['name']).bias\n",
    "                w = weight\n",
    "                r, c = w.size()\n",
    "                pre_node_size.append([r, c])\n",
    "                all_node_feats.append(padding(w, 512, 512))\n",
    "                b = bias.expand(1,-1)\n",
    "                r, c = b.size()\n",
    "                # print(\"size:\", b.size())\n",
    "                pre_bias_size.append([r, c])\n",
    "                all_bias_feats.append(padding(b, 1, 512))\n",
    "            layers.append(cur_layer_node)\n",
    "            \n",
    "    # get all edges\n",
    "    for idx in range(len(layers)):\n",
    "        if idx < len(layers) - 1:\n",
    "            edges = all_u_to_v(layers[idx], layers[idx+1])\n",
    "            all_edges += edges\n",
    "    \n",
    "    all_edges = torch.tensor(all_edges).t()\n",
    "    u, v = all_edges[0], all_edges[1]\n",
    "    g = dgl.graph((u,v)).to('cuda')\n",
    "    g.ndata['x'] = torch.stack(all_node_feats)\n",
    "    # tag for message transmission process\n",
    "    g.ndata['tag'] = torch.tensor(node_layer_idx).to('cuda')\n",
    "    # layer for layer type, 0 for conv, 1 for full connect\n",
    "    g.ndata['layer'] = torch.tensor(node_layer_num).to('cuda')\n",
    "    # acutal node size(kernel size or fc node size)\n",
    "    g.ndata['node_size'] = torch.tensor(pre_node_size).to('cuda')\n",
    "    # params for conv kernel params \n",
    "    g.ndata['params'] = torch.tensor(node_params).to('cuda')\n",
    "    # bias weight\n",
    "    g.ndata['bias'] = torch.stack(all_bias_feats)\n",
    "    # bias size\n",
    "    g.ndata['bias_size'] = torch.tensor(pre_bias_size).to('cuda')\n",
    "    # pooling params\n",
    "    g.ndata['pooling'] = torch.tensor(pooling).to('cuda')\n",
    "    \n",
    "    return g\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph(num_nodes=162, num_edges=5153,\n",
      "      ndata_schemes={'x': Scheme(shape=(512, 512), dtype=torch.float32), 'idx': Scheme(shape=(), dtype=torch.int64), 'node_size': Scheme(shape=(2,), dtype=torch.int64), 'params': Scheme(shape=(3, 2), dtype=torch.int64), 'bias': Scheme(shape=(1, 512), dtype=torch.float32), 'bias_size': Scheme(shape=(2,), dtype=torch.int64)}\n",
      "      edata_schemes={})\n"
     ]
    }
   ],
   "source": [
    "from dgl.dataloading import GraphDataLoader\n",
    "from dgl.heterograph import DGLHeteroGraph\n",
    "from model_lib.hetero_struct_backdoor_dataset import HeteroStrucBackdoorDataset\n",
    "import torch\n",
    "def test_hetero_activation():\n",
    "    dataset = HeteroStrucBackdoorDataset(nums=10,\n",
    "        raw_dir='/home/dorian/repos/Meta-Nerual-Trojan-Detection/shadow_model_ckpt/mnist/models', activation=True)\n",
    "    dataloader = GraphDataLoader(dataset, batch_size=1, pin_memory=torch.cuda.is_available())\n",
    "    for batch, (batched_graph, labels) in enumerate(dataloader):\n",
    "        assert batch == 0\n",
    "        assert isinstance(batched_graph, DGLHeteroGraph)\n",
    "        # assert batched_graph.ndata['idx'].any()\n",
    "        # assert batched_graph.ndata['node_size']\n",
    "        # assert batched_graph.ndata['params']\n",
    "        # assert batched_graph.ndata['bias']\n",
    "        # assert batched_graph.ndata['bias_size']\n",
    "        print(batched_graph)\n",
    "        break\n",
    "\n",
    "test_hetero_activation() \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 设计传播函数模拟神经网络传参\n",
    "- 图片分类网络结果  \n",
    "    - [x] 读取数据\n",
    "    - [x] 调用分类网络获得分类结果\n",
    "    - [x] 获取网络中间结果  \n",
    "- 设计传播函数  \n",
    "    - [ ] conv 层\n",
    "    - [ ] 全连接层\n",
    "    - [ ] 输出层获得分类结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from model_lib import mnist_cnn_model as father_model\n",
    "from utils_basic import load_spec_model\n",
    "from utils_gnn import padding\n",
    "x = '/home/dorian/repos/Meta-Nerual-Trojan-Detection/shadow_model_ckpt/mnist/models5/shadow_jumbo_9.model'\n",
    "# load model \n",
    "# Model = load_spec_model(father_model, '5')\n",
    "from model_lib.mnist_cnn_model import Model6 as Model\n",
    "model = Model(gpu=True)\n",
    "params = torch.load(x)\n",
    "model.load_state_dict(params)\n",
    "\n",
    "# load model detail \n",
    "# model_detail = {}\n",
    "# model_detail_path = \"./intermediate_data/model_detail.json\"\n",
    "# import json\n",
    "# with open(model_detail_path, 'r') as f:\n",
    "#     model_detail = json.load(f)\n",
    "# print(model_detail)\n",
    "# g = cnn2graph_activation(model, model_detail['mnist']['5'])\n",
    "# dgl.save_graphs('./intermediate_data/grapj_test.bin', g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "# from utils_gnn import SGNACT\n",
    "GPU = True\n",
    "if GPU:\n",
    "        torch.cuda.manual_seed_all(0)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "        \n",
    "transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "        ])\n",
    "BATCH_SIZE = 1\n",
    "# MNIST image dataset \n",
    "trainset = torchvision.datasets.MNIST(root='./raw_data/', train=True, download=True, transform=transform)\n",
    "dataloader = torch.utils.data.DataLoader(trainset, batch_size=BATCH_SIZE)\n",
    "\n",
    "from model_lib.hetero_struct_backdoor_dataset import HeteroStrucBackdoorDataset\n",
    "from dgl.dataloading import GraphDataLoader\n",
    "# Shadow model dataset\n",
    "dataset = HeteroStrucBackdoorDataset(nums=10,\n",
    "    raw_dir='/home/dorian/repos/Meta-Nerual-Trojan-Detection/shadow_model_ckpt/mnist/models', activation=True)\n",
    "model_dataloader = GraphDataLoader(dataset, batch_size=1, pin_memory=torch.cuda.is_available())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph(num_nodes=162, num_edges=5153,\n",
      "      ndata_schemes={'x': Scheme(shape=(512, 512), dtype=torch.float32), 'idx': Scheme(shape=(), dtype=torch.int64), 'node_size': Scheme(shape=(2,), dtype=torch.int64), 'params': Scheme(shape=(3, 2), dtype=torch.int64), 'bias': Scheme(shape=(1, 512), dtype=torch.float32), 'bias_size': Scheme(shape=(2,), dtype=torch.int64)}\n",
      "      edata_schemes={})\n",
      "tensor(3, device='cuda:0')\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'x'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-0de745b41a3c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0;31m# get calculation results on graph node\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcnn_cal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatched_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;31m# compare\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-0de745b41a3c>\u001b[0m in \u001b[0;36mcnn_cal\u001b[0;34m(graph)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcnn_cal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m     \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage_func\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmessage_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_func\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreduce_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m     \u001b[0mft\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ft'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mft\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/dorian/.conda/envs/mntd/lib/python3.6/site-packages/dgl/heterograph.py\u001b[0m in \u001b[0;36mupdate_all\u001b[0;34m(self, message_func, reduce_func, apply_node_func, etype)\u001b[0m\n\u001b[1;32m   4893\u001b[0m             \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetagraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_edge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4894\u001b[0m             \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0metype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4895\u001b[0;31m             \u001b[0mndata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage_passing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapply_node_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4896\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_builtin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduce_func\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mreduce_func\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'min'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'max'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mndata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4897\u001b[0m                 \u001b[0;31m# Replace infinity with zero for isolated nodes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/dorian/.conda/envs/mntd/lib/python3.6/site-packages/dgl/core.py\u001b[0m in \u001b[0;36mmessage_passing\u001b[0;34m(g, mfunc, rfunc, afunc)\u001b[0m\n\u001b[1;32m    363\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m             \u001b[0morig_eid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEID\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 365\u001b[0;31m             \u001b[0mmsgdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minvoke_edge_udf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mALL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanonical_etypes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morig_eid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morig_eid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    366\u001b[0m         \u001b[0;31m# reduce phase\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    367\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_builtin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/dorian/.conda/envs/mntd/lib/python3.6/site-packages/dgl/core.py\u001b[0m in \u001b[0;36minvoke_edge_udf\u001b[0;34m(graph, eid, etype, func, orig_eid)\u001b[0m\n\u001b[1;32m     83\u001b[0m     ebatch = EdgeBatch(graph, eid if orig_eid is None else orig_eid,\n\u001b[1;32m     84\u001b[0m                        etype, srcdata, edata, dstdata)\n\u001b[0;32m---> 85\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mebatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0minvoke_udf_reduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsgdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morig_nid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-0de745b41a3c>\u001b[0m in \u001b[0;36mmessage_func\u001b[0;34m(edges)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmessage_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0medges\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'pre'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0medges\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'x'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mreduce_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/dorian/.conda/envs/mntd/lib/python3.6/site-packages/dgl/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    620\u001b[0m             \u001b[0mColumn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    621\u001b[0m         \"\"\"\n\u001b[0;32m--> 622\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_columns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    623\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'x'"
     ]
    }
   ],
   "source": [
    "import dgl\n",
    "from dgl.data import DGLDataset\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from dgl import save_graphs, load_graphs\n",
    "import torch\n",
    "import json\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "# from model_lib.mnist_cnn_model import Model\n",
    "from random import randint\n",
    "from utils_basic import load_spec_model\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from torchinfo import summary\n",
    "import torch.nn.functional as F\n",
    "from dgl.nn.pytorch.conv import GINConv\n",
    "from dgl.nn.pytorch.glob import SumPooling, AvgPooling, MaxPooling, SortPooling\n",
    "from utils_gnn import MLP\n",
    "from utils_gnn import unpadding, padding\n",
    "\n",
    "\n",
    "def conv(data, weight, bias, kernel_size, stride, padding):\n",
    "    row, col = weight.size()\n",
    "    # get actual conv kernel weight and bias\n",
    "    w = unpadding(weight, kernel_size, kernel_size)\n",
    "    w = w.unsqueeze(0).unsqueeze(0)\n",
    "    b = unpadding(bias, 1, 1)[0]\n",
    "    # get conv operator \n",
    "    operator = torch.nn.Conv2d(1, 1, kernel_size=kernel_size, stride=stride,\n",
    "                    padding=padding)\n",
    "    # set conv operator weight and bias\n",
    "    operator.weight.data = w\n",
    "    operator.bias.data = b\n",
    "    # conduct conv operation\n",
    "    x = operator(data)\n",
    "    return padding(x[0][0], )\n",
    "\n",
    "def maxpool(kernel_size, stride, padding):\n",
    "    pass\n",
    "\n",
    "def message_func(edges):\n",
    "    print(\"this is message function.\")\n",
    "    print(\"message fucntion ends\")\n",
    "    return {'pre': edges.src['x']}\n",
    "\n",
    "def reduce_func(nodes):\n",
    "    print(\"this is reduce function\")\n",
    "    input_mask = nodes.data['tag'] == 0\n",
    "    conv_mask = nodes.data['tag'] == 1\n",
    "    concat_mask = nodes.data['tag'] == 2\n",
    "    fc_mask = nodes.data['tag'] == 3\n",
    "\n",
    "    # input_feat = nodes.data['x'][input_mask]\n",
    "    # print(input_feat)\n",
    "    print(\"reduce function ends\")\n",
    "    return {'pre': nodes.mailbox['pre']}\n",
    "\n",
    "\n",
    "def cnn_cal(graph):\n",
    "    graph.update_all(message_func=message_func, reduce_func=reduce_func)\n",
    "    ft = graph.ndata['ft'][0]\n",
    "    return ft\n",
    "\n",
    "model.eval()\n",
    "for batch, (batched_graph, labels) in enumerate(model_dataloader):\n",
    "    print(batched_graph)\n",
    "    feat = batched_graph.ndata.pop('x')\n",
    "    for i, (x_in, y_in) in enumerate(dataloader):\n",
    "        # print(x_in.size())\n",
    "        # get orginal cnn calculation resutls\n",
    "        pred, params = model(x_in)\n",
    "        print(torch.argmax(pred))\n",
    "        # get calculation results on graph node \n",
    "        res = cnn_cal(batched_graph)\n",
    "        # compare\n",
    "        break\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "254 253 254 253\n",
      "256 255 0 -1\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'int' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-1fa7f2fc2dea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mx_in\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_in\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cuda'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'x'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'bias'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-35-6a95ddf117b8>\u001b[0m in \u001b[0;36mconv\u001b[0;34m(data, weight, bias, kernel_size, stride, padding)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;31m# conduct conv operation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moperator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'int' object is not callable"
     ]
    }
   ],
   "source": [
    "x_in = x_in.to('cuda')\n",
    "x = conv(x_in, g.ndata['x'][0], g.ndata['bias'][0], 5, 1, 2)\n",
    "print(x.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256 255 0 -1\n"
     ]
    }
   ],
   "source": [
    "bias = g.ndata['bias'][0]\n",
    "b = unpadding(bias, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0161, device='cuda:0')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.conv1.bias.data.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.13 ('mntd')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7d504790743f38722d745ab54c6dcc5c590f96c5141b7c6566bf2e4e2b011705"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
