{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "\n",
    "# POC 激活验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import dgl\n",
    "import torch\n",
    "from utils_gnn import cnn2graph_activation\n",
    "# from model_lib import mnist_cnn_model as father_model\n",
    "from utils_basic import load_spec_model\n",
    "from utils_gnn import padding\n",
    "from dgl.data import DGLDataset\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from dgl import save_graphs, load_graphs\n",
    "import torch\n",
    "import json\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "# from model_lib.mnist_cnn_model import Model\n",
    "from random import randint\n",
    "from utils_basic import load_spec_model\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from torchinfo import summary\n",
    "import torch.nn.functional as F\n",
    "from dgl.nn.pytorch.conv import GINConv\n",
    "from dgl.nn.pytorch.glob import SumPooling, AvgPooling, MaxPooling, SortPooling\n",
    "from utils_gnn import MLP\n",
    "from utils_gnn import unpadding, padding\n",
    "\n",
    "# x = '/home/dorian/repos/Meta-Nerual-Trojan-Detection/shadow_model_ckpt/mnist/models5/shadow_jumbo_9.model'\n",
    "x = './shadow_model_ckpt/mnist/models5/shadow_jumbo_0.model'\n",
    "# load model \n",
    "# Model = load_spec_model(father_model, '5')\n",
    "from model_lib.mnist_cnn_model import Model6 as Model\n",
    "model = Model(gpu=True)\n",
    "params = torch.load(x)\n",
    "model.load_state_dict(params)\n",
    "del params\n",
    "\n",
    "# load model detail \n",
    "model_detail = {}\n",
    "model_detail_path = \"./intermediate_data/model_detail.json\"\n",
    "import json\n",
    "with open(model_detail_path, 'r') as f:\n",
    "    model_detail = json.load(f)\n",
    "# print(model_detail)\n",
    "g = cnn2graph_activation(model, model_detail['mnist']['5'])\n",
    "dgl.save_graphs('./intermediate_data/grapj_test.bin', g)\n",
    "del model_detail\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "# from utils_gnn import SGNACT\n",
    "GPU = True\n",
    "if GPU:\n",
    "        torch.cuda.manual_seed_all(0)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "        \n",
    "transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "        ])\n",
    "BATCH_SIZE = 1\n",
    "# MNIST image dataset \n",
    "trainset = torchvision.datasets.MNIST(root='./raw_data/', train=True, download=True, transform=transform)\n",
    "dataloader = torch.utils.data.DataLoader(trainset, batch_size=BATCH_SIZE)\n",
    "\n",
    "# get a image\n",
    "image = None\n",
    "label = None\n",
    "for i, (x_in, y_in) in enumerate(dataloader):\n",
    "    image = x_in\n",
    "    model(image)\n",
    "    label = y_in\n",
    "    break\n",
    "del trainset, dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# define the init process\n",
    "def init_conv(data, data_size, weight, bias, kernel_size, stride, padding):\n",
    "    row, col = weight.size()\n",
    "    # print(weight.size())\n",
    "    # get actual conv kernel weight and bias\n",
    "    w = unpadding(weight, kernel_size[0], kernel_size[1])\n",
    "    w = w.unsqueeze(0).unsqueeze(0)\n",
    "    b = unpadding(bias, 1, 1)[0]\n",
    "    # get conv operator \n",
    "    # print(\"kernel_size, stride, padding:\")\n",
    "    # print(kernel_size, stride, padding)\n",
    "    operator = torch.nn.Conv2d(1, 1, kernel_size=kernel_size, \n",
    "                    stride=stride, padding=padding)\n",
    "    # set conv operator weight and bias\n",
    "    operator.weight.data = w\n",
    "    operator.bias.data = b\n",
    "    # conduct conv operation\n",
    "    # print(\"conv input size:\", data.size())\n",
    "    x = operator(data.to(\"cuda\"))\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "# def maxpool(kernel_size, stride, padding):\n",
    "#     pass  \n",
    "\n",
    "# def message_func(edges):\n",
    "#     # print(\"this is message function.\")\n",
    "#     # print(\"message fucntion ends\")\n",
    "#     # print(\"edges src ft size:\", edges.src['ft'].size())\n",
    "#     return {'m': edges.src['ft']}\n",
    "#     # return {}\n",
    "\n",
    "\n",
    "# def reduce(nodes):\n",
    "#     # print(\"this is reduce function\")\n",
    "\n",
    "#     pre_data = nodes.mailbox['m']\n",
    "#     # print(\"mailbox data size:\", pre_data.size())\n",
    "#     ft = torch.zeros((1, 1, 28, 28)).to(\"cuda\")\n",
    "#     # print(\"nodes data size in reduce:\", ft.size())\n",
    "#     # print(\"nodes ft size:\", nodes.data['ft'].size())\n",
    "#     if pre_data.all() == 0:\n",
    "#         return {'h': torch.sum(pre_data, dim=1)}\n",
    "#     for i in range(len(pre_data)):\n",
    "#         # else do conv operation\n",
    "#         kernel_size, stride, padding = nodes.data['params'][i]\n",
    "\n",
    "#         res_ft = my_conv(pre_data[i][0], None, nodes.data['x'][i], nodes.data['bias'][i], kernel_size, stride, padding)\n",
    "#         # print(\"res_ft in reduce func:\", res_ft)\n",
    "#         ft += res_ft\n",
    "#     # print(\"size before and after:\", nodes.mailbox['m'].size(), ft.size())\n",
    "#     # print(\"reduce function ends\")\n",
    "#     return {'h': ft}\n",
    "\n",
    "\n",
    "def initiate_node_feature(graph, image):\n",
    "    ft = None \n",
    "    mask = graph.ndata['tag'] == 0\n",
    "    out_channels = int(sum(mask))\n",
    "    ft = torch.zeros((len(graph.nodes()), 1, 1, 28, 28))\n",
    "    convd_size = torch.zeros((len(graph.nodes()), 2))\n",
    "    for i in range(out_channels):\n",
    "        kernel_size, stride, padding = graph.ndata['params'][i]\n",
    "        # do conv\n",
    "        res_ft = init_conv(image, None, graph.ndata['x'][i], graph.ndata['bias'][i],\n",
    "                kernel_size, stride, padding)\n",
    "        # do relu\n",
    "        relu_opt = torch.nn.functional.relu\n",
    "        res_ft = relu_opt(res_ft)\n",
    "\n",
    "        # do max pooling\n",
    "        pooling = graph.ndata['pooling'][i]\n",
    "        if pooling.all() != 0:\n",
    "            # do max_pooling\n",
    "            kernel_size, stride, pad, dilation, ceil_mode = pooling\n",
    "            max_pooling_operator = torch.nn.MaxPool2d(kernel_size=kernel_size, stride=stride, \n",
    "                padding=pad, dilation=dilation, ceil_mode=ceil_mode)\n",
    "            \n",
    "            res_ft = max_pooling_operator(res_ft)\n",
    "        _, _, r, c = res_ft.size()\n",
    "        ft[i] = res_ft\n",
    "        convd_size[i] = torch.tensor([int(r), int(c)])\n",
    "    graph.ndata['ft'] = ft.to(\"cuda\")\n",
    "    graph.ndata['convd_size'] = convd_size.to(\"cuda\")\n",
    "\n",
    "\n",
    "# def conv_message_passing(graph):\n",
    "#     # get node id first, then get subgraph\n",
    "#     def nodes_feature_smaller_than_one(nodes):\n",
    "#         return nodes.data['tag'] <= 1\n",
    "    \n",
    "#     nodes_idx = graph.filter_nodes(nodes_feature_smaller_than_one)\n",
    "#     # print(\"in conv mp, nodes idx:\", nodes_idx)\n",
    "#     subg = dgl.node_subgraph(graph, nodes_idx)\n",
    "#     def conv_reduce_func():\n",
    "#         pass\n",
    "#     subg.update_all(dgl.function.copy_src('ft', 'm'))\n",
    "#     ft = subg.ndata['ft']\n",
    "\n",
    "# def cnn_cal(graph, image):\n",
    "#     initiate_node_feature(graph, image)\n",
    "#     # conv_message_passing(graph)\n",
    "#     # graph.update_all(message_func=message_func, reduce_func=reduce_func)\n",
    "#     #ft = graph.ndata['ft'][0]\n",
    "#     #return ft\n",
    "\n",
    "# import json\n",
    "# # get cnn results\n",
    "# pred, params = model(x_in)\n",
    "# print(params.keys())\n",
    "# with open(\"./intermediate_data/params.json\", \"w\") as f:\n",
    "#     json.dump(params, f)\n",
    "# # get gnn transmission results\n",
    "# with torch.no_grad():\n",
    "#     res = cnn_cal(g, image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 3, 3],\n",
      "       device='cuda:0')\n",
      "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71,\n",
      "        72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# init ft feature and get subg\n",
    "with torch.no_grad():\n",
    "    initiate_node_feature(g, image)\n",
    "print(g.ndata['tag'])\n",
    "# get node id\n",
    "def nodes_with_feature_smaller_two(nodes):\n",
    "    return nodes.data['tag'] <= 1\n",
    "nodes_idx = g.filter_nodes(nodes_with_feature_smaller_two)\n",
    "# print(nodes_idx)\n",
    "subg = dgl.node_subgraph(g, nodes_idx, relabel_nodes=True)\n",
    "print(subg.nodes())\n",
    "ft32 = None\n",
    "# got the right subg of conv layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "subg.ndata['ft']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "subg.ndata['convd_size']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(subg.ndata['ft'])\n",
    "print(subg.ndata['convd_size'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "global_ft = []\n",
    "global_size = []\n",
    "def my_reduce(nodes):\n",
    "    global global_ft, global_size\n",
    "    print(\"my reduce function called!\")\n",
    "    m = nodes.mailbox['m']\n",
    "    if torch.eq(m, torch.zeros(m.size()).to(\"cuda\")).all() == True:\n",
    "        print(\"received message all are zeros! qaq\")\n",
    "    actual_size = nodes.mailbox['ret_size']\n",
    "    global_ft.append(m)\n",
    "    global_size.append(actual_size)\n",
    "    \n",
    "    print(\"mailbox data size:\", m.size(), actual_size.size())\n",
    "    print(nodes)\n",
    "    mshape = m.size()\n",
    "    n, f, d = actual_size.size()\n",
    "    ret_size = torch.zeros((n, d)).to(\"cuda\")\n",
    "    ret_ft = torch.zeros((n, 1, 1, 28, 28)).to(\"cuda\")\n",
    "    pre_ft = None\n",
    "    pre_weight = None\n",
    "    cnt = 0 \n",
    "    print(\"node bacht N: \", mshape)\n",
    "    # reduce nodes batch N\n",
    "    for out_idx in range(mshape[0]):\n",
    "        # begin the process for each node\n",
    "        received_feats = m[out_idx]\n",
    "        if torch.eq(received_feats, torch.zeros(received_feats.size()).to(\"cuda\")).all() == True:\n",
    "            print(\"skiped %d feats.\" % cnt)\n",
    "            cnt += 1\n",
    "            continue\n",
    "        received_sizes = actual_size[out_idx]\n",
    "        # print(\"received_size: \", received_sizes)\n",
    "        # a_break = input()\n",
    "        # channels = received_feats.size()[0]\n",
    "        ft = torch.zeros((1, 1, 28, 28)).to(\"cuda\")\n",
    "        # print(\"channels: %d \" % channels)\n",
    "\n",
    "        # prepare conv operator\n",
    "        kernel_size, stride, pad = nodes.data['params'][out_idx]\n",
    "        # print(\"idx:\", out_idx, nodes.data['params'][out_idx])\n",
    "        conv_operator = torch.nn.Conv2d(1, 1, kernel_size=kernel_size, stride=stride, padding=pad)\n",
    "        # get and set my_conv weight & bias\n",
    "        weight = nodes.data['x'][out_idx]\n",
    "        if pre_weight is None:\n",
    "            pre_weight = weight\n",
    "        elif torch.eq(pre_weight, weight).all() == True:\n",
    "            print(\"this weight is same as pre weight totally!\")\n",
    "        else:\n",
    "            print(\"weight diffs!\")\n",
    "        w = unpadding(weight, kernel_size[0], kernel_size[1])\n",
    "        w = w.unsqueeze(0).unsqueeze(0)\n",
    "        bias = nodes.data['bias'][out_idx]\n",
    "        b = unpadding(bias, 1, 1)[0]\n",
    "        # print(\"weight size:\", conv_operator.weight.size())\n",
    "        conv_operator.weight.data = w\n",
    "        # print(\"weight size:\", conv_operator.weight.size())\n",
    "        conv_operator.bias.data = b\n",
    "        row, col = -1, -1\n",
    "        # for in_channel, data_size, size_idx in zip(received_feats, actual_size[out_idx], ret_size[0]):\n",
    "        for inner_idx in range(len(received_feats)):\n",
    "            in_channel = received_feats[inner_idx]\n",
    "            data_size = received_sizes[inner_idx]\n",
    "            # get actual size data\n",
    "            row, col = data_size\n",
    "            row, col = int(row), int(col)\n",
    "            # print(\"types: \", type(row))\n",
    "            # print(\"row: \", row)\n",
    "            if row == 0:\n",
    "                continue\n",
    "            # resize \n",
    "            data = in_channel.resize_((28, 28))\n",
    "            data = unpadding(data, row, col)\n",
    "            data = data.resize_((1, 1, row, col))\n",
    "        \n",
    "            # do conv\n",
    "            # print(\"input size:\", data.size())\n",
    "            data = conv_operator(data.to(\"cuda\"))\n",
    "            # print(\"finished conv, res size:\", data.size())\n",
    "\n",
    "            # do relu\n",
    "            relu_operator = torch.nn.functional.relu\n",
    "            data = relu_operator(data)\n",
    "\n",
    "            # do max_pool\n",
    "            pooling = nodes.data['pooling'][out_idx]\n",
    "            if pooling.all() != 0:\n",
    "                # do max_pooling\n",
    "                kernel_size, stride, pad, dilation, ceil_mode = pooling\n",
    "                max_pooling_operator = torch.nn.MaxPool2d(kernel_size=kernel_size, stride=stride, \n",
    "                    padding=pad, dilation=dilation, ceil_mode=ceil_mode)\n",
    "                \n",
    "                data = max_pooling_operator(data)\n",
    "            _, _, row, col = data.size()\n",
    "            data = data.resize_((row, col))\n",
    "            # print(\"maxPooling data size: \", data.size(), type(data))\n",
    "            data = padding(data, 28, 28)\n",
    "            if torch.eq(data, torch.zeros(data.size()).to(\"cuda\")).all() == True:\n",
    "                print(\"data is all zeros!\")\n",
    "            else:\n",
    "                print(\"data feat seems ok!\")\n",
    "            ft += data\n",
    "        convd_size = torch.tensor([row, col])\n",
    "        ret_size[out_idx] = convd_size.to(\"cuda\")\n",
    "        ret_ft[out_idx] = ft.to(\"cuda\")\n",
    "        if torch.eq(ft, torch.zeros(ft.size()).to(\"cuda\")).all() == True:\n",
    "            print(\"idx: \", out_idx)\n",
    "            # a_break = input()\n",
    "        # else:\n",
    "            # print(ft)\n",
    "            # a_break = input()\n",
    "        if pre_ft is None:\n",
    "            pre_ft = ft\n",
    "        elif torch.eq(pre_ft, ft).all() == True:\n",
    "            print(\"this ft is equals pre ft totally!\")\n",
    "        else:\n",
    "            print(\"final feat diffs!\")\n",
    "        pre_ft = ft\n",
    "        # a_break = input()\n",
    "\n",
    "    # return size is [n, 1, 1, 28, 28], reduced from [n, m, 1, 1, 28, 28]\n",
    "    return {'h': ret_ft, 'ret_size': ret_size}\n",
    "\n",
    "def my_message(edges):\n",
    "    return {'m': edges.src['ft'], 'ret_size': edges.src['convd_size']}\n",
    "\n",
    "def print_zeros_in_feat(key):\n",
    "    print(key + \": \")\n",
    "    zeros = []\n",
    "    nonzero = []\n",
    "    for id in subg.nodes():\n",
    "        id = int(id)\n",
    "        feat = subg.nodes[id].data[key]\n",
    "        if torch.eq(feat, torch.zeros(feat.size()).to(\"cuda\")).all() == True:\n",
    "            zeros.append(id)\n",
    "        else:\n",
    "            nonzero.append(id)\n",
    "    print(\"zeros - \", zeros)\n",
    "    print(\"nonzeros - \", nonzero)\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    subg.update_all(my_message, my_reduce)\n",
    "    print(\"ret_size of data: \", subg.ndata['ret_size'])\n",
    "    print(\"convd_size of data: \", subg.ndata['convd_size'])\n",
    "    subg.ndata['convd_size'] += subg.ndata['ret_size']\n",
    "    print_zeros_in_feat('ft')\n",
    "    print_zeros_in_feat('h')\n",
    "    subg.ndata['ft'] += subg.ndata['h']\n",
    "    print_zeros_in_feat('ft')\n",
    "    print_zeros_in_feat('h')\n",
    "    cur_ft32 = subg.ndata['ft'][32]\n",
    "    if ft32 is not None and torch.eq(cur_ft32, ft32).all():\n",
    "        ft32 = cur_ft32\n",
    "        print(\"ft32 equals!\")\n",
    "    else:\n",
    "        ft32 = cur_ft32\n",
    "        print(\"ft32 not equeal!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "subg.ndata['ft']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for ft, st in zip(global_ft[1], global_size[1]):\n",
    "    # print(len(global_ft[1]), len(global_size[1]))\n",
    "    # print(ft, st)\n",
    "    # check zeros\n",
    "    condition = torch.eq(ft, torch.zeros(ft.size()).to(\"cuda\")).all() == True\n",
    "    if not condition:\n",
    "        print(\"not all zeros!\")\n",
    "        print(ft)\n",
    "        print(st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "feats = []\n",
    "for feat in subg.ndata['ft']:\n",
    "    feat = feat.cpu()\n",
    "    if torch.eq(feat, torch.zeros(feat.size())).all() == True:\n",
    "        feats.append(\"Zeros\")\n",
    "    else:\n",
    "        feats.append(\"Feats\")\n",
    "print(feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(subg.ndata['ft'].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "cnn_params = None \n",
    "with open(\"./intermediate_data/params.json\", \"r\") as f:\n",
    "    cnn_params = json.load(f)\n",
    "x_in = cnn_params['conv1']['in']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# input is the same\n",
    "torch.eq(torch.tensor(x_in), image).all() == True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ft = g.ndata['ft']\n",
    "mask = g.ndata['tag'] == 0\n",
    "print(ft[mask].size())\n",
    "model_out = ft[mask]\n",
    "out = torch.tensor(cnn_params['conv1']['out'])\n",
    "print(out.size())\n",
    "model_out = model_out.resize_((32, 28, 28)).to(\"cuda\")\n",
    "out = out.resize_((32, 28, 28)).to(\"cuda\")\n",
    "print(model_out.size(), out.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# conv1 out is the same \n",
    "from torch.nn.functional import relu\n",
    "torch.eq(model_out, relu(out)).all() == True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# checking output by gnn\n",
    "from torch.nn.functional import relu\n",
    "conv2_out = torch.tensor(cnn_params['conv2']['relu'])\n",
    "print(conv2_out.size())\n",
    "gnn2_out = subg.ndata['ft'][32:64]\n",
    "print(gnn2_out.size())\n",
    "conv2_out = conv2_out.resize_((32, 28, 28)).to(\"cuda\")\n",
    "gnn2_out = gnn2_out.resize_((32, 28, 28)).to(\"cuda\")\n",
    "print(conv2_out.size(), gnn2_out.size())\n",
    "import numpy as np\n",
    "for id in range(len(conv2_out)):\n",
    "    np.savetxt(\"./intermediate_data/cnn_out_%d.csv\" % id, conv2_out[id].cpu().numpy(), delimiter=',')\n",
    "    np.savetxt(\"./intermediate_data/gnn_out_%d.csv\" % id, gnn2_out[id].cpu().numpy(), delimiter=',')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print_zeros_in_feat('ft')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "equals = False\n",
    "for gf in gnn2_out:\n",
    "    for cf in conv2_out:\n",
    "        if torch.eq(gf, cf).all() == True:\n",
    "            equeals = True\n",
    "            break\n",
    "        \n",
    "print(\"equals: \", equals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.13 ('mntd')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2d7768e61f5674adf4efa61c7b8cc3ee2c06ae8f502b5df709cd3e31381a4347"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}