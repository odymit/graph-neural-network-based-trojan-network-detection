{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# POC 激活验证"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 同构激活图"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "已完成"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 设计传播函数模拟神经网络传参\n",
    "- 图片分类网络结果  \n",
    "    - [x] 读取数据\n",
    "    - [x] 调用分类网络获得分类结果\n",
    "    - [x] 获取网络中间结果  \n",
    "- 设计传播函数  \n",
    "    - [ ] conv 层\n",
    "    - [ ] 全连接层\n",
    "    - [ ] 输出层获得分类结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dorian/.conda/envs/mntd/lib/python3.6/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mnist': {'0': [{'name': 'conv1', 'num': 16, 'maxpool': {'kernel_size': 2, 'stride': 2, 'padding': 0, 'dilation': 1, 'ceil_mode': False}}, {'name': 'conv2', 'num': 32, 'maxpool': {'kernel_size': 2, 'stride': 2, 'padding': 0, 'dilation': 1, 'ceil_mode': False}}, {'name': 'fc', 'num': 1, 'maxpool': None}, {'name': 'output', 'num': 1, 'maxpool': None}], '1': [{'name': 'conv1', 'num': 16, 'maxpool': {'kernel_size': 2, 'stride': 1, 'padding': 0, 'dilation': 1, 'ceil_mode': False}}, {'name': 'conv2', 'num': 32, 'maxpool': {'kernel_size': 2, 'stride': 1, 'padding': 0, 'dilation': 1, 'ceil_mode': False}}, {'name': 'conv3', 'num': 32, 'maxpool': {'kernel_size': 2, 'stride': 1, 'padding': 0, 'dilation': 1, 'ceil_mode': False}}, {'name': 'fc', 'num': 1, 'maxpool': None}, {'name': 'output', 'num': 1, 'maxpool': None}], '2': [{'name': 'conv1', 'num': 32, 'maxpool': None}, {'name': 'conv2', 'num': 32, 'maxpool': None}, {'name': 'conv3', 'num': 64, 'maxpool': None}, {'name': 'fc', 'num': 1, 'maxpool': None}, {'name': 'fc1', 'num': 1, 'maxpool': None}, {'name': 'output', 'num': 1, 'maxpool': None}], '3': [{'name': 'conv1', 'num': 64, 'maxpool': {'kernel_size': 2, 'stride': 2, 'padding': 0, 'dilation': 1, 'ceil_mode': False}}, {'name': 'conv2', 'num': 128, 'maxpool': {'kernel_size': 2, 'stride': 2, 'padding': 0, 'dilation': 1, 'ceil_mode': False}}, {'name': 'conv3', 'num': 16, 'maxpool': None}, {'name': 'fc1', 'num': 1, 'maxpool': None}, {'name': 'fc2', 'num': 1, 'maxpool': None}, {'name': 'output', 'num': 1, 'maxpool': None}], '4': [{'name': 'conv1', 'num': 32, 'maxpool': {'kernel_size': 2, 'stride': 2, 'padding': 0, 'dilation': 1, 'ceil_mode': False}}, {'name': 'conv2', 'num': 64, 'maxpool': None}, {'name': 'conv3', 'num': 32, 'maxpool': None}, {'name': 'conv4', 'num': 32, 'maxpool': {'kernel_size': 2, 'stride': 2, 'padding': 0, 'dilation': 1, 'ceil_mode': False}}, {'name': 'fc', 'num': 1, 'maxpool': None}, {'name': 'output', 'num': 1, 'maxpool': None}], '5': [{'name': 'conv1', 'num': 32, 'maxpool': None}, {'name': 'conv2', 'num': 32, 'maxpool': {'kernel_size': 2, 'stride': 2, 'padding': 0, 'dilation': 1, 'ceil_mode': False}}, {'name': 'conv3', 'num': 16, 'maxpool': None}, {'name': 'conv4', 'num': 8, 'maxpool': {'kernel_size': 2, 'stride': 2, 'padding': 0, 'dilation': 1, 'ceil_mode': False}}, {'name': 'fc1', 'num': 1, 'maxpool': None}, {'name': 'fc2', 'num': 1, 'maxpool': None}, {'name': 'output', 'num': 1, 'maxpool': None}]}, 'cifar10': {}, 'max_size': [512, 512]}\n",
      "None\n",
      "{'kernel_size': 2, 'stride': 2, 'padding': 0, 'dilation': 1, 'ceil_mode': False}\n",
      "None\n",
      "{'kernel_size': 2, 'stride': 2, 'padding': 0, 'dilation': 1, 'ceil_mode': False}\n",
      "None\n",
      "None\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import dgl\n",
    "import torch\n",
    "from utils_gnn import cnn2graph_activation\n",
    "# from model_lib import mnist_cnn_model as father_model\n",
    "from utils_basic import load_spec_model\n",
    "from utils_gnn import padding\n",
    "x = '/home/dorian/repos/Meta-Nerual-Trojan-Detection/shadow_model_ckpt/mnist/models5/shadow_jumbo_9.model'\n",
    "# load model \n",
    "# Model = load_spec_model(father_model, '5')\n",
    "from model_lib.mnist_cnn_model import Model6 as Model\n",
    "model = Model(gpu=True)\n",
    "params = torch.load(x)\n",
    "model.load_state_dict(params)\n",
    "\n",
    "# load model detail \n",
    "model_detail = {}\n",
    "model_detail_path = \"./intermediate_data/model_detail.json\"\n",
    "import json\n",
    "with open(model_detail_path, 'r') as f:\n",
    "    model_detail = json.load(f)\n",
    "print(model_detail)\n",
    "g = cnn2graph_activation(model, model_detail['mnist']['5'])\n",
    "dgl.save_graphs('./intermediate_data/grapj_test.bin', g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "# from utils_gnn import SGNACT\n",
    "GPU = True\n",
    "if GPU:\n",
    "        torch.cuda.manual_seed_all(0)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "        \n",
    "transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "        ])\n",
    "BATCH_SIZE = 1\n",
    "# MNIST image dataset \n",
    "trainset = torchvision.datasets.MNIST(root='./raw_data/', train=True, download=True, transform=transform)\n",
    "dataloader = torch.utils.data.DataLoader(trainset, batch_size=BATCH_SIZE)\n",
    "\n",
    "from model_lib.hetero_struct_backdoor_dataset import HeteroStrucBackdoorDataset\n",
    "from dgl.dataloading import GraphDataLoader\n",
    "# Shadow model dataset\n",
    "dataset = HeteroStrucBackdoorDataset(nums=10,\n",
    "    raw_dir='/home/dorian/repos/Meta-Nerual-Trojan-Detection/shadow_model_ckpt/mnist/models', activation=True)\n",
    "model_dataloader = GraphDataLoader(dataset, batch_size=1, pin_memory=torch.cuda.is_available())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'kernel_size': 2, 'stride': 2, 'padding': 0, 'dilation': 1, 'ceil_mode': False}\n",
      "None\n",
      "None\n",
      "{'kernel_size': 2, 'stride': 2, 'padding': 0, 'dilation': 1, 'ceil_mode': False}\n",
      "None\n",
      "None\n",
      "Graph(num_nodes=162, num_edges=5153,\n",
      "      ndata_schemes={'x': Scheme(shape=(512, 512), dtype=torch.float32), 'tag': Scheme(shape=(), dtype=torch.int64), 'layer': Scheme(shape=(), dtype=torch.int64), 'node_size': Scheme(shape=(2,), dtype=torch.int64), 'params': Scheme(shape=(3, 2), dtype=torch.int64), 'bias': Scheme(shape=(1, 512), dtype=torch.float32), 'bias_size': Scheme(shape=(2,), dtype=torch.int64), 'pooling': Scheme(shape=(5,), dtype=torch.int64)}\n",
      "      edata_schemes={})\n",
      "tensor(3, device='cuda:0')\n",
      "dict_keys(['x', 'tag', 'layer', 'node_size', 'params', 'bias', 'bias_size', 'pooling'])\n",
      "this is message function.\n",
      "message fucntion ends\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 5.03 GiB (GPU 0; 3.82 GiB total capacity; 256.19 MiB already allocated; 2.08 GiB free; 258.00 MiB reserved in total by PyTorch)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-8a18e1eeaad4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;31m# get calculation results on graph node\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatched_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcnn_cal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatched_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m         \u001b[0;31m# compare\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-8a18e1eeaad4>\u001b[0m in \u001b[0;36mcnn_cal\u001b[0;34m(graph)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcnn_cal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m     \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage_func\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmessage_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_func\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreduce_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m     \u001b[0mft\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ft'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mft\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/dorian/.conda/envs/mntd/lib/python3.6/site-packages/dgl/heterograph.py\u001b[0m in \u001b[0;36mupdate_all\u001b[0;34m(self, message_func, reduce_func, apply_node_func, etype)\u001b[0m\n\u001b[1;32m   4893\u001b[0m             \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetagraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_edge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4894\u001b[0m             \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0metype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4895\u001b[0;31m             \u001b[0mndata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage_passing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapply_node_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4896\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_builtin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduce_func\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mreduce_func\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'min'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'max'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mndata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4897\u001b[0m                 \u001b[0;31m# Replace infinity with zero for isolated nodes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/dorian/.conda/envs/mntd/lib/python3.6/site-packages/dgl/core.py\u001b[0m in \u001b[0;36mmessage_passing\u001b[0;34m(g, mfunc, rfunc, afunc)\u001b[0m\n\u001b[1;32m    363\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m             \u001b[0morig_eid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEID\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 365\u001b[0;31m             \u001b[0mmsgdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minvoke_edge_udf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mALL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanonical_etypes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morig_eid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morig_eid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    366\u001b[0m         \u001b[0;31m# reduce phase\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    367\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_builtin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/dorian/.conda/envs/mntd/lib/python3.6/site-packages/dgl/core.py\u001b[0m in \u001b[0;36minvoke_edge_udf\u001b[0;34m(graph, eid, etype, func, orig_eid)\u001b[0m\n\u001b[1;32m     83\u001b[0m     ebatch = EdgeBatch(graph, eid if orig_eid is None else orig_eid,\n\u001b[1;32m     84\u001b[0m                        etype, srcdata, edata, dstdata)\n\u001b[0;32m---> 85\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mebatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0minvoke_udf_reduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsgdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morig_nid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-8a18e1eeaad4>\u001b[0m in \u001b[0;36mmessage_func\u001b[0;34m(edges)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"this is message function.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"message fucntion ends\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'pre'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0medges\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'x'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mreduce_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/dorian/.conda/envs/mntd/lib/python3.6/site-packages/dgl/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    620\u001b[0m             \u001b[0mColumn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    621\u001b[0m         \"\"\"\n\u001b[0;32m--> 622\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_columns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    623\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/dorian/.conda/envs/mntd/lib/python3.6/site-packages/dgl/frame.py\u001b[0m in \u001b[0;36mdata\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    224\u001b[0m                         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_to\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_ctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 226\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstorage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather_row\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    227\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/dorian/.conda/envs/mntd/lib/python3.6/site-packages/dgl/backend/pytorch/tensor.py\u001b[0m in \u001b[0;36mgather_row\u001b[0;34m(data, row_index)\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mgather_row\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_select\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow_index\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mslice_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbegin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 5.03 GiB (GPU 0; 3.82 GiB total capacity; 256.19 MiB already allocated; 2.08 GiB free; 258.00 MiB reserved in total by PyTorch)"
     ]
    }
   ],
   "source": [
    "import dgl\n",
    "from dgl.data import DGLDataset\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from dgl import save_graphs, load_graphs\n",
    "import torch\n",
    "import json\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "# from model_lib.mnist_cnn_model import Model\n",
    "from random import randint\n",
    "from utils_basic import load_spec_model\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from torchinfo import summary\n",
    "import torch.nn.functional as F\n",
    "from dgl.nn.pytorch.conv import GINConv\n",
    "from dgl.nn.pytorch.glob import SumPooling, AvgPooling, MaxPooling, SortPooling\n",
    "from utils_gnn import MLP\n",
    "from utils_gnn import unpadding, padding\n",
    "\n",
    "\n",
    "def conv(data, weight, bias, kernel_size, stride, padding):\n",
    "    row, col = weight.size()\n",
    "    # get actual conv kernel weight and bias\n",
    "    w = unpadding(weight, kernel_size, kernel_size)\n",
    "    w = w.unsqueeze(0).unsqueeze(0)\n",
    "    b = unpadding(bias, 1, 1)[0]\n",
    "    # get conv operator \n",
    "    operator = torch.nn.Conv2d(1, 1, kernel_size=kernel_size, stride=stride,\n",
    "                    padding=padding)\n",
    "    # set conv operator weight and bias\n",
    "    operator.weight.data = w\n",
    "    operator.bias.data = b\n",
    "    # conduct conv operation\n",
    "    x = operator(data)\n",
    "    return padding(x[0][0], 512, 512)\n",
    "\n",
    "def maxpool(kernel_size, stride, padding):\n",
    "    pass\n",
    "\n",
    "def message_func(edges):\n",
    "    print(\"this is message function.\")\n",
    "    print(\"message fucntion ends\")\n",
    "    return {'pre': edges.src['x']}\n",
    "\n",
    "def reduce_func(nodes):\n",
    "    print(\"this is reduce function\")\n",
    "    input_mask = nodes.data['tag'] == 0\n",
    "    conv_mask = nodes.data['tag'] == 1\n",
    "    concat_mask = nodes.data['tag'] == 2\n",
    "    fc_mask = nodes.data['tag'] == 3\n",
    "\n",
    "    # input_feat = nodes.data['x'][input_mask]\n",
    "    # print(input_feat)\n",
    "    print(\"reduce function ends\")\n",
    "    return {'h': nodes.data['x']}\n",
    "\n",
    "\n",
    "def cnn_cal(graph):\n",
    "    graph.update_all(message_func=message_func, reduce_func=reduce_func)\n",
    "    ft = graph.ndata['ft'][0]\n",
    "    return ft\n",
    "\n",
    "model.eval()\n",
    "for batch, (batched_graph, labels) in enumerate(model_dataloader):\n",
    "    print(batched_graph)\n",
    "    for i, (x_in, y_in) in enumerate(dataloader):\n",
    "        # print(x_in.size())\n",
    "        # get orginal cnn calculation resutls\n",
    "        pred, params = model(x_in)\n",
    "        print(torch.argmax(pred))\n",
    "        # get calculation results on graph node \n",
    "        print(batched_graph.ndata.keys())\n",
    "        res = cnn_cal(batched_graph)\n",
    "        # compare\n",
    "        break\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = g.ndata[\"tag\"] == 0\n",
    "g.ndata['test'] = torch.tensor([1. if i else 0 for i in mask]).to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0.], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(g.ndata[\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def message_func(edges):\n",
    "    print(\"message function called.\")\n",
    "    return {\"m\": edges.src['test']}\n",
    "from dgl import function as fn\n",
    "reduce_func = fn.max(\"m\", \"h\")\n",
    "# def reduce_func(nodes):\n",
    "#     print(\"reduce function called.\")\n",
    "#     return {\"h\": torch.max(nodes.mailbox[\"m\"], dim=1)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while g.ndata['ft'][-1]:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "message function called.\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0.], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "g.update_all(message_func, reduce_func)\n",
    "print(g.ndata[\"h\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "message function called.\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "g.ndata[\"test\"] = g.ndata.pop(\"h\")\n",
    "g.update_all(message_func, reduce_func)\n",
    "print(g.ndata['h'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.13 ('mntd')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7d504790743f38722d745ab54c6dcc5c590f96c5141b7c6566bf2e4e2b011705"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
