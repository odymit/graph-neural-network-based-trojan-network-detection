{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# POC 激活验证\n",
    "### 1. 获得异构图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dgl\n",
    "import torch\n",
    "from model_lib.hetero_struct_backdoor_dataset import HeteroStrucBackdoorDataset\n",
    "from utils_gnn import all_u_to_v\n",
    "\n",
    "def cnn2graph(model, model_info):\n",
    "    # convert cnn model to a dgl graph\n",
    "    # model: model weight data\n",
    "    # model_info: model struct info\n",
    "    \n",
    "    graph_data = {\n",
    "        # (src_type, relation, dst_type): ([src_nodes], [dst_nodes]) type in tensor\n",
    "        ('conv', 'channels_to', 'conv'): None,\n",
    "        ('conv', 'concat_to', 'fc'): None,\n",
    "        ('fc', 'connect_to', 'fc'): None\n",
    "    }\n",
    "    layers = []\n",
    "    all_node_feats = []\n",
    "    all_edges = []\n",
    "    cnt = 0\n",
    "    layer_types = [] \n",
    "    layer_idx = []\n",
    "    with torch.no_grad():\n",
    "        for i in range(len(model_info)):\n",
    "            cur_layer_info = model_info[i]\n",
    "            cur_layer_node = []\n",
    "            \n",
    "            if 'conv' in cur_layer_info['name']:\n",
    "                # construct cur layer nodes\n",
    "                for weight, bias in zip(model.get_submodule(cur_layer_info['name']).weight, \n",
    "                                        model.get_submodule(cur_layer_info['name']).bias):\n",
    "                    cur_layer_node.append(cnt)\n",
    "                    cnt += 1\n",
    "                    # featue resize?\n",
    "                    w = weight[0] + bias\n",
    "                    # all_node_feats.append(padding(w, 512, 513))\n",
    "                    layer_types.append('conv')\n",
    "                    layer_idx.append(i)\n",
    "            else:\n",
    "                # construct dense layer node\n",
    "                cur_layer_node.append(cnt)\n",
    "                cnt += 1\n",
    "                # feature resize?\n",
    "                w = model.get_submodule(cur_layer_info['name']).weight.t() + model.get_submodule(cur_layer_info['name']).bias\n",
    "                all_node_feats.append(padding(w, 512, 513))\n",
    "                layer_types.append('fc')\n",
    "                layer_idx.append(i)\n",
    "            layers.append(cur_layer_node)\n",
    "            \n",
    "    # get all edges\n",
    "    conv_2_conv = []\n",
    "    conv_2_fc = []\n",
    "    fc_2_fc =[]\n",
    "    for idx in range(len(layers)):\n",
    "        if idx < len(layers) - 1:\n",
    "            cur_layer_type = layer_types[idx]\n",
    "            next_layer_type = layer_types[idx+1]\n",
    "            if cur_layer_type == 'conv' and next_layer_type == 'conv':\n",
    "                conv_2_conv += all_u_to_v(layers[idx], layers[idx+1])\n",
    "            elif cur_layer_type == 'conv' and next_layer_type == 'fc':\n",
    "                conv_2_fc += all_u_to_v(layers[idx], layers[idx+1])\n",
    "            else:\n",
    "                fc_2_fc += all_u_to_v(layers[idx], layers[idx+1])\n",
    "    \n",
    "    # convert to tensor\n",
    "    graph_data[('conv', 'channels_to', 'conv')] = torch.tensor(conv_2_conv).t()\n",
    "    graph_data[('conv', 'concat_to', 'fc')] = torch.tensor(conv_2_fc).t()\n",
    "    graph_data[('fc', 'connect_to', 'fc')] = torch.tensor(fc_2_fc).t()\n",
    "\n",
    "    # get hetero graph\n",
    "    g = dgl.heterograph(graph_data).to('cuda')\n",
    "    g.ndata['x'] = torch.stack(all_node_feats)\n",
    "    return g\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.13 ('mntd')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.6.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7d504790743f38722d745ab54c6dcc5c590f96c5141b7c6566bf2e4e2b011705"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
