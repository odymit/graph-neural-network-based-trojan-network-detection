{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "\n",
    "# POC 激活验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import dgl\n",
    "import torch\n",
    "from utils_gnn import cnn2graph_activation\n",
    "# from model_lib import mnist_cnn_model as father_model\n",
    "from utils_basic import load_spec_model\n",
    "from utils_gnn import padding, unpadding\n",
    "from dgl.data import DGLDataset\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from dgl import save_graphs, load_graphs\n",
    "import torch\n",
    "import json\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "# from model_lib.mnist_cnn_model import Model\n",
    "from random import randint\n",
    "from utils_basic import load_spec_model\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from torchinfo import summary\n",
    "import torch.nn.functional as F\n",
    "from dgl.nn.pytorch.conv import GINConv\n",
    "from dgl.nn.pytorch.glob import SumPooling, AvgPooling, MaxPooling, SortPooling\n",
    "from utils_gnn import MLP\n",
    "\n",
    "\n",
    "# x = '/home/dorian/repos/Meta-Nerual-Trojan-Detection/shadow_model_ckpt/mnist/models5/shadow_jumbo_9.model'\n",
    "x = './shadow_model_ckpt/mnist/models5/shadow_jumbo_0.model'\n",
    "# load model \n",
    "# Model = load_spec_model(father_model, '5')\n",
    "from model_lib.mnist_cnn_model import Model6 as Model\n",
    "model = Model(gpu=True)\n",
    "params = torch.load(x)\n",
    "model.load_state_dict(params)\n",
    "del params\n",
    "\n",
    "# load model detail \n",
    "model_detail = {}\n",
    "model_detail_path = \"./intermediate_data/model_detail.json\"\n",
    "import json\n",
    "with open(model_detail_path, 'r') as f:\n",
    "    model_detail = json.load(f)\n",
    "# print(model_detail)\n",
    "g = cnn2graph_activation(model, model_detail['mnist']['5'])\n",
    "dgl.save_graphs('./intermediate_data/grapj_test.bin', g)\n",
    "del model_detail\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "# from utils_gnn import SGNACT\n",
    "GPU = True\n",
    "if GPU:\n",
    "        torch.cuda.manual_seed_all(0)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "        \n",
    "transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "        ])\n",
    "BATCH_SIZE = 1\n",
    "# MNIST image dataset \n",
    "trainset = torchvision.datasets.MNIST(root='./raw_data/', train=True, download=True, transform=transform)\n",
    "dataloader = torch.utils.data.DataLoader(trainset, batch_size=BATCH_SIZE)\n",
    "\n",
    "# get a image\n",
    "image = None\n",
    "label = None\n",
    "for i, (x_in, y_in) in enumerate(dataloader):\n",
    "    image = x_in\n",
    "    model(image)\n",
    "    label = y_in\n",
    "    break\n",
    "del trainset, dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# define the init process\n",
    "def init_conv(data, data_size, weight, bias, kernel_size, stride, padding):\n",
    "    row, col = weight.size()\n",
    "    # print(weight.size())\n",
    "    # get actual conv kernel weight and bias\n",
    "    w = unpadding(weight, kernel_size[0], kernel_size[1])\n",
    "    w = w.unsqueeze(0).unsqueeze(0)\n",
    "    b = unpadding(bias, 1, 1)[0]\n",
    "    # get conv operator \n",
    "    # print(\"kernel_size, stride, padding:\")\n",
    "    # print(kernel_size, stride, padding)\n",
    "    operator = torch.nn.Conv2d(1, 1, kernel_size=kernel_size, \n",
    "                    stride=stride, padding=padding)\n",
    "    # set conv operator weight and bias\n",
    "    operator.weight.data = w\n",
    "    operator.bias.data = b\n",
    "    # conduct conv operation\n",
    "    # print(\"conv input size:\", data.size())\n",
    "    x = operator(data.to(\"cuda\"))\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "def initiate_node_feature(graph, image):\n",
    "    ft = None \n",
    "    mask = graph.ndata['tag'] == 0\n",
    "    out_channels = int(sum(mask))\n",
    "    ft = torch.zeros((len(graph.nodes()), 1, 1, 28, 28))\n",
    "    convd_size = torch.zeros((len(graph.nodes()), 2))\n",
    "    for i in range(out_channels):\n",
    "        kernel_size, stride, padding = graph.ndata['kernel_params'][i]\n",
    "        # do conv\n",
    "        res_ft = init_conv(image, None, graph.ndata['kernel_weight'][i], graph.ndata['bias'][i],\n",
    "                kernel_size, stride, padding)\n",
    "        # do relu\n",
    "        relu_opt = torch.nn.functional.relu\n",
    "        res_ft = relu_opt(res_ft)\n",
    "\n",
    "        # do max pooling\n",
    "        pooling = graph.ndata['pooling_params'][i]\n",
    "        if pooling.all() != 0:\n",
    "            # do max_pooling\n",
    "            kernel_size, stride, pad, dilation, ceil_mode = pooling\n",
    "            max_pooling_operator = torch.nn.MaxPool2d(kernel_size=kernel_size, stride=stride, \n",
    "                padding=pad, dilation=dilation, ceil_mode=ceil_mode)\n",
    "            \n",
    "            res_ft = max_pooling_operator(res_ft)\n",
    "        _, _, r, c = res_ft.size()\n",
    "        ft[i] = res_ft\n",
    "        convd_size[i] = torch.tensor([int(r), int(c)])\n",
    "    graph.ndata['ft'] = ft.to(\"cuda\")\n",
    "    graph.ndata['ft_size'] = convd_size.to(\"cuda\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 3, 3],\n",
      "       device='cuda:0')\n",
      "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71,\n",
      "        72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# init ft feature and get subg\n",
    "with torch.no_grad():\n",
    "    initiate_node_feature(g, image)\n",
    "print(g.ndata['tag'])\n",
    "# get node id\n",
    "def nodes_with_feature_smaller_two(nodes):\n",
    "    return nodes.data['tag'] <= 1\n",
    "nodes_idx = g.filter_nodes(nodes_with_feature_smaller_two)\n",
    "# print(nodes_idx)\n",
    "subg = dgl.node_subgraph(g, nodes_idx, relabel_nodes=True)\n",
    "print(subg.nodes())\n",
    "ft32 = None\n",
    "# got the right subg of conv layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_act_equals():\n",
    "    # case 1, ones equal\n",
    "    x = torch.ones((2,2,2))\n",
    "    y = torch.ones((2,2,2))\n",
    "    ret = equals(x, y)\n",
    "    assert ret == True, \"x != y in case 1\"\n",
    "    # case 2, ones not equal\n",
    "    x = torch.ones((2,2,2))\n",
    "    y = torch.rand((2,2,2))\n",
    "    ret = equals(x, y)\n",
    "    assert ret == False, \"x == y in case 2\"\n",
    "    # case 3, zeros\n",
    "    x = torch.zeros((2,2,2)).to(\"cuda\")\n",
    "    ret = equals(x, zeros=True)\n",
    "    assert ret == True, \"x != y in case 3\"\n",
    "test_act_equals()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'size'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-6a6a89eed05c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m     \u001b[0msubg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmy_message\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmy_reduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ret_size of data: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'reduce_ret_size'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"convd_size of data: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ft_size'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/envs/mntd/lib/python3.6/site-packages/dgl/heterograph.py\u001b[0m in \u001b[0;36mupdate_all\u001b[0;34m(self, message_func, reduce_func, apply_node_func, etype)\u001b[0m\n\u001b[1;32m   4893\u001b[0m             \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetagraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_edge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4894\u001b[0m             \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0metype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4895\u001b[0;31m             \u001b[0mndata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage_passing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapply_node_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4896\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_builtin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduce_func\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mreduce_func\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'min'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'max'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mndata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4897\u001b[0m                 \u001b[0;31m# Replace infinity with zero for isolated nodes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/envs/mntd/lib/python3.6/site-packages/dgl/core.py\u001b[0m in \u001b[0;36mmessage_passing\u001b[0;34m(g, mfunc, rfunc, afunc)\u001b[0m\n\u001b[1;32m    370\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    371\u001b[0m             \u001b[0morig_nid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdstdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNID\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 372\u001b[0;31m             \u001b[0mndata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minvoke_udf_reduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsgdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morig_nid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morig_nid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    373\u001b[0m     \u001b[0;31m# apply phase\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    374\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mafunc\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/envs/mntd/lib/python3.6/site-packages/dgl/core.py\u001b[0m in \u001b[0;36minvoke_udf_reduce\u001b[0;34m(graph, func, msgdata, orig_nid)\u001b[0m\n\u001b[1;32m    141\u001b[0m         \u001b[0;31m# invoke udf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m         \u001b[0mnbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNodeBatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morig_nid_bkt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mntype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mndata_bkt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsgs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmaildata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m         \u001b[0mbkt_rsts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[0;31m# prepare a result frame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-6a6a89eed05c>\u001b[0m in \u001b[0;36mmy_reduce\u001b[0;34m(nodes)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0;31m# save ft size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m         \u001b[0mcur_ret_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mft\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0;31m# update return data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'size'"
     ]
    }
   ],
   "source": [
    "def prepare_data(rdata, rsize):\n",
    "    n = len(rdata)        \n",
    "    cur_size = rsize[idx]\n",
    "    width, height = cur_size\n",
    "    ret_data = torch.zeros((n, 1, 1, width, height)).to(\"cuda\")\n",
    "    for idx in range(n):\n",
    "        cur_data = rdata[idx]\n",
    "        # convet (1, 1, 28, 28) to (1, 1, width, height)\n",
    "        shaped_data = unpadding(cur_data, width, height)\n",
    "        ret_data[idx] = shaped_data\n",
    "    return ret_data\n",
    "\n",
    "\n",
    "def prepare_conv_operator():\n",
    "    pass\n",
    "\n",
    "def do_operation():\n",
    "    pass\n",
    "\n",
    "def equals(x, y=None, zeros=False):\n",
    "    if zeros:\n",
    "        y = torch.zeros(x.size()).to(\"cuda\")\n",
    "    \n",
    "    cmp_results = x == y\n",
    "    if cmp_results.all() == True:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "\n",
    "def my_reduce(nodes):\n",
    "    # received data and their size\n",
    "    mfeat = nodes.mailbox['m']\n",
    "    msize = nodes.mailbox['ret_size']\n",
    "    \n",
    "    mf_size = mfeat.size()\n",
    "    n_nodes = mf_size[0]\n",
    "    n_channels = mf_size[1]\n",
    "\n",
    "    # prepare ret_ft & ret_size, input size (1, 1, 28, 28)\n",
    "    ret_ft = torch.zeros((n_nodes, 1, 1, 28, 28)).to(\"cuda\")\n",
    "    ret_size = torch.zeros((n_nodes, 2)).to(\"cuda\")\n",
    "\n",
    "    # for each node, do conv for received data\n",
    "    for out_idx in range(n_nodes):\n",
    "\n",
    "        # prepare received data and conv weight\n",
    "        received_data = mfeat[out_idx]\n",
    "        received_size = msize[out_idx]\n",
    "        # skip if all zeros\n",
    "        if equals(received_data, zeros=True):\n",
    "            continue\n",
    "        \n",
    "        data = prepare_data(received_data, received_size)\n",
    "\n",
    "\n",
    "        # prepare conv operator\n",
    "        conv_opt = prepare_conv_operator()\n",
    "\n",
    "        # do operation\n",
    "        ft = do_operation()\n",
    "\n",
    "        # save ft size\n",
    "        cur_ret_size = ft.size()\n",
    "\n",
    "        # update return data\n",
    "        \n",
    "    # return size is [n, 1, 1, 28, 28], reduced from [n, m, 1, 1, 28, 28]\n",
    "    return {'h': ret_ft, 'reduce_ret_size': ret_size}\n",
    "\n",
    "def my_message(edges):\n",
    "    return {'m': edges.src['ft'], 'ret_size': edges.src['ft_size']}\n",
    "\n",
    "def print_zeros_in_feat(key):\n",
    "    print(key + \": \")\n",
    "    zeros = []\n",
    "    nonzero = []\n",
    "    for id in subg.nodes():\n",
    "        id = int(id)\n",
    "        feat = subg.nodes[id].data[key]\n",
    "        if torch.eq(feat, torch.zeros(feat.size()).to(\"cuda\")).all() == True:\n",
    "            zeros.append(id)\n",
    "        else:\n",
    "            nonzero.append(id)\n",
    "    print(\"zeros - \", zeros)\n",
    "    print(\"nonzeros - \", nonzero)\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    subg.update_all(my_message, my_reduce)\n",
    "    print(\"ret_size of data: \", subg.ndata['reduce_ret_size'])\n",
    "    print(\"convd_size of data: \", subg.ndata['ft_size'])\n",
    "    print(\"subg ft_size:\", subg.ndata['ft_size'])\n",
    "    print(\"subg ret_size:\", subg.ndata['reduce_ret_size'])\n",
    "    subg.ndata['ft_size'] += subg.ndata['reduce_ret_size']\n",
    "    print_zeros_in_feat('ft')\n",
    "    print_zeros_in_feat('h')\n",
    "    subg.ndata['ft'] += subg.ndata['h']\n",
    "    print_zeros_in_feat('ft')\n",
    "    print_zeros_in_feat('h')\n",
    "    cur_ft32 = subg.ndata['ft'][32]\n",
    "    if ft32 is not None and torch.eq(cur_ft32, ft32).all():\n",
    "        ft32 = cur_ft32\n",
    "        print(\"ft32 equals!\")\n",
    "    else:\n",
    "        ft32 = cur_ft32\n",
    "        print(\"ft32 not equeal!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    subg.update_all(my_message, my_reduce)\n",
    "    print(\"ret_size of data: \", subg.ndata['reduce_ret_size'])\n",
    "    print(\"convd_size of data: \", subg.ndata['ft_size'])\n",
    "    print(\"subg ft_size:\", subg.ndata['ft_size'])\n",
    "    print(\"subg ret_size:\", subg.ndata['reduce_ret_size'])\n",
    "    subg.ndata['ft_size'] += subg.ndata['reduce_ret_size']\n",
    "    print_zeros_in_feat('ft')\n",
    "    print_zeros_in_feat('h')\n",
    "    subg.ndata['ft'] += subg.ndata['h']\n",
    "    print_zeros_in_feat('ft')\n",
    "    print_zeros_in_feat('h')\n",
    "    cur_ft32 = subg.ndata['ft'][32]\n",
    "    if ft32 is not None and torch.eq(cur_ft32, ft32).all():\n",
    "        ft32 = cur_ft32\n",
    "        print(\"ft32 equals!\")\n",
    "    else:\n",
    "        ft32 = cur_ft32\n",
    "        print(\"ft32 not equeal!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input is the same:  tensor(True)\n"
     ]
    }
   ],
   "source": [
    "cnn_params = None \n",
    "with open(\"./intermediate_data/params.json\", \"r\") as f:\n",
    "    cnn_params = json.load(f)\n",
    "x_in = cnn_params['conv1']['in']\n",
    "print(\"input is the same: \", torch.eq(torch.tensor(x_in), image).all() == True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 1, 1, 28, 28])\n",
      "torch.Size([1, 32, 28, 28])\n",
      "torch.Size([32, 28, 28]) torch.Size([32, 28, 28])\n",
      "conv1 out is the same:  tensor(False, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "ft = g.ndata['ft']\n",
    "mask = g.ndata['tag'] == 0\n",
    "print(ft[mask].size())\n",
    "model_out = ft[mask]\n",
    "out = torch.tensor(cnn_params['conv1']['out'])\n",
    "print(out.size())\n",
    "model_out = model_out.resize_((32, 28, 28)).to(\"cuda\")\n",
    "out = out.resize_((32, 28, 28)).to(\"cuda\")\n",
    "print(model_out.size(), out.size())\n",
    "# conv1 out is the same \n",
    "from torch.nn.functional import relu\n",
    "print(\"conv1 out is the same: \", torch.eq(model_out, relu(out)).all() == True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 32, 28, 28])\n",
      "torch.Size([32, 1, 1, 28, 28])\n",
      "torch.Size([32, 28, 28]) torch.Size([32, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "# checking output by gnn\n",
    "from torch.nn.functional import relu\n",
    "conv2_out = torch.tensor(cnn_params['conv2']['relu'])\n",
    "print(conv2_out.size())\n",
    "gnn2_out = subg.ndata['ft'][32:64]\n",
    "print(gnn2_out.size())\n",
    "conv2_out = conv2_out.resize_((32, 28, 28)).to(\"cuda\")\n",
    "gnn2_out = gnn2_out.resize_((32, 28, 28)).to(\"cuda\")\n",
    "print(conv2_out.size(), gnn2_out.size())\n",
    "import numpy as np\n",
    "for id in range(len(conv2_out)):\n",
    "    np.savetxt(\"./intermediate_data/cnn_out_%d.csv\" % id, conv2_out[id].cpu().numpy(), delimiter=',')\n",
    "    np.savetxt(\"./intermediate_data/gnn_out_%d.csv\" % id, gnn2_out[id].cpu().numpy(), delimiter=',')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data equals but are zero\n",
      "data equals but are zero\n",
      "data equals but are zero\n",
      "data equals but are zero\n",
      "data equals but are zero\n",
      "data equals but are zero\n",
      "data equals but are zero\n",
      "data equals but are zero\n",
      "data equals but are zero\n",
      "data equals but are zero\n",
      "data equals but are zero\n",
      "data equals but are zero\n",
      "data equals but are zero\n",
      "data equals but are zero\n",
      "data equals but are zero\n",
      "data equals but are zero\n",
      "equals:  0\n"
     ]
    }
   ],
   "source": [
    "equals = 0\n",
    "from time import sleep\n",
    "for out_idx in range(len(gnn2_out)):\n",
    "    gf = gnn2_out[out_idx]\n",
    "    for cf in conv2_out:\n",
    "        eq_cond = torch.eq(gf, cf).all() == True\n",
    "        zero_cond = (gf == 0).all() == True\n",
    "        if zero_cond and eq_cond:\n",
    "            print(\"data equals but are zero\")\n",
    "        elif eq_cond and not zero_cond:\n",
    "            print(\"equals and not zeros\")\n",
    "            equals += 1\n",
    "            \n",
    "print(\"equals: \", equals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1554,\n",
       "           0.1550, 0.1550, 0.1550, 0.1550, 0.1550, 0.1550, 0.1550, 0.1550,\n",
       "           0.1550, 0.1550, 0.1550, 0.1550, 0.0779, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2272,\n",
       "           0.2515, 0.2515, 0.2515, 0.2522, 0.2542, 0.2666, 0.2733, 0.2801,\n",
       "           0.2725, 0.2598, 0.2515, 0.2515, 0.1564, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2272,\n",
       "           0.2531, 0.2834, 0.3250, 0.3422, 0.3114, 0.3063, 0.2918, 0.2612,\n",
       "           0.2293, 0.1660, 0.1207, 0.1224, 0.0938, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2272,\n",
       "           0.2559, 0.3255, 0.3973, 0.4188, 0.3293, 0.1949, 0.1498, 0.2362,\n",
       "           0.2447, 0.3720, 0.3786, 0.3279, 0.1776, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2272,\n",
       "           0.2562, 0.3270, 0.4636, 0.6102, 0.6228, 0.5682, 0.3635, 0.4382,\n",
       "           0.4150, 0.4158, 0.4104, 0.3347, 0.1706, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2272,\n",
       "           0.2523, 0.2968, 0.4082, 0.5763, 0.6040, 0.5626, 0.3220, 0.3630,\n",
       "           0.3400, 0.2940, 0.2515, 0.2515, 0.1564, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2272,\n",
       "           0.2515, 0.2521, 0.2723, 0.3587, 0.4775, 0.5059, 0.3851, 0.1763,\n",
       "           0.1691, 0.2425, 0.2515, 0.2515, 0.1564, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2272,\n",
       "           0.2515, 0.2515, 0.2519, 0.3009, 0.3977, 0.4971, 0.5400, 0.4649,\n",
       "           0.2265, 0.1239, 0.2368, 0.2515, 0.1564, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2272,\n",
       "           0.2515, 0.2515, 0.2515, 0.2588, 0.3114, 0.4688, 0.5894, 0.5690,\n",
       "           0.3180, 0.0534, 0.1890, 0.2515, 0.1564, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2272,\n",
       "           0.2515, 0.2551, 0.2892, 0.3469, 0.3809, 0.3962, 0.3928, 0.3182,\n",
       "           0.1986, 0.2473, 0.2567, 0.2531, 0.1564, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2364,\n",
       "           0.3005, 0.3489, 0.3606, 0.3645, 0.3601, 0.2765, 0.2887, 0.3908,\n",
       "           0.3958, 0.3522, 0.2843, 0.2515, 0.1564, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2674,\n",
       "           0.3403, 0.3768, 0.3583, 0.2659, 0.3152, 0.3845, 0.3922, 0.4016,\n",
       "           0.3700, 0.3009, 0.2534, 0.2515, 0.1564, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2688,\n",
       "           0.3560, 0.4570, 0.5038, 0.5145, 0.4927, 0.4248, 0.3646, 0.3014,\n",
       "           0.2548, 0.2515, 0.2515, 0.2515, 0.1564, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2333,\n",
       "           0.3072, 0.3962, 0.4459, 0.4307, 0.3558, 0.2781, 0.2335, 0.2278,\n",
       "           0.2278, 0.2278, 0.2278, 0.2278, 0.1560, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000]]]], device='cuda:0')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subg.ndata['ft'][32]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.13 ('mntd')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2d7768e61f5674adf4efa61c7b8cc3ee2c06ae8f502b5df709cd3e31381a4347"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
