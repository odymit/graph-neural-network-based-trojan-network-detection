{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "05c89f84",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ModelTest(\n",
      "  (conv1): Conv2d(1, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (max_pool_1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (max_pool_2): MaxPool2d(kernel_size=2, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (output): Linear(in_features=512, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "params = torch.load('/home/ubuntu/date/hdd4/shadow_model_ckpt/mnist/models_hetero/target_trojB_226.model')\n",
    "from model_lib.mnist_cnn_model import ModelTest, Model\n",
    "m = ModelTest()\n",
    "m.load_state_dict(params)\n",
    "print(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "67bd0e44",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512, 513])\n",
      "torch.Size([512, 513])\n",
      "torch.Size([512, 513])\n",
      "torch.Size([512, 513])\n",
      "torch.Size([50, 262656])\n",
      "tensor([[ 0,  0,  0,  ..., 46, 47, 48],\n",
      "        [16, 17, 18,  ..., 48, 48, 49]])\n",
      "  (0, 16)\t1.0\n",
      "  (0, 17)\t1.0\n",
      "  (0, 18)\t1.0\n",
      "  (0, 19)\t1.0\n",
      "  (0, 20)\t1.0\n",
      "  (0, 21)\t1.0\n",
      "  (0, 22)\t1.0\n",
      "  (0, 23)\t1.0\n",
      "  (0, 24)\t1.0\n",
      "  (0, 25)\t1.0\n",
      "  (0, 26)\t1.0\n",
      "  (0, 27)\t1.0\n",
      "  (0, 28)\t1.0\n",
      "  (0, 29)\t1.0\n",
      "  (0, 30)\t1.0\n",
      "  (0, 31)\t1.0\n",
      "  (0, 32)\t1.0\n",
      "  (0, 33)\t1.0\n",
      "  (0, 34)\t1.0\n",
      "  (0, 35)\t1.0\n",
      "  (0, 36)\t1.0\n",
      "  (0, 37)\t1.0\n",
      "  (0, 38)\t1.0\n",
      "  (0, 39)\t1.0\n",
      "  (0, 40)\t1.0\n",
      "  :\t:\n",
      "  (24, 48)\t1.0\n",
      "  (25, 48)\t1.0\n",
      "  (26, 48)\t1.0\n",
      "  (27, 48)\t1.0\n",
      "  (28, 48)\t1.0\n",
      "  (29, 48)\t1.0\n",
      "  (30, 48)\t1.0\n",
      "  (31, 48)\t1.0\n",
      "  (32, 48)\t1.0\n",
      "  (33, 48)\t1.0\n",
      "  (34, 48)\t1.0\n",
      "  (35, 48)\t1.0\n",
      "  (36, 48)\t1.0\n",
      "  (37, 48)\t1.0\n",
      "  (38, 48)\t1.0\n",
      "  (39, 48)\t1.0\n",
      "  (40, 48)\t1.0\n",
      "  (41, 48)\t1.0\n",
      "  (42, 48)\t1.0\n",
      "  (43, 48)\t1.0\n",
      "  (44, 48)\t1.0\n",
      "  (45, 48)\t1.0\n",
      "  (46, 48)\t1.0\n",
      "  (47, 48)\t1.0\n",
      "  (48, 49)\t1.0\n"
     ]
    }
   ],
   "source": [
    "# Load and preprocess data\n",
    "import torch\n",
    "TRAIN_NUM = 10\n",
    "VAL_NUM = 10\n",
    "TEST_NUM = 10\n",
    "shadow_path = './shadow_model_ckpt/%s/models' % 'mnist'\n",
    "train_dataset = []\n",
    "for i in range(TRAIN_NUM):\n",
    "    x = shadow_path + '/shadow_jumbo_%d.model'%i\n",
    "    train_dataset.append((x,1))\n",
    "    x = shadow_path + '/shadow_benign_%d.model'%i\n",
    "    train_dataset.append((x,0))\n",
    "\n",
    "val_dataset = []\n",
    "for i in range(TRAIN_NUM, TRAIN_NUM+VAL_NUM):\n",
    "    x = shadow_path + '/shadow_jumbo_%d.model'%i\n",
    "    val_dataset.append((x,1))\n",
    "    x = shadow_path + '/shadow_benign_%d.model'%i\n",
    "    val_dataset.append((x,0))\n",
    "\n",
    "test_dataset = []\n",
    "for i in range(TEST_NUM):\n",
    "    x = shadow_path + '/target_troj%s_%d.model'%('M', i)\n",
    "    test_dataset.append((x,1))\n",
    "    x = shadow_path + '/target_benign_%d.model'%i\n",
    "    test_dataset.append((x,0))\n",
    "\n",
    "# print(train_dataset, val_dataset, test_dataset)\n",
    "import numpy as np \n",
    "from torchsummary import summary\n",
    "from model_lib.mnist_cnn_model import Model\n",
    "from torch import nn\n",
    "from cogdl.data import Graph\n",
    "\n",
    "m = None \n",
    "def load_dataset(dataset):\n",
    "    perm = np.random.permutation(len(dataset))\n",
    "    graphs = []\n",
    "    \n",
    "    for i in perm:\n",
    "        x, y = dataset[i]\n",
    "        label = torch.IntTensor([y])\n",
    "#         print(label)\n",
    "        basic_model = Model()\n",
    "        t = torch.load(x)\n",
    "        t = basic_model.load_state_dict(t)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            # nodes_feat 512 * 513\n",
    "            nodes_feat = []\n",
    "            cnt = 0\n",
    "            # get conv1 nodes \n",
    "            conv1 = {}\n",
    "            for weight in basic_model.conv1.weight:\n",
    "                pad = nn.ZeroPad2d(padding=(254,254,253,254))\n",
    "                feat = pad(weight[0])\n",
    "                conv1[cnt] = feat\n",
    "                nodes_feat.append(torch.reshape(feat, (1, 262656))[0])\n",
    "                cnt += 1\n",
    "            print(conv1[0].shape)\n",
    "            # get conv2 nodes\n",
    "            conv2 = {}\n",
    "            for weight in basic_model.conv2.weight:\n",
    "                pad = nn.ZeroPad2d(padding=(254,254,253,254))\n",
    "                feat = pad(weight[0])\n",
    "                conv2[cnt] = feat\n",
    "                nodes_feat.append(torch.reshape(feat, (1, 262656))[0])\n",
    "                cnt += 1\n",
    "            print(conv2[16].shape)\n",
    "            # get conv1 -> conv2 edges\n",
    "            conv1_2 = []\n",
    "            for src in conv1.keys():\n",
    "                for dst in conv2.keys():\n",
    "                    conv1_2.append([src, dst])\n",
    "\n",
    "\n",
    "            # get fc node\n",
    "            fc_index = cnt\n",
    "            cnt += 1\n",
    "            fc_node = torch.concat([basic_model.fc.weight, basic_model.fc.bias.reshape(512, 1)], 1)\n",
    "            nodes_feat.append(torch.reshape(fc_node, (1, 262656))[0])\n",
    "            print(fc_node.shape)\n",
    "\n",
    "            # get conv2 -> fc edges\n",
    "            conv2_fc = []\n",
    "            for src in conv2.keys():\n",
    "                conv2_fc.append([src, fc_index])\n",
    "\n",
    "            # get output node\n",
    "            out_index = cnt\n",
    "            cnt += 1 \n",
    "            out = torch.concat([basic_model.output.weight, basic_model.output.bias.reshape(10, 1)], 1)\n",
    "            pad = nn.ZeroPad2d(padding=(0,0,251,251))\n",
    "            out_node = pad(out)\n",
    "            nodes_feat.append(torch.reshape(out_node, (1, 262656))[0])\n",
    "\n",
    "            print(out_node.shape)\n",
    "\n",
    "            # get fc -> output edge\n",
    "            fc_out_edge = [[fc_index, out_index]]\n",
    "\n",
    "            # get all nodes\n",
    "            nodes_feat = torch.stack(nodes_feat)\n",
    "            print(nodes_feat.shape)\n",
    "            # get all edges\n",
    "            all_edges = torch.tensor(conv1_2 + conv2_fc + fc_out_edge).t()\n",
    "            print(all_edges)\n",
    "            g = Graph(edge_index=all_edges,x=nodes_feat, y=label)\n",
    "            print(g.to_scipy_csr())\n",
    "#             print(\"nodes:\", g.num_nodes)\n",
    "#             print(\"edges:\", g.num_edges)\n",
    "            graphs.append(g)\n",
    "            break\n",
    "    return graphs\n",
    "        \n",
    "res = load_dataset(train_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c24202",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "x =torch.tensor([[0,1],[1,3],[2,1],[4,2],[0,3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b7b125",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "x = torch.tensor([[-1,1],[0,1],[1,1],[2,1],[3,1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeff6fb6",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "torch.reshape(x, (1,10))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d34658",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from cogdl.data import Graph\n",
    "edges = torch.tensor([[0,1],[1,3],[2,1],[4,2],[0,3]]).t()\n",
    "x = torch.tensor([[-1],[0],[1],[2],[3]])\n",
    "g = Graph(edge_index=edges,x=x) # equivalent to that above\n",
    "print(g.edges())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a482e3d8",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import hiddenlayer as hl\n",
    "print(m)\n",
    "# summary(basic_model, (1, 28, 28))\n",
    "hl.build_graph(m, torch.zeros([1, 1, 28, 28]).cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b31d71",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from cogdl.data import Graph\n",
    "from cogdl.datasets import GraphDataset\n",
    "import gc\n",
    "import torch\n",
    "import numpy as np\n",
    "from model_lib.mnist_cnn_model import Model\n",
    "from torch import nn\n",
    "\n",
    "class MyGraphDataset(GraphDataset):\n",
    "    def __init__(self, path=\"./shadow_model_ckpt/mnist/train-data.pt\"):\n",
    "        self.path = path\n",
    "        super(MyGraphDataset, self).__init__(path, metric=\"accuracy\")\n",
    "\n",
    "    def process(self):\n",
    "        # Load and preprocess data\n",
    "        # Here we randomly generate several graphs for simplicity as an example\n",
    "        # TRAIN_NUM = 2048\n",
    "        TRAIN_NUM = 256\n",
    "        VAL_NUM = 256\n",
    "        TEST_NUM = 256\n",
    "        shadow_path = './shadow_model_ckpt/%s/models' % 'mnist'\n",
    "        graphs = []\n",
    "\n",
    "        train_dataset = []\n",
    "        for i in range(TRAIN_NUM):\n",
    "            x = shadow_path + '/shadow_jumbo_%d.model'%i\n",
    "            train_dataset.append((x,1))\n",
    "            x = shadow_path + '/shadow_benign_%d.model'%i\n",
    "            train_dataset.append((x,0))\n",
    "        graphs += self.load_dataset(train_dataset)\n",
    "        del train_dataset\n",
    "        gc.collect()\n",
    "        \n",
    "        val_dataset = []\n",
    "        for i in range(TRAIN_NUM, TRAIN_NUM+VAL_NUM):\n",
    "            x = shadow_path + '/shadow_jumbo_%d.model'%i\n",
    "            val_dataset.append((x,1))\n",
    "            x = shadow_path + '/shadow_benign_%d.model'%i\n",
    "            val_dataset.append((x,0))\n",
    "        graphs += self.load_dataset(val_dataset)\n",
    "        del val_dataset\n",
    "        gc.collect()\n",
    "        \n",
    "        test_dataset = []\n",
    "        for i in range(TEST_NUM):\n",
    "            x = shadow_path + '/target_troj%s_%d.model'%('M', i)\n",
    "            test_dataset.append((x,1))\n",
    "            x = shadow_path + '/target_benign_%d.model'%i\n",
    "            test_dataset.append((x,0))\n",
    "        graphs += self.load_dataset(test_dataset)\n",
    "        del test_dataset\n",
    "        gc.collect()\n",
    "\n",
    "        return graphs\n",
    "    \n",
    "    def load_dataset(self, dataset):\n",
    "        perm = np.random.permutation(len(dataset))\n",
    "        graphs = []\n",
    "\n",
    "        for i in perm:\n",
    "            x, y = dataset[i]\n",
    "            label = torch.IntTensor([y])\n",
    "    #         print(label)\n",
    "            basic_model = Model().cuda()\n",
    "            t = torch.load(x)\n",
    "            t = basic_model.load_state_dict(t)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                # nodes_feat 512 * 513\n",
    "                nodes_feat = []\n",
    "                cnt = 0\n",
    "                # get conv1 nodes \n",
    "                conv1 = {}\n",
    "                for weight in basic_model.conv1.weight:\n",
    "                    pad = nn.ZeroPad2d(padding=(254,254,253,254))\n",
    "                    feat = pad(weight[0])\n",
    "                    conv1[cnt] = feat\n",
    "                    nodes_feat.append(feat)\n",
    "                    cnt += 1\n",
    "\n",
    "                # get conv2 nodes\n",
    "                conv2 = {}\n",
    "                for weight in basic_model.conv2.weight:\n",
    "                    pad = nn.ZeroPad2d(padding=(254,254,253,254))\n",
    "                    feat = pad(weight[0])\n",
    "                    conv2[cnt] = feat\n",
    "                    nodes_feat.append(feat)\n",
    "                    cnt += 1\n",
    "\n",
    "                # get conv1 -> conv2 edges\n",
    "                conv1_2 = []\n",
    "                for src in conv1.keys():\n",
    "                    for dst in conv2.keys():\n",
    "                        conv1_2.append([src, dst])\n",
    "\n",
    "\n",
    "                # get fc node\n",
    "                fc_index = cnt\n",
    "                cnt += 1\n",
    "                fc_node = torch.concat([basic_model.fc.weight, basic_model.fc.bias.reshape(512, 1)], 1)\n",
    "                nodes_feat.append(fc_node)\n",
    "                # print(fc_node.shape)\n",
    "\n",
    "                # get conv2 -> fc edges\n",
    "                conv2_fc = []\n",
    "                for src in conv2.keys():\n",
    "                    conv2_fc.append([src, fc_index])\n",
    "\n",
    "                # get output node\n",
    "                out_index = cnt\n",
    "                cnt += 1 \n",
    "                out = torch.concat([basic_model.output.weight, basic_model.output.bias.reshape(10, 1)], 1)\n",
    "                pad = nn.ZeroPad2d(padding=(0,0,251,251))\n",
    "                out_node = pad(out)\n",
    "                nodes_feat.append(out_node)\n",
    "\n",
    "                # print(out_node.shape)\n",
    "\n",
    "                # get fc -> output edge\n",
    "                fc_out_edge = [[fc_index, out_index]]\n",
    "\n",
    "                # get all nodes\n",
    "                nodes_feat = torch.stack(nodes_feat)\n",
    "                # print(nodes_feat.shape)\n",
    "                # get all edges\n",
    "                all_edges = torch.tensor(conv1_2 + conv2_fc + fc_out_edge).t()\n",
    "\n",
    "                g = Graph(edge_index=all_edges,x=nodes_feat, y=label)\n",
    "    #             print(\"nodes:\", g.num_nodes)\n",
    "    #             print(\"edges:\", g.num_edges)\n",
    "                graphs.append(g)\n",
    "        return graphs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd9d6c9",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    dataset = MyGraphDataset()\n",
    "    experiment(model=\"gin\", dataset=dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da025e73",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fcdb6d6",
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from cogdl.data import Graph\n",
    "edges = torch.tensor([[0,1],[1,3],[2,1],[4,2],[0,3]]).t()\n",
    "x = torch.tensor([[-1],[0],[1],[2],[3]])\n",
    "g = Graph(edge_index=edges,x=x) # equivalent to that above\n",
    "print(g.edges())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6cc14a7e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model(\n",
      "  (conv1): Conv2d(1, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (max_pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (output): Linear(in_features=512, out_features=10, bias=True)\n",
      ")\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.38.0 (20140413.2041)\n",
       " -->\n",
       "<!-- Title: %3 Pages: 1 -->\n",
       "<svg width=\"851pt\" height=\"216pt\"\n",
       " viewBox=\"0.00 0.00 851.00 216.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(72 180)\">\n",
       "<title>%3</title>\n",
       "<polygon fill=\"#ffffff\" stroke=\"none\" points=\"-72,36 -72,-180 779,-180 779,36 -72,36\"/>\n",
       "<!-- /outputs/9 -->\n",
       "<g id=\"node1\" class=\"node\"><title>/outputs/9</title>\n",
       "<polygon fill=\"#e8e8e8\" stroke=\"#000000\" points=\"69.5,-90 15.5,-90 15.5,-54 69.5,-54 69.5,-90\"/>\n",
       "<text text-anchor=\"start\" x=\"30.5\" y=\"-69\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">Shape</text>\n",
       "</g>\n",
       "<!-- /outputs/11 -->\n",
       "<g id=\"node3\" class=\"node\"><title>/outputs/11</title>\n",
       "<polygon fill=\"#e8e8e8\" stroke=\"#000000\" points=\"183,-90 129,-90 129,-54 183,-54 183,-90\"/>\n",
       "<text text-anchor=\"start\" x=\"142\" y=\"-69\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">Gather</text>\n",
       "</g>\n",
       "<!-- /outputs/9&#45;&gt;/outputs/11 -->\n",
       "<g id=\"edge1\" class=\"edge\"><title>/outputs/9&#45;&gt;/outputs/11</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M69.6418,-72C84.2149,-72 102.591,-72 118.556,-72\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"118.636,-75.5001 128.636,-72 118.636,-68.5001 118.636,-75.5001\"/>\n",
       "</g>\n",
       "<!-- /outputs/10 -->\n",
       "<g id=\"node2\" class=\"node\"><title>/outputs/10</title>\n",
       "<polygon fill=\"#e8e8e8\" stroke=\"#000000\" points=\"69.5,-144 15.5,-144 15.5,-108 69.5,-108 69.5,-144\"/>\n",
       "<text text-anchor=\"start\" x=\"24.5\" y=\"-123\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">Constant</text>\n",
       "</g>\n",
       "<!-- /outputs/10&#45;&gt;/outputs/11 -->\n",
       "<g id=\"edge2\" class=\"edge\"><title>/outputs/10&#45;&gt;/outputs/11</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M69.6418,-113.339C84.4925,-106.147 103.292,-97.0424 119.466,-89.2094\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"121.161,-92.2772 128.636,-84.7684 118.11,-85.9772 121.161,-92.2772\"/>\n",
       "</g>\n",
       "<!-- /outputs/19 -->\n",
       "<g id=\"node7\" class=\"node\"><title>/outputs/19</title>\n",
       "<polygon fill=\"#e8e8e8\" stroke=\"#000000\" points=\"300.5,-90 238.5,-90 238.5,-54 300.5,-54 300.5,-90\"/>\n",
       "<text text-anchor=\"start\" x=\"246.5\" y=\"-69\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">Unsqueeze</text>\n",
       "</g>\n",
       "<!-- /outputs/11&#45;&gt;/outputs/19 -->\n",
       "<g id=\"edge3\" class=\"edge\"><title>/outputs/11&#45;&gt;/outputs/19</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M183.142,-72C196.53,-72 213.128,-72 228.118,-72\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"228.179,-75.5001 238.179,-72 228.179,-68.5001 228.179,-75.5001\"/>\n",
       "</g>\n",
       "<!-- /outputs/14 -->\n",
       "<g id=\"node4\" class=\"node\"><title>/outputs/14</title>\n",
       "<polygon fill=\"#e8e8e8\" stroke=\"#000000\" points=\"191,-36 121,-36 121,-0 191,-0 191,-36\"/>\n",
       "<text text-anchor=\"start\" x=\"129\" y=\"-15\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">MaxPool2x2</text>\n",
       "</g>\n",
       "<!-- 15547298524717558442 -->\n",
       "<g id=\"node13\" class=\"node\"><title>15547298524717558442</title>\n",
       "<polygon fill=\"#e8e8e8\" stroke=\"#000000\" points=\"312,-36 227,-36 227,-0 312,-0 312,-36\"/>\n",
       "<text text-anchor=\"start\" x=\"235.5\" y=\"-15\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">Conv5x5 &gt; Relu</text>\n",
       "</g>\n",
       "<!-- /outputs/14&#45;&gt;15547298524717558442 -->\n",
       "<g id=\"edge10\" class=\"edge\"><title>/outputs/14&#45;&gt;15547298524717558442</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M191.06,-18C199.161,-18 207.986,-18 216.684,-18\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"216.783,-21.5001 226.783,-18 216.783,-14.5001 216.783,-21.5001\"/>\n",
       "</g>\n",
       "<!-- /outputs/17 -->\n",
       "<g id=\"node5\" class=\"node\"><title>/outputs/17</title>\n",
       "<polygon fill=\"#e8e8e8\" stroke=\"#000000\" points=\"418,-36 348,-36 348,-0 418,-0 418,-36\"/>\n",
       "<text text-anchor=\"start\" x=\"356\" y=\"-15\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">MaxPool2x2</text>\n",
       "</g>\n",
       "<!-- /outputs/22 -->\n",
       "<g id=\"node10\" class=\"node\"><title>/outputs/22</title>\n",
       "<polygon fill=\"#e8e8e8\" stroke=\"#000000\" points=\"508,-63 454,-63 454,-27 508,-27 508,-63\"/>\n",
       "<text text-anchor=\"start\" x=\"464\" y=\"-42\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">Reshape</text>\n",
       "</g>\n",
       "<!-- /outputs/17&#45;&gt;/outputs/22 -->\n",
       "<g id=\"edge4\" class=\"edge\"><title>/outputs/17&#45;&gt;/outputs/22</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M418.116,-27.5952C426.561,-29.9702 435.632,-32.5216 444.156,-34.919\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"443.267,-38.3045 453.841,-37.6428 445.162,-31.5659 443.267,-38.3045\"/>\n",
       "</g>\n",
       "<!-- /outputs/18 -->\n",
       "<g id=\"node6\" class=\"node\"><title>/outputs/18</title>\n",
       "<polygon fill=\"#e8e8e8\" stroke=\"#000000\" points=\"183,-144 129,-144 129,-108 183,-108 183,-144\"/>\n",
       "<text text-anchor=\"start\" x=\"138\" y=\"-123\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">Constant</text>\n",
       "</g>\n",
       "<!-- /outputs/20 -->\n",
       "<g id=\"node8\" class=\"node\"><title>/outputs/20</title>\n",
       "<polygon fill=\"#e8e8e8\" stroke=\"#000000\" points=\"300.5,-144 238.5,-144 238.5,-108 300.5,-108 300.5,-144\"/>\n",
       "<text text-anchor=\"start\" x=\"246.5\" y=\"-123\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">Unsqueeze</text>\n",
       "</g>\n",
       "<!-- /outputs/18&#45;&gt;/outputs/20 -->\n",
       "<g id=\"edge5\" class=\"edge\"><title>/outputs/18&#45;&gt;/outputs/20</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M183.142,-126C196.53,-126 213.128,-126 228.118,-126\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"228.179,-129.5 238.179,-126 228.179,-122.5 228.179,-129.5\"/>\n",
       "</g>\n",
       "<!-- /outputs/21 -->\n",
       "<g id=\"node9\" class=\"node\"><title>/outputs/21</title>\n",
       "<polygon fill=\"#e8e8e8\" stroke=\"#000000\" points=\"410,-90 356,-90 356,-54 410,-54 410,-90\"/>\n",
       "<text text-anchor=\"start\" x=\"368\" y=\"-69\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">Concat</text>\n",
       "</g>\n",
       "<!-- /outputs/19&#45;&gt;/outputs/21 -->\n",
       "<g id=\"edge6\" class=\"edge\"><title>/outputs/19&#45;&gt;/outputs/21</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M300.674,-72C314.582,-72 331.202,-72 345.782,-72\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"345.97,-75.5001 355.97,-72 345.97,-68.5001 345.97,-75.5001\"/>\n",
       "</g>\n",
       "<!-- /outputs/20&#45;&gt;/outputs/21 -->\n",
       "<g id=\"edge7\" class=\"edge\"><title>/outputs/20&#45;&gt;/outputs/21</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M300.674,-111.387C314.852,-104.52 331.849,-96.2884 346.629,-89.1302\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"348.496,-92.1151 355.97,-84.6063 345.445,-85.8151 348.496,-92.1151\"/>\n",
       "</g>\n",
       "<!-- /outputs/21&#45;&gt;/outputs/22 -->\n",
       "<g id=\"edge8\" class=\"edge\"><title>/outputs/21&#45;&gt;/outputs/22</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M410.232,-64.6221C420.603,-61.7053 432.694,-58.3047 443.869,-55.1617\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"445.12,-58.4458 453.799,-52.3689 443.225,-51.7072 445.12,-58.4458\"/>\n",
       "</g>\n",
       "<!-- 4540290768618378616 -->\n",
       "<g id=\"node14\" class=\"node\"><title>4540290768618378616</title>\n",
       "<polygon fill=\"#e8e8e8\" stroke=\"#000000\" points=\"617,-63 544,-63 544,-27 617,-27 617,-63\"/>\n",
       "<text text-anchor=\"start\" x=\"552.5\" y=\"-42\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">Linear &gt; Relu</text>\n",
       "</g>\n",
       "<!-- /outputs/22&#45;&gt;4540290768618378616 -->\n",
       "<g id=\"edge12\" class=\"edge\"><title>/outputs/22&#45;&gt;4540290768618378616</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M508.128,-45C515.994,-45 524.868,-45 533.619,-45\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"533.768,-48.5001 543.768,-45 533.768,-41.5001 533.768,-48.5001\"/>\n",
       "</g>\n",
       "<!-- /outputs/25 -->\n",
       "<g id=\"node11\" class=\"node\"><title>/outputs/25</title>\n",
       "<polygon fill=\"#e8e8e8\" stroke=\"#000000\" points=\"707,-63 653,-63 653,-27 707,-27 707,-63\"/>\n",
       "<text text-anchor=\"start\" x=\"667\" y=\"-42\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">Linear</text>\n",
       "</g>\n",
       "<!-- 4496806174641778114 -->\n",
       "<g id=\"node12\" class=\"node\"><title>4496806174641778114</title>\n",
       "<polygon fill=\"#e8e8e8\" stroke=\"#000000\" points=\"85,-36 0,-36 0,-0 85,-0 85,-36\"/>\n",
       "<text text-anchor=\"start\" x=\"8.5\" y=\"-15\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">Conv5x5 &gt; Relu</text>\n",
       "</g>\n",
       "<!-- 4496806174641778114&#45;&gt;/outputs/14 -->\n",
       "<g id=\"edge9\" class=\"edge\"><title>4496806174641778114&#45;&gt;/outputs/14</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M85.0185,-18C93.382,-18 102.203,-18 110.659,-18\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"110.736,-21.5001 120.736,-18 110.736,-14.5001 110.736,-21.5001\"/>\n",
       "</g>\n",
       "<!-- 15547298524717558442&#45;&gt;/outputs/17 -->\n",
       "<g id=\"edge11\" class=\"edge\"><title>15547298524717558442&#45;&gt;/outputs/17</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M312.018,-18C320.382,-18 329.203,-18 337.659,-18\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"337.736,-21.5001 347.736,-18 337.736,-14.5001 337.736,-21.5001\"/>\n",
       "</g>\n",
       "<!-- 4540290768618378616&#45;&gt;/outputs/25 -->\n",
       "<g id=\"edge13\" class=\"edge\"><title>4540290768618378616&#45;&gt;/outputs/25</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M617.252,-45C625.506,-45 634.296,-45 642.579,-45\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"642.719,-48.5001 652.719,-45 642.719,-41.5001 642.719,-48.5001\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<hiddenlayer.graph.Graph at 0x7fd5d97d5a10>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import hiddenlayer as hl\n",
    "print(m)\n",
    "# summary(basic_model, (1, 28, 28))\n",
    "hl.build_graph(m, torch.zeros([1, 1, 28, 28]).cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dc281f6a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from cogdl.data import Graph\n",
    "from cogdl.datasets import GraphDataset\n",
    "import gc\n",
    "import torch\n",
    "import numpy as np\n",
    "from model_lib.mnist_cnn_model import Model\n",
    "from torch import nn\n",
    "\n",
    "class MyGraphDataset(GraphDataset):\n",
    "    def __init__(self, path=\"./shadow_model_ckpt/mnist/train-data.pt\"):\n",
    "        self.path = path\n",
    "        super(MyGraphDataset, self).__init__(path, metric=\"accuracy\")\n",
    "\n",
    "    def process(self):\n",
    "        # Load and preprocess data\n",
    "        # Here we randomly generate several graphs for simplicity as an example\n",
    "        # TRAIN_NUM = 2048\n",
    "        TRAIN_NUM = 256\n",
    "        VAL_NUM = 256\n",
    "        TEST_NUM = 256\n",
    "        shadow_path = './shadow_model_ckpt/%s/models' % 'mnist'\n",
    "        graphs = []\n",
    "\n",
    "        train_dataset = []\n",
    "        for i in range(TRAIN_NUM):\n",
    "            x = shadow_path + '/shadow_jumbo_%d.model'%i\n",
    "            train_dataset.append((x,1))\n",
    "            x = shadow_path + '/shadow_benign_%d.model'%i\n",
    "            train_dataset.append((x,0))\n",
    "        graphs += self.load_dataset(train_dataset)\n",
    "        del train_dataset\n",
    "        gc.collect()\n",
    "        \n",
    "        val_dataset = []\n",
    "        for i in range(TRAIN_NUM, TRAIN_NUM+VAL_NUM):\n",
    "            x = shadow_path + '/shadow_jumbo_%d.model'%i\n",
    "            val_dataset.append((x,1))\n",
    "            x = shadow_path + '/shadow_benign_%d.model'%i\n",
    "            val_dataset.append((x,0))\n",
    "        graphs += self.load_dataset(val_dataset)\n",
    "        del val_dataset\n",
    "        gc.collect()\n",
    "        \n",
    "        test_dataset = []\n",
    "        for i in range(TEST_NUM):\n",
    "            x = shadow_path + '/target_troj%s_%d.model'%('M', i)\n",
    "            test_dataset.append((x,1))\n",
    "            x = shadow_path + '/target_benign_%d.model'%i\n",
    "            test_dataset.append((x,0))\n",
    "        graphs += self.load_dataset(test_dataset)\n",
    "        del test_dataset\n",
    "        gc.collect()\n",
    "\n",
    "        return graphs\n",
    "    \n",
    "    def load_dataset(self, dataset):\n",
    "        perm = np.random.permutation(len(dataset))\n",
    "        graphs = []\n",
    "\n",
    "        for i in perm:\n",
    "            x, y = dataset[i]\n",
    "            label = torch.IntTensor([y])\n",
    "    #         print(label)\n",
    "            basic_model = Model().cuda()\n",
    "            t = torch.load(x)\n",
    "            t = basic_model.load_state_dict(t)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                # nodes_feat 512 * 513\n",
    "                nodes_feat = []\n",
    "                cnt = 0\n",
    "                # get conv1 nodes \n",
    "                conv1 = {}\n",
    "                for weight in basic_model.conv1.weight:\n",
    "                    pad = nn.ZeroPad2d(padding=(254,254,253,254))\n",
    "                    feat = pad(weight[0])\n",
    "                    conv1[cnt] = feat\n",
    "                    nodes_feat.append(feat)\n",
    "                    cnt += 1\n",
    "\n",
    "                # get conv2 nodes\n",
    "                conv2 = {}\n",
    "                for weight in basic_model.conv2.weight:\n",
    "                    pad = nn.ZeroPad2d(padding=(254,254,253,254))\n",
    "                    feat = pad(weight[0])\n",
    "                    conv2[cnt] = feat\n",
    "                    nodes_feat.append(feat)\n",
    "                    cnt += 1\n",
    "\n",
    "                # get conv1 -> conv2 edges\n",
    "                conv1_2 = []\n",
    "                for src in conv1.keys():\n",
    "                    for dst in conv2.keys():\n",
    "                        conv1_2.append([src, dst])\n",
    "\n",
    "\n",
    "                # get fc node\n",
    "                fc_index = cnt\n",
    "                cnt += 1\n",
    "                fc_node = torch.concat([basic_model.fc.weight, basic_model.fc.bias.reshape(512, 1)], 1)\n",
    "                nodes_feat.append(fc_node)\n",
    "                # print(fc_node.shape)\n",
    "\n",
    "                # get conv2 -> fc edges\n",
    "                conv2_fc = []\n",
    "                for src in conv2.keys():\n",
    "                    conv2_fc.append([src, fc_index])\n",
    "\n",
    "                # get output node\n",
    "                out_index = cnt\n",
    "                cnt += 1 \n",
    "                out = torch.concat([basic_model.output.weight, basic_model.output.bias.reshape(10, 1)], 1)\n",
    "                pad = nn.ZeroPad2d(padding=(0,0,251,251))\n",
    "                out_node = pad(out)\n",
    "                nodes_feat.append(out_node)\n",
    "\n",
    "                # print(out_node.shape)\n",
    "\n",
    "                # get fc -> output edge\n",
    "                fc_out_edge = [[fc_index, out_index]]\n",
    "\n",
    "                # get all nodes\n",
    "                nodes_feat = torch.stack(nodes_feat)\n",
    "                # print(nodes_feat.shape)\n",
    "                # get all edges\n",
    "                all_edges = torch.tensor(conv1_2 + conv2_fc + fc_out_edge).t()\n",
    "\n",
    "                g = Graph(edge_index=all_edges,x=nodes_feat, y=label)\n",
    "    #             print(\"nodes:\", g.num_nodes)\n",
    "    #             print(\"edges:\", g.num_edges)\n",
    "                graphs.append(g)\n",
    "        return graphs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7d661127",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "data = torch.load('/home/ubuntu/date/hdd4/shadow_model_ckpt/mnist/processed_data/shadow_benign_0.model.pth')\n",
    "from cogdl.data import Graph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1fbd8028",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "545\n"
     ]
    }
   ],
   "source": [
    "g = Graph(edge_index=data['edges'], y=data['y'])\n",
    "print(g.num_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6aa76c48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 30])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edges.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1c5fb8a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 545])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['edges'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b407fe70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n"
     ]
    }
   ],
   "source": [
    "edges = torch.randint(0, 20, (2, 30))\n",
    "label = torch.randint(0, 7, (1,))\n",
    "gg = Graph(edge_index=edges, y=label)\n",
    "print(gg.num_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ba03994f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 52.00 MiB (GPU 0; 10.76 GiB total capacity; 8.36 GiB already allocated; 32.44 MiB free; 8.48 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_11576/2346841383.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMyGraphDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mexperiment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"gin\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_11576/2700614631.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"./shadow_model_ckpt/mnist/train-data.pt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMyGraphDataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"accuracy\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/envs/cogdl/lib/python3.7/site-packages/cogdl/datasets/customized_data.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path, metric)\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"cus_graph_data.pt\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"accuracy\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mGraphDataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m         \u001b[0;31m# try:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/envs/cogdl/lib/python3.7/site-packages/cogdl/data/dataset.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, transform, pre_transform, pre_filter)\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mMultiGraphDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpre_transform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpre_filter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMultiGraphDataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpre_transform\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpre_filter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mslices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/envs/cogdl/lib/python3.7/site-packages/cogdl/data/dataset.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, transform, pre_transform, pre_filter)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_download\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/envs/cogdl/lib/python3.7/site-packages/cogdl/datasets/customized_data.py\u001b[0m in \u001b[0;36m_process\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_11576/2700614631.py\u001b[0m in \u001b[0;36mprocess\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshadow_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/shadow_benign_%d.model'\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0mgraphs\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_11576/2700614631.py\u001b[0m in \u001b[0;36mload_dataset\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m                 \u001b[0;31m# get all nodes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m                 \u001b[0mnodes_feat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnodes_feat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m                 \u001b[0;31m# print(nodes_feat.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m                 \u001b[0;31m# get all edges\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 52.00 MiB (GPU 0; 10.76 GiB total capacity; 8.36 GiB already allocated; 32.44 MiB free; 8.48 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    dataset = MyGraphDataset()\n",
    "    experiment(model=\"gin\", dataset=dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5d980e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Model5(nn.Module):\n",
    "    def __init__(self, gpu=False):\n",
    "        super(Model5, self).__init__()\n",
    "        self.gpu = gpu\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv4 = nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv5 = nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv6 = nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1)\n",
    "        self.max_pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.linear = nn.Linear(256*4*4, 512)\n",
    "        self.fc1 = nn.Linear(512, 256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.output = nn.Linear(128, 10)\n",
    "\n",
    "\n",
    "        if gpu:\n",
    "            self.cuda()\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.gpu:\n",
    "            x = x.cuda()\n",
    "        B = x.size()[0]\n",
    "\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.max_pool(F.relu(self.conv2(x)))\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = self.max_pool(F.relu(self.conv4(x)))\n",
    "        x = F.relu(self.conv5(x))\n",
    "        x = self.max_pool(F.relu(self.conv6(x)))\n",
    "        x = F.relu(self.linear(x.view(B,256*4*4)))\n",
    "        x = F.dropout(F.relu(self.fc1(x)), 0.5, training=self.training)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.output(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def loss(self, pred, label):\n",
    "        if self.gpu:\n",
    "            label = label.cuda()\n",
    "        return F.cross_entropy(pred, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1cdeeeaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 32, 32, 32]             896\n",
      "            Conv2d-2           [-1, 64, 32, 32]          18,496\n",
      "         MaxPool2d-3           [-1, 64, 16, 16]               0\n",
      "            Conv2d-4          [-1, 128, 16, 16]          73,856\n",
      "            Conv2d-5          [-1, 128, 16, 16]         147,584\n",
      "         MaxPool2d-6            [-1, 128, 8, 8]               0\n",
      "            Conv2d-7            [-1, 256, 8, 8]         295,168\n",
      "            Conv2d-8            [-1, 256, 8, 8]         590,080\n",
      "         MaxPool2d-9            [-1, 256, 4, 4]               0\n",
      "           Linear-10                  [-1, 512]       2,097,664\n",
      "           Linear-11                  [-1, 256]         131,328\n",
      "           Linear-12                  [-1, 128]          32,896\n",
      "           Linear-13                   [-1, 10]           1,290\n",
      "================================================================\n",
      "Total params: 3,389,258\n",
      "Trainable params: 3,389,258\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 1.73\n",
      "Params size (MB): 12.93\n",
      "Estimated Total Size (MB): 14.67\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "m = Model5().cuda()\n",
    "summary(m, (3,32,32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d534b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b2a79e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:cogdl]",
   "language": "python",
   "name": "conda-env-cogdl-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
