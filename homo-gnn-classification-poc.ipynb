{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e9ac4d52",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 简单图网络后门检测任务 PoC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a7ca79d",
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.10.1+cu102'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "71978209",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "768\n",
      "Graph(num_nodes=50, num_edges=545,\n",
      "      ndata_schemes={'x': Scheme(shape=(512, 513), dtype=torch.float32)}\n",
      "      edata_schemes={}) 1\n"
     ]
    }
   ],
   "source": [
    "from dgl.data.dgl_dataset import DGLBuiltinDataset\n",
    "from model_lib.mnist_cnn_model import Model0 as Model\n",
    "import os \n",
    "import re\n",
    "import torch\n",
    "from torch import nn\n",
    "import dgl\n",
    "\n",
    "class HomoStrucBackdoorDataset(DGLBuiltinDataset):\n",
    "    def __init__(self, mode='train', raw_dir='/home/ubuntu/date/hdd4/shadow_model_ckpt/mnist/models/',\n",
    "                 force_reload=False, verbose=False, transform=None):\n",
    "        mode = mode.lower()\n",
    "        assert mode in ['train', 'valid', 'test'], \"Mode not valid.\"\n",
    "        self.mode = mode    \n",
    "        self.x = []\n",
    "        self.y = []\n",
    "        _url = None\n",
    "        super(HomoStrucBackdoorDataset, self).__init__(name='HomoBackdoorDT',\n",
    "                                           raw_dir=raw_dir,\n",
    "                                           force_reload=force_reload,\n",
    "                                           verbose=verbose,\n",
    "                                           url=_url,\n",
    "                                           transform=transform)\n",
    "    def process(self):\n",
    "        pass\n",
    "    \n",
    "    def has_cache(self):\n",
    "        pass\n",
    "    \n",
    "    def load(self):\n",
    "        '''load dataset info'''\n",
    "        \n",
    "        for filename in os.listdir(self.raw_dir):\n",
    "            if '.model' not in filename:\n",
    "                # not a model\n",
    "                continue\n",
    "            idx_pattern = '[0-9]+'\n",
    "            idx = re.findall(idx_pattern, filename)\n",
    "            if self.mode == 'train':\n",
    "                if int(idx[0]) < 2048 and 'target' not in filename:\n",
    "                    # is a training model\n",
    "                    self.x.append(filename)\n",
    "                else:\n",
    "                    continue\n",
    "                # print(filename)\n",
    "            elif self.mode == 'valid':\n",
    "                if int(idx[0]) >= 2048 and 'target' not in filename:\n",
    "                    self.x.append(filename)\n",
    "                else:\n",
    "                    continue\n",
    "            else:\n",
    "                # self.mode == 'test'\n",
    "                if 'target' in filename:\n",
    "                    self.x.append(filename)\n",
    "                else:\n",
    "                    continue\n",
    "            # add co\n",
    "            if 'benign' in filename:\n",
    "                self.y.append(0)\n",
    "            else:\n",
    "                self.y.append(1)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        assert idx < len(self.x), \"Out of index when get item.\"\n",
    "        # load data, process and return\n",
    "        g, y = self.load_g(idx)\n",
    "        return g, y\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "    \n",
    "    def get_x_y(self):\n",
    "        return self.x, self.y\n",
    "    \n",
    "    def iter_y(self):\n",
    "        for y in self.y:\n",
    "            yield y\n",
    "    \n",
    "    def load_g(self, idx):\n",
    "        x = os.path.join(self.raw_dir, self.x[idx])\n",
    "        y = self.y[idx]\n",
    "    #         print(label)\n",
    "        CUDA_LAUNCH_BLOCKING=1\n",
    "        basic_model = Model().cuda()\n",
    "        t = torch.load(x)\n",
    "        t = basic_model.load_state_dict(t)\n",
    "        \n",
    "        g = None\n",
    "        with torch.no_grad():\n",
    "            # nodes_feat 512 * 513\n",
    "            nodes_feat = []\n",
    "            cnt = 0\n",
    "            # get conv1 nodes \n",
    "            conv1 = {}\n",
    "            for weight in basic_model.conv1.weight:\n",
    "                pad = nn.ZeroPad2d(padding=(254,254,253,254))\n",
    "                feat = pad(weight[0])\n",
    "                conv1[cnt] = feat\n",
    "                nodes_feat.append(feat)\n",
    "                cnt += 1\n",
    "\n",
    "            # get conv2 nodes\n",
    "            conv2 = {}\n",
    "            for weight in basic_model.conv2.weight:\n",
    "                pad = nn.ZeroPad2d(padding=(254,254,253,254))\n",
    "                feat = pad(weight[0])\n",
    "                conv2[cnt] = feat\n",
    "                nodes_feat.append(feat)\n",
    "                cnt += 1\n",
    "\n",
    "            # get conv1 -> conv2 edges\n",
    "            conv1_2 = []\n",
    "            for src in conv1.keys():\n",
    "                for dst in conv2.keys():\n",
    "                    conv1_2.append([src, dst])\n",
    "\n",
    "\n",
    "            # get fc node\n",
    "            fc_index = cnt\n",
    "            cnt += 1\n",
    "            fc_node = torch.concat([basic_model.fc.weight, basic_model.fc.bias.reshape(512, 1)], 1)\n",
    "            nodes_feat.append(fc_node)\n",
    "            # print(fc_node.shape)\n",
    "\n",
    "            # get conv2 -> fc edges\n",
    "            conv2_fc = []\n",
    "            for src in conv2.keys():\n",
    "                conv2_fc.append([src, fc_index])\n",
    "\n",
    "            # get output node\n",
    "            out_index = cnt\n",
    "            cnt += 1 \n",
    "            out = torch.concat([basic_model.output.weight, basic_model.output.bias.reshape(10, 1)], 1)\n",
    "            pad = nn.ZeroPad2d(padding=(0,0,251,251))\n",
    "            out_node = pad(out)\n",
    "            nodes_feat.append(out_node)\n",
    "\n",
    "            # print(out_node.shape)\n",
    "\n",
    "            # get fc -> output edge\n",
    "            fc_out_edge = [[fc_index, out_index]]\n",
    "\n",
    "            # get all nodes\n",
    "            nodes_feat = torch.stack(nodes_feat)\n",
    "            # print(nodes_feat.shape)\n",
    "            # get all edges\n",
    "            all_edges = torch.tensor(conv1_2 + conv2_fc + fc_out_edge).t().tolist()\n",
    "            u, v = all_edges[0], all_edges[1]\n",
    "\n",
    "\n",
    "            g = dgl.graph((u,v)).to('cuda')\n",
    "            g.ndata['x'] = nodes_feat\n",
    "        return g, y\n",
    "dataset = HomoStrucBackdoorDataset(mode='test')\n",
    "dataset.load()\n",
    "print(len(dataset))\n",
    "\n",
    "for x,y in dataset:\n",
    "    print(x, y)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "13a50ce0",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target_trojB_113.model\n",
      "target_trojM_21.model\n",
      "target_benign_148.model\n",
      "target_trojB_26.model\n",
      "target_trojM_85.model\n",
      "target_benign_10.model\n",
      "target_trojM_122.model\n",
      "target_trojB_187.model\n",
      "target_benign_237.model\n",
      "target_benign_233.model\n",
      "target_trojM_159.model\n",
      "target_trojB_17.model\n",
      "target_trojM_91.model\n",
      "target_trojB_38.model\n",
      "target_trojM_117.model\n",
      "target_benign_99.model\n",
      "target_trojB_157.model\n",
      "target_trojM_145.model\n",
      "target_benign_67.model\n",
      "target_benign_4.model\n",
      "target_trojB_0.model\n",
      "target_trojM_71.model\n",
      "target_benign_107.model\n",
      "target_trojM_33.model\n",
      "target_trojM_115.model\n",
      "target_trojM_60.model\n",
      "target_benign_48.model\n",
      "target_trojM_231.model\n",
      "target_benign_220.model\n",
      "target_trojB_130.model\n",
      "target_benign_141.model\n",
      "target_trojB_110.model\n",
      "target_benign_234.model\n",
      "target_benign_215.model\n",
      "target_trojB_57.model\n",
      "target_trojM_116.model\n",
      "target_trojB_234.model\n",
      "target_trojM_79.model\n",
      "target_benign_124.model\n",
      "target_trojB_22.model\n",
      "target_benign_240.model\n",
      "target_trojB_186.model\n",
      "target_trojM_186.model\n",
      "target_trojM_17.model\n",
      "target_benign_87.model\n",
      "target_benign_222.model\n",
      "target_trojB_48.model\n",
      "target_benign_172.model\n",
      "target_benign_110.model\n",
      "target_trojB_206.model\n",
      "target_trojB_117.model\n",
      "target_trojB_16.model\n",
      "target_trojM_56.model\n",
      "target_trojM_253.model\n",
      "target_trojM_70.model\n",
      "target_trojM_251.model\n",
      "target_benign_162.model\n",
      "target_benign_207.model\n",
      "target_benign_40.model\n",
      "target_trojM_111.model\n",
      "target_trojM_108.model\n",
      "target_trojM_90.model\n",
      "target_benign_204.model\n",
      "target_benign_51.model\n",
      "target_trojM_156.model\n",
      "target_benign_73.model\n",
      "target_benign_22.model\n",
      "target_benign_137.model\n",
      "target_trojM_66.model\n",
      "target_trojB_79.model\n",
      "target_trojB_220.model\n",
      "target_trojM_125.model\n",
      "target_trojB_212.model\n",
      "target_trojM_128.model\n",
      "target_trojM_5.model\n",
      "target_trojM_36.model\n",
      "target_benign_210.model\n",
      "target_trojB_61.model\n",
      "target_benign_161.model\n",
      "target_trojB_19.model\n",
      "target_trojM_255.model\n",
      "target_trojB_123.model\n",
      "target_trojB_7.model\n",
      "target_benign_131.model\n",
      "target_trojM_135.model\n",
      "target_trojB_242.model\n",
      "target_trojB_238.model\n",
      "target_trojB_50.model\n",
      "target_trojM_6.model\n",
      "target_trojB_85.model\n",
      "target_trojM_55.model\n",
      "target_trojB_23.model\n",
      "target_trojM_189.model\n",
      "target_benign_227.model\n",
      "target_trojM_193.model\n",
      "target_trojM_27.model\n",
      "target_trojB_209.model\n",
      "target_trojB_41.model\n",
      "target_trojM_9.model\n",
      "target_benign_224.model\n",
      "target_trojB_70.model\n",
      "target_trojM_103.model\n",
      "target_trojB_21.model\n",
      "target_trojM_118.model\n",
      "target_benign_178.model\n",
      "target_trojM_120.model\n",
      "target_trojM_176.model\n",
      "target_trojB_59.model\n",
      "target_benign_187.model\n",
      "target_trojM_254.model\n",
      "target_trojB_102.model\n",
      "target_trojB_236.model\n",
      "target_trojM_247.model\n",
      "target_benign_219.model\n",
      "target_trojM_107.model\n",
      "target_trojB_84.model\n",
      "target_trojB_213.model\n",
      "target_trojB_96.model\n",
      "target_trojB_115.model\n",
      "target_benign_2.model\n",
      "target_trojB_252.model\n",
      "target_trojB_154.model\n",
      "target_trojM_82.model\n",
      "target_benign_166.model\n",
      "target_benign_24.model\n",
      "target_trojB_42.model\n",
      "target_trojB_133.model\n",
      "target_benign_113.model\n",
      "target_trojM_177.model\n",
      "target_benign_97.model\n",
      "target_benign_33.model\n",
      "target_trojM_87.model\n",
      "target_trojB_2.model\n",
      "target_trojB_224.model\n",
      "target_trojM_58.model\n",
      "target_benign_11.model\n",
      "target_benign_230.model\n",
      "target_trojB_90.model\n",
      "target_benign_159.model\n",
      "target_trojB_87.model\n",
      "target_benign_15.model\n",
      "target_trojB_188.model\n",
      "target_benign_114.model\n",
      "target_trojM_150.model\n",
      "target_benign_83.model\n",
      "target_benign_132.model\n",
      "target_trojM_14.model\n",
      "target_trojM_75.model\n",
      "target_trojM_100.model\n",
      "target_trojB_132.model\n",
      "target_trojM_12.model\n",
      "target_benign_250.model\n",
      "target_trojB_27.model\n",
      "target_trojB_122.model\n",
      "target_trojB_135.model\n",
      "target_trojM_73.model\n",
      "target_trojB_250.model\n",
      "target_trojB_8.model\n",
      "target_trojB_225.model\n",
      "target_benign_231.model\n",
      "target_trojB_193.model\n",
      "target_benign_45.model\n",
      "target_trojM_105.model\n",
      "target_benign_18.model\n",
      "target_trojB_20.model\n",
      "target_trojM_126.model\n",
      "target_trojB_45.model\n",
      "target_benign_68.model\n",
      "target_benign_188.model\n",
      "target_benign_160.model\n",
      "target_trojM_223.model\n",
      "target_trojM_124.model\n",
      "target_benign_28.model\n",
      "target_trojM_28.model\n",
      "target_trojB_72.model\n",
      "target_trojM_44.model\n",
      "target_benign_42.model\n",
      "target_trojB_119.model\n",
      "target_trojM_248.model\n",
      "target_benign_46.model\n",
      "target_trojM_243.model\n",
      "target_trojB_125.model\n",
      "target_benign_244.model\n",
      "target_benign_58.model\n",
      "target_trojB_63.model\n",
      "target_trojB_99.model\n",
      "target_trojM_244.model\n",
      "target_trojB_146.model\n",
      "target_trojB_114.model\n",
      "target_trojM_127.model\n",
      "target_benign_32.model\n",
      "target_benign_31.model\n",
      "target_trojM_43.model\n",
      "target_trojM_2.model\n",
      "target_benign_93.model\n",
      "target_benign_5.model\n",
      "target_trojB_64.model\n",
      "target_benign_77.model\n",
      "target_benign_154.model\n",
      "target_trojM_188.model\n",
      "target_trojB_185.model\n",
      "target_benign_19.model\n",
      "target_benign_52.model\n",
      "target_benign_1.model\n",
      "target_benign_171.model\n",
      "target_trojB_177.model\n",
      "target_benign_61.model\n",
      "target_benign_34.model\n",
      "target_trojM_8.model\n",
      "target_trojB_155.model\n",
      "target_trojM_220.model\n",
      "target_trojM_19.model\n",
      "target_trojB_215.model\n",
      "target_trojM_237.model\n",
      "target_benign_196.model\n",
      "target_trojB_172.model\n",
      "target_trojM_76.model\n",
      "target_trojB_244.model\n",
      "target_trojB_211.model\n",
      "target_trojM_84.model\n",
      "target_trojM_174.model\n",
      "target_trojB_152.model\n",
      "target_benign_13.model\n",
      "target_trojM_207.model\n",
      "target_benign_195.model\n",
      "target_trojM_246.model\n",
      "target_trojB_182.model\n",
      "target_benign_84.model\n",
      "target_trojB_245.model\n",
      "target_trojM_11.model\n",
      "target_trojM_170.model\n",
      "target_trojB_181.model\n",
      "target_trojB_143.model\n",
      "target_benign_214.model\n",
      "target_trojB_5.model\n",
      "target_trojB_227.model\n",
      "target_trojB_81.model\n",
      "target_trojM_63.model\n",
      "target_trojM_1.model\n",
      "target_trojB_49.model\n",
      "target_trojM_162.model\n",
      "target_trojB_174.model\n",
      "target_benign_156.model\n",
      "target_benign_0.model\n",
      "target_trojM_192.model\n",
      "target_trojM_22.model\n",
      "target_trojM_74.model\n",
      "target_benign_104.model\n",
      "target_benign_199.model\n",
      "target_benign_72.model\n",
      "target_trojM_41.model\n",
      "target_benign_139.model\n",
      "target_trojB_202.model\n",
      "target_trojM_4.model\n",
      "target_trojB_136.model\n",
      "target_benign_185.model\n",
      "target_benign_123.model\n",
      "target_trojM_195.model\n",
      "target_benign_142.model\n",
      "target_trojB_15.model\n",
      "target_trojM_201.model\n",
      "target_benign_27.model\n",
      "target_benign_158.model\n",
      "target_trojB_190.model\n",
      "target_benign_179.model\n",
      "target_trojM_93.model\n",
      "target_benign_76.model\n",
      "target_trojB_161.model\n",
      "target_benign_251.model\n",
      "target_benign_101.model\n",
      "target_benign_216.model\n",
      "target_trojM_194.model\n",
      "target_benign_203.model\n",
      "target_benign_75.model\n",
      "target_benign_26.model\n",
      "target_trojM_30.model\n",
      "target_trojB_191.model\n",
      "target_trojB_71.model\n",
      "target_trojB_144.model\n",
      "target_benign_37.model\n",
      "target_trojM_10.model\n",
      "target_trojB_228.model\n",
      "target_trojM_224.model\n",
      "target_benign_118.model\n",
      "target_benign_242.model\n",
      "target_trojB_166.model\n",
      "target_benign_163.model\n",
      "target_trojM_196.model\n",
      "target_trojM_252.model\n",
      "target_benign_206.model\n",
      "target_benign_49.model\n",
      "target_benign_71.model\n",
      "target_trojB_116.model\n",
      "target_trojB_97.model\n",
      "target_trojB_92.model\n",
      "target_trojB_150.model\n",
      "target_trojM_96.model\n",
      "target_benign_143.model\n",
      "target_trojM_198.model\n",
      "target_trojB_221.model\n",
      "target_trojB_32.model\n",
      "target_trojB_39.model\n",
      "target_benign_23.model\n",
      "target_benign_169.model\n",
      "target_trojM_37.model\n",
      "target_benign_95.model\n",
      "target_trojB_176.model\n",
      "target_trojB_77.model\n",
      "target_trojM_92.model\n",
      "target_benign_57.model\n",
      "target_benign_145.model\n",
      "target_trojM_140.model\n",
      "target_trojM_129.model\n",
      "target_benign_103.model\n",
      "target_trojB_183.model\n",
      "target_benign_252.model\n",
      "target_benign_55.model\n",
      "target_trojM_197.model\n",
      "target_trojB_173.model\n",
      "target_benign_81.model\n",
      "target_trojB_13.model\n",
      "target_benign_211.model\n",
      "target_benign_255.model\n",
      "target_trojM_228.model\n",
      "target_trojB_101.model\n",
      "target_benign_133.model\n",
      "target_benign_21.model\n",
      "target_trojM_15.model\n",
      "target_benign_134.model\n",
      "target_trojB_164.model\n",
      "target_benign_108.model\n",
      "target_trojM_53.model\n",
      "target_trojB_83.model\n",
      "target_trojB_100.model\n",
      "target_trojM_221.model\n",
      "target_trojB_58.model\n",
      "target_benign_7.model\n",
      "target_benign_109.model\n",
      "target_trojB_118.model\n",
      "target_benign_59.model\n",
      "target_benign_6.model\n",
      "target_benign_167.model\n",
      "target_trojB_153.model\n",
      "target_trojM_31.model\n",
      "target_trojB_253.model\n",
      "target_trojB_46.model\n",
      "target_benign_164.model\n",
      "target_trojM_183.model\n",
      "target_trojM_99.model\n",
      "target_benign_243.model\n",
      "target_benign_65.model\n",
      "target_trojB_60.model\n",
      "target_trojM_151.model\n",
      "target_trojM_67.model\n",
      "target_benign_235.model\n",
      "target_trojM_51.model\n",
      "target_trojB_88.model\n",
      "target_trojM_178.model\n",
      "target_trojB_163.model\n",
      "target_trojB_171.model\n",
      "target_trojB_128.model\n",
      "target_benign_247.model\n",
      "target_trojB_40.model\n",
      "target_trojM_235.model\n",
      "target_trojM_241.model\n",
      "target_trojM_212.model\n",
      "target_benign_150.model\n",
      "target_trojM_161.model\n",
      "target_benign_20.model\n",
      "target_benign_91.model\n",
      "target_trojM_101.model\n",
      "target_trojB_80.model\n",
      "target_benign_100.model\n",
      "target_benign_96.model\n",
      "target_trojB_62.model\n",
      "target_trojM_168.model\n",
      "target_benign_152.model\n",
      "target_benign_217.model\n",
      "target_trojB_203.model\n",
      "target_trojB_147.model\n",
      "target_trojB_162.model\n",
      "target_trojM_134.model\n",
      "target_benign_151.model\n",
      "target_trojM_208.model\n",
      "target_trojM_112.model\n",
      "target_trojM_57.model\n",
      "target_trojB_196.model\n",
      "target_benign_85.model\n",
      "target_benign_86.model\n",
      "target_trojB_34.model\n",
      "target_trojM_249.model\n",
      "target_trojB_93.model\n",
      "target_trojM_219.model\n",
      "target_trojM_94.model\n",
      "target_trojB_217.model\n",
      "target_trojB_29.model\n",
      "target_benign_168.model\n",
      "target_trojB_214.model\n",
      "target_trojB_229.model\n",
      "target_benign_80.model\n",
      "target_benign_64.model\n",
      "target_benign_212.model\n",
      "target_trojM_13.model\n",
      "target_benign_170.model\n",
      "target_benign_190.model\n",
      "target_trojM_209.model\n",
      "target_trojB_33.model\n",
      "target_benign_232.model\n",
      "target_trojM_132.model\n",
      "target_trojB_184.model\n",
      "target_benign_182.model\n",
      "target_benign_54.model\n",
      "target_trojM_165.model\n",
      "target_benign_153.model\n",
      "target_benign_144.model\n",
      "target_trojB_169.model\n",
      "target_trojB_86.model\n",
      "target_trojB_10.model\n",
      "target_trojM_46.model\n",
      "target_trojM_234.model\n",
      "target_benign_238.model\n",
      "target_trojB_204.model\n",
      "target_trojB_180.model\n",
      "target_benign_8.model\n",
      "target_trojB_145.model\n",
      "target_trojB_91.model\n",
      "target_benign_249.model\n",
      "target_trojB_69.model\n",
      "target_trojB_148.model\n",
      "target_trojB_178.model\n",
      "target_trojM_167.model\n",
      "target_benign_127.model\n",
      "target_trojB_107.model\n",
      "target_benign_200.model\n",
      "target_benign_70.model\n",
      "target_trojB_14.model\n",
      "target_trojB_112.model\n",
      "target_trojM_216.model\n",
      "target_trojM_20.model\n",
      "target_trojB_66.model\n",
      "target_trojB_56.model\n",
      "target_trojM_149.model\n",
      "target_benign_122.model\n",
      "target_benign_135.model\n",
      "target_trojB_1.model\n",
      "target_trojB_218.model\n",
      "target_trojB_156.model\n",
      "target_benign_208.model\n",
      "target_trojB_241.model\n",
      "target_benign_174.model\n",
      "target_trojB_28.model\n",
      "target_benign_44.model\n",
      "target_trojB_134.model\n",
      "target_trojB_126.model\n",
      "target_trojB_43.model\n",
      "target_trojB_199.model\n",
      "target_trojB_175.model\n",
      "target_benign_186.model\n",
      "target_trojM_77.model\n",
      "target_benign_202.model\n",
      "target_benign_201.model\n",
      "target_trojB_111.model\n",
      "target_benign_63.model\n",
      "target_benign_102.model\n",
      "target_trojB_131.model\n",
      "target_trojB_189.model\n",
      "target_benign_221.model\n",
      "target_trojM_25.model\n",
      "target_benign_47.model\n",
      "target_trojM_143.model\n",
      "target_trojB_231.model\n",
      "target_benign_254.model\n",
      "target_benign_146.model\n",
      "target_trojB_230.model\n",
      "target_benign_136.model\n",
      "target_trojM_133.model\n",
      "target_trojM_180.model\n",
      "target_trojM_214.model\n",
      "target_trojB_149.model\n",
      "target_benign_98.model\n",
      "target_benign_175.model\n",
      "target_trojM_61.model\n",
      "target_trojM_0.model\n",
      "target_trojB_251.model\n",
      "target_benign_193.model\n",
      "target_trojB_75.model\n",
      "target_benign_165.model\n",
      "target_trojB_65.model\n",
      "target_trojM_86.model\n",
      "target_trojB_104.model\n",
      "target_trojB_47.model\n",
      "target_trojM_173.model\n",
      "target_benign_74.model\n",
      "target_trojM_206.model\n",
      "target_trojM_157.model\n",
      "target_benign_94.model\n",
      "target_benign_29.model\n",
      "target_trojM_154.model\n",
      "target_benign_194.model\n",
      "target_benign_128.model\n",
      "target_trojB_6.model\n",
      "target_trojM_110.model\n",
      "target_trojB_54.model\n",
      "target_trojB_222.model\n",
      "target_benign_213.model\n",
      "target_benign_176.model\n",
      "target_trojM_181.model\n",
      "target_trojB_67.model\n",
      "target_trojM_98.model\n",
      "target_trojB_140.model\n",
      "target_trojM_83.model\n",
      "target_trojB_233.model\n",
      "target_trojM_199.model\n",
      "target_trojM_158.model\n",
      "target_trojB_35.model\n",
      "target_trojB_192.model\n",
      "target_benign_184.model\n",
      "target_trojB_137.model\n",
      "target_benign_112.model\n",
      "target_trojB_141.model\n",
      "target_trojM_211.model\n",
      "target_trojM_175.model\n",
      "target_trojM_65.model\n",
      "target_benign_3.model\n",
      "target_benign_38.model\n",
      "target_trojB_4.model\n",
      "target_trojM_81.model\n",
      "target_trojB_68.model\n",
      "target_trojB_51.model\n",
      "target_trojB_201.model\n",
      "target_trojM_172.model\n",
      "target_trojM_239.model\n",
      "target_trojM_78.model\n",
      "target_trojM_230.model\n",
      "target_trojM_130.model\n",
      "target_trojB_151.model\n",
      "target_trojM_250.model\n",
      "target_trojM_182.model\n",
      "target_trojM_225.model\n",
      "target_benign_225.model\n",
      "target_trojM_233.model\n",
      "target_benign_239.model\n",
      "target_benign_248.model\n",
      "target_trojM_24.model\n",
      "target_benign_236.model\n",
      "target_trojB_142.model\n",
      "target_trojM_213.model\n",
      "target_trojM_200.model\n",
      "target_benign_41.model\n",
      "target_trojB_235.model\n",
      "target_trojB_239.model\n",
      "target_benign_36.model\n",
      "target_trojB_165.model\n",
      "target_benign_205.model\n",
      "target_trojM_169.model\n",
      "target_trojM_104.model\n",
      "target_benign_56.model\n",
      "target_benign_140.model\n",
      "target_trojB_138.model\n",
      "target_benign_191.model\n",
      "target_benign_90.model\n",
      "target_trojB_170.model\n",
      "target_trojB_216.model\n",
      "target_trojB_44.model\n",
      "target_benign_119.model\n",
      "target_benign_245.model\n",
      "target_benign_43.model\n",
      "target_trojM_232.model\n",
      "target_trojM_42.model\n",
      "target_benign_125.model\n",
      "target_trojM_45.model\n",
      "target_benign_209.model\n",
      "target_trojM_163.model\n",
      "target_trojM_3.model\n",
      "target_trojM_16.model\n",
      "target_benign_89.model\n",
      "target_trojB_103.model\n",
      "target_trojM_153.model\n",
      "target_benign_16.model\n",
      "target_trojB_55.model\n",
      "target_trojB_25.model\n",
      "target_benign_147.model\n",
      "target_benign_111.model\n",
      "target_trojM_48.model\n",
      "target_trojM_215.model\n",
      "target_trojM_26.model\n",
      "target_trojM_123.model\n",
      "target_benign_229.model\n",
      "target_benign_246.model\n",
      "target_benign_35.model\n",
      "target_trojM_49.model\n",
      "target_trojM_217.model\n",
      "target_benign_130.model\n",
      "target_trojB_223.model\n",
      "target_trojM_131.model\n",
      "target_trojM_152.model\n",
      "target_trojM_54.model\n",
      "target_trojM_171.model\n",
      "target_benign_92.model\n",
      "target_trojM_80.model\n",
      "target_trojM_222.model\n",
      "target_trojM_40.model\n",
      "target_trojM_18.model\n",
      "target_trojB_160.model\n",
      "target_trojM_62.model\n",
      "target_trojB_18.model\n",
      "target_trojB_12.model\n",
      "target_benign_177.model\n",
      "target_trojM_242.model\n",
      "target_trojM_139.model\n",
      "target_trojB_53.model\n",
      "target_trojM_141.model\n",
      "target_trojM_35.model\n",
      "target_benign_106.model\n",
      "target_trojM_148.model\n",
      "target_trojM_95.model\n",
      "target_benign_60.model\n",
      "target_trojM_119.model\n",
      "target_trojB_210.model\n",
      "target_trojB_106.model\n",
      "target_trojB_3.model\n",
      "target_trojM_113.model\n",
      "target_trojB_248.model\n",
      "target_benign_30.model\n",
      "target_trojB_94.model\n",
      "target_benign_115.model\n",
      "target_trojB_76.model\n",
      "target_benign_105.model\n",
      "target_trojB_105.model\n",
      "target_benign_173.model\n",
      "target_trojM_179.model\n",
      "target_benign_88.model\n",
      "target_trojB_255.model\n",
      "target_trojM_50.model\n",
      "target_trojB_11.model\n",
      "target_trojB_30.model\n",
      "target_trojM_102.model\n",
      "target_benign_66.model\n",
      "target_trojM_236.model\n",
      "target_trojM_64.model\n",
      "target_benign_25.model\n",
      "target_trojB_240.model\n",
      "target_trojB_254.model\n",
      "target_benign_218.model\n",
      "target_trojB_249.model\n",
      "target_benign_129.model\n",
      "target_trojB_31.model\n",
      "target_trojB_52.model\n",
      "target_trojB_36.model\n",
      "target_trojM_245.model\n",
      "target_trojM_47.model\n",
      "target_trojM_240.model\n",
      "target_trojB_78.model\n",
      "target_benign_180.model\n",
      "target_benign_183.model\n",
      "target_benign_189.model\n",
      "target_trojM_121.model\n",
      "target_benign_79.model\n",
      "target_trojM_164.model\n",
      "target_trojM_69.model\n",
      "target_trojB_98.model\n",
      "target_benign_53.model\n",
      "target_trojM_114.model\n",
      "target_benign_14.model\n",
      "target_trojB_247.model\n",
      "target_trojM_89.model\n",
      "target_trojB_194.model\n",
      "target_trojM_97.model\n",
      "target_benign_117.model\n",
      "target_benign_39.model\n",
      "target_trojB_37.model\n",
      "target_benign_9.model\n",
      "target_trojB_197.model\n",
      "target_trojM_185.model\n",
      "target_trojM_160.model\n",
      "target_trojM_32.model\n",
      "target_benign_198.model\n",
      "target_benign_116.model\n",
      "target_benign_157.model\n",
      "target_trojM_52.model\n",
      "target_trojM_106.model\n",
      "target_trojB_82.model\n",
      "target_trojM_191.model\n",
      "target_trojB_9.model\n",
      "target_trojB_205.model\n",
      "target_benign_149.model\n",
      "target_trojB_200.model\n",
      "target_benign_62.model\n",
      "target_benign_253.model\n",
      "target_trojB_246.model\n",
      "target_trojB_208.model\n",
      "target_benign_12.model\n",
      "target_trojB_237.model\n",
      "target_benign_17.model\n",
      "target_trojM_202.model\n",
      "target_trojM_88.model\n",
      "target_trojB_226.model\n",
      "target_trojM_39.model\n",
      "target_benign_78.model\n",
      "target_trojM_29.model\n",
      "target_benign_69.model\n",
      "target_trojM_218.model\n",
      "target_benign_138.model\n",
      "target_trojB_124.model\n",
      "target_trojM_72.model\n",
      "target_trojB_158.model\n",
      "target_trojB_243.model\n",
      "target_trojB_219.model\n",
      "target_trojM_146.model\n",
      "target_trojB_73.model\n",
      "target_benign_197.model\n",
      "target_trojB_74.model\n",
      "target_trojM_229.model\n",
      "target_trojB_120.model\n",
      "target_trojM_142.model\n",
      "target_trojB_95.model\n",
      "target_trojM_147.model\n",
      "target_trojM_205.model\n",
      "target_trojB_195.model\n",
      "target_trojM_238.model\n",
      "target_trojM_38.model\n",
      "target_benign_126.model\n",
      "target_trojM_144.model\n",
      "target_trojM_138.model\n",
      "target_trojM_136.model\n",
      "target_benign_228.model\n",
      "target_trojM_210.model\n",
      "target_trojM_190.model\n",
      "target_trojM_226.model\n",
      "target_benign_121.model\n",
      "target_benign_223.model\n",
      "target_trojM_109.model\n",
      "target_trojB_24.model\n",
      "target_trojM_137.model\n",
      "target_trojB_159.model\n",
      "target_trojM_204.model\n",
      "target_benign_192.model\n",
      "target_trojM_34.model\n",
      "target_trojB_127.model\n",
      "target_trojB_129.model\n",
      "target_trojM_187.model\n",
      "target_trojB_167.model\n",
      "target_benign_226.model\n",
      "target_benign_120.model\n",
      "target_trojM_23.model\n",
      "target_trojM_203.model\n",
      "target_trojB_108.model\n",
      "target_trojB_168.model\n",
      "target_benign_82.model\n",
      "target_trojB_232.model\n",
      "target_trojB_89.model\n",
      "target_trojM_166.model\n",
      "target_trojM_184.model\n",
      "target_trojM_7.model\n",
      "target_benign_155.model\n",
      "target_trojB_121.model\n",
      "target_benign_181.model\n",
      "target_benign_241.model\n",
      "target_trojB_207.model\n",
      "target_trojM_227.model\n",
      "target_trojM_155.model\n",
      "target_trojM_68.model\n",
      "target_trojM_59.model\n",
      "target_trojB_109.model\n",
      "target_trojB_139.model\n",
      "target_trojB_198.model\n",
      "target_benign_50.model\n",
      "target_trojB_179.model\n"
     ]
    }
   ],
   "source": [
    "x, y = dataset.get_x_y()\n",
    "for i in x:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c7ab5078",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def is_correct_labeled(x, y):\n",
    "    cnt = 0\n",
    "    error = 0\n",
    "    for i,j in zip(x,y):\n",
    "        if 'benign' in i and j == 0:\n",
    "            cnt += 1\n",
    "        elif 'benign' not in i and j == 1:\n",
    "            cnt += 1\n",
    "        else:\n",
    "            error += 1\n",
    "    if cnt != len(x) or error > 0:\n",
    "        return False\n",
    "    else:\n",
    "        return True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "004da954",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with DGL built-in GINConv module with a fixed epsilon = 0\n",
      "Training Procedure...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [01:00<00:00, 17.04it/s]\n",
      "100%|██████████| 1024/1024 [00:46<00:00, 21.97it/s]\n",
      "100%|██████████| 1024/1024 [00:46<00:00, 22.04it/s]\n",
      "100%|██████████| 1024/1024 [00:46<00:00, 22.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00000 | Loss 2.6127 | Train Acc. 0.9248 | Validation Acc. 0.9248| Test Acc. 0.9248 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [01:03<00:00, 16.06it/s]\n",
      "100%|██████████| 1024/1024 [00:45<00:00, 22.51it/s]\n",
      "100%|██████████| 1024/1024 [00:46<00:00, 22.21it/s]\n",
      "100%|██████████| 1024/1024 [00:46<00:00, 22.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00001 | Loss 0.9778 | Train Acc. 0.9651 | Validation Acc. 0.9651| Test Acc. 0.9651 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:57<00:00, 17.93it/s]\n",
      "100%|██████████| 1024/1024 [00:46<00:00, 21.97it/s]\n",
      "100%|██████████| 1024/1024 [00:46<00:00, 21.98it/s]\n",
      "100%|██████████| 1024/1024 [00:46<00:00, 22.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00002 | Loss 0.7188 | Train Acc. 0.9822 | Validation Acc. 0.9822| Test Acc. 0.9822 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [01:00<00:00, 16.90it/s]\n",
      "100%|██████████| 1024/1024 [00:46<00:00, 22.04it/s]\n",
      "100%|██████████| 1024/1024 [00:46<00:00, 22.09it/s]\n",
      "100%|██████████| 1024/1024 [00:46<00:00, 22.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00003 | Loss 0.5679 | Train Acc. 0.9880 | Validation Acc. 0.9880| Test Acc. 0.9880 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:58<00:00, 17.48it/s]\n",
      "100%|██████████| 1024/1024 [00:46<00:00, 21.79it/s]\n",
      "100%|██████████| 1024/1024 [00:47<00:00, 21.75it/s]\n",
      "100%|██████████| 1024/1024 [00:46<00:00, 21.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00004 | Loss 0.4770 | Train Acc. 0.9900 | Validation Acc. 0.9900| Test Acc. 0.9900 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:58<00:00, 17.58it/s]\n",
      "100%|██████████| 1024/1024 [00:46<00:00, 21.84it/s]\n",
      "100%|██████████| 1024/1024 [00:45<00:00, 22.28it/s]\n",
      "100%|██████████| 1024/1024 [00:46<00:00, 21.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00005 | Loss 0.6682 | Train Acc. 0.9946 | Validation Acc. 0.9946| Test Acc. 0.9946 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:59<00:00, 17.12it/s]\n",
      "100%|██████████| 1024/1024 [00:46<00:00, 21.99it/s]\n",
      "100%|██████████| 1024/1024 [00:46<00:00, 21.96it/s]\n",
      "100%|██████████| 1024/1024 [00:46<00:00, 22.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00006 | Loss 0.3700 | Train Acc. 0.9961 | Validation Acc. 0.9961| Test Acc. 0.9961 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:58<00:00, 17.65it/s]\n",
      "100%|██████████| 1024/1024 [00:46<00:00, 22.22it/s]\n",
      "100%|██████████| 1024/1024 [00:46<00:00, 22.13it/s]\n",
      "100%|██████████| 1024/1024 [00:46<00:00, 22.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00007 | Loss 0.2506 | Train Acc. 0.9971 | Validation Acc. 0.9971| Test Acc. 0.9971 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [01:03<00:00, 16.11it/s]\n",
      "100%|██████████| 1024/1024 [00:46<00:00, 22.12it/s]\n",
      "100%|██████████| 1024/1024 [00:46<00:00, 22.18it/s]\n",
      "100%|██████████| 1024/1024 [00:45<00:00, 22.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00008 | Loss 0.2549 | Train Acc. 0.9978 | Validation Acc. 0.9978| Test Acc. 0.9978 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:57<00:00, 17.77it/s]\n",
      "100%|██████████| 1024/1024 [00:46<00:00, 22.26it/s]\n",
      "100%|██████████| 1024/1024 [00:46<00:00, 22.08it/s]\n",
      "100%|██████████| 1024/1024 [00:46<00:00, 22.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00009 | Loss 0.3059 | Train Acc. 0.9966 | Validation Acc. 0.9966| Test Acc. 0.9966 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [01:01<00:00, 16.78it/s]\n",
      "100%|██████████| 1024/1024 [00:46<00:00, 21.95it/s]\n",
      "100%|██████████| 1024/1024 [00:46<00:00, 21.98it/s]\n",
      "100%|██████████| 1024/1024 [00:46<00:00, 21.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00010 | Loss 0.2289 | Train Acc. 0.9976 | Validation Acc. 0.9976| Test Acc. 0.9976 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [01:00<00:00, 16.89it/s]\n",
      "100%|██████████| 1024/1024 [00:46<00:00, 22.12it/s]\n",
      "100%|██████████| 1024/1024 [00:46<00:00, 22.21it/s]\n",
      "100%|██████████| 1024/1024 [00:46<00:00, 21.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00011 | Loss 0.3611 | Train Acc. 0.9976 | Validation Acc. 0.9976| Test Acc. 0.9976 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [01:03<00:00, 16.06it/s]\n",
      "100%|██████████| 1024/1024 [00:46<00:00, 22.03it/s]\n",
      "100%|██████████| 1024/1024 [00:46<00:00, 21.83it/s]\n",
      "100%|██████████| 1024/1024 [00:46<00:00, 21.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00012 | Loss 0.1632 | Train Acc. 0.9980 | Validation Acc. 0.9980| Test Acc. 0.9980 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:58<00:00, 17.50it/s]\n",
      "100%|██████████| 1024/1024 [00:47<00:00, 21.78it/s]\n",
      "100%|██████████| 1024/1024 [00:46<00:00, 22.11it/s]\n",
      "100%|██████████| 1024/1024 [00:46<00:00, 22.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00013 | Loss 0.3791 | Train Acc. 0.9988 | Validation Acc. 0.9988| Test Acc. 0.9988 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [01:01<00:00, 16.60it/s]\n",
      "100%|██████████| 1024/1024 [00:46<00:00, 22.09it/s]\n",
      "100%|██████████| 1024/1024 [00:46<00:00, 21.98it/s]\n",
      "100%|██████████| 1024/1024 [00:46<00:00, 21.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00014 | Loss 0.2070 | Train Acc. 0.9988 | Validation Acc. 0.9988| Test Acc. 0.9988 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:56<00:00, 17.97it/s]\n",
      "100%|██████████| 1024/1024 [00:46<00:00, 22.22it/s]\n",
      "100%|██████████| 1024/1024 [00:46<00:00, 22.16it/s]\n",
      "100%|██████████| 1024/1024 [00:46<00:00, 22.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00015 | Loss 0.1747 | Train Acc. 0.9995 | Validation Acc. 0.9995| Test Acc. 0.9995 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [01:00<00:00, 16.88it/s]\n",
      "100%|██████████| 1024/1024 [00:46<00:00, 22.06it/s]\n",
      "100%|██████████| 1024/1024 [00:46<00:00, 21.92it/s]\n",
      "100%|██████████| 1024/1024 [00:46<00:00, 21.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00016 | Loss 0.1432 | Train Acc. 0.9995 | Validation Acc. 0.9995| Test Acc. 0.9995 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [01:02<00:00, 16.37it/s]\n",
      "100%|██████████| 1024/1024 [00:45<00:00, 22.33it/s]\n",
      "100%|██████████| 1024/1024 [00:46<00:00, 22.25it/s]\n",
      "100%|██████████| 1024/1024 [00:46<00:00, 22.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00017 | Loss 0.1357 | Train Acc. 0.9998 | Validation Acc. 0.9998| Test Acc. 0.9998 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:57<00:00, 17.67it/s]\n",
      "100%|██████████| 1024/1024 [00:46<00:00, 22.25it/s]\n",
      "100%|██████████| 1024/1024 [00:46<00:00, 21.95it/s]\n",
      "100%|██████████| 1024/1024 [00:46<00:00, 21.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00018 | Loss 0.1026 | Train Acc. 0.9995 | Validation Acc. 0.9995| Test Acc. 0.9995 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:54<00:00, 18.93it/s]\n",
      "100%|██████████| 1024/1024 [00:46<00:00, 22.19it/s]\n",
      "100%|██████████| 1024/1024 [00:46<00:00, 22.08it/s]\n",
      "100%|██████████| 1024/1024 [00:46<00:00, 22.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00019 | Loss 0.1527 | Train Acc. 0.9988 | Validation Acc. 0.9988| Test Acc. 0.9988 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [01:03<00:00, 16.19it/s]\n",
      "100%|██████████| 1024/1024 [00:46<00:00, 22.04it/s]\n",
      "100%|██████████| 1024/1024 [00:46<00:00, 21.84it/s]\n",
      "100%|██████████| 1024/1024 [00:46<00:00, 21.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00020 | Loss 0.1659 | Train Acc. 0.9995 | Validation Acc. 0.9995| Test Acc. 0.9995 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:59<00:00, 17.20it/s]\n",
      "100%|██████████| 1024/1024 [00:46<00:00, 21.91it/s]\n",
      "100%|██████████| 1024/1024 [00:45<00:00, 22.28it/s]\n",
      "100%|██████████| 1024/1024 [00:46<00:00, 22.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00021 | Loss 0.1032 | Train Acc. 0.9995 | Validation Acc. 0.9995| Test Acc. 0.9995 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [01:00<00:00, 17.06it/s]\n",
      "100%|██████████| 1024/1024 [00:46<00:00, 21.87it/s]\n",
      "100%|██████████| 1024/1024 [00:46<00:00, 22.00it/s]\n",
      "100%|██████████| 1024/1024 [00:46<00:00, 21.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00022 | Loss 0.0903 | Train Acc. 1.0000 | Validation Acc. 1.0000| Test Acc. 1.0000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [01:00<00:00, 16.97it/s]\n",
      "100%|██████████| 1024/1024 [00:46<00:00, 22.00it/s]\n",
      "100%|██████████| 1024/1024 [00:46<00:00, 22.12it/s]\n",
      "100%|██████████| 1024/1024 [00:46<00:00, 22.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00023 | Loss 0.0826 | Train Acc. 0.9995 | Validation Acc. 0.9995| Test Acc. 0.9995 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [01:04<00:00, 15.93it/s]\n",
      "100%|██████████| 1024/1024 [00:46<00:00, 22.19it/s]\n",
      "100%|██████████| 1024/1024 [00:45<00:00, 22.29it/s]\n",
      "100%|██████████| 1024/1024 [00:46<00:00, 22.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00024 | Loss 0.1423 | Train Acc. 0.9995 | Validation Acc. 0.9995| Test Acc. 0.9995 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:57<00:00, 17.81it/s]\n",
      "100%|██████████| 1024/1024 [00:46<00:00, 21.96it/s]\n",
      "100%|██████████| 1024/1024 [00:46<00:00, 21.91it/s]\n",
      "100%|██████████| 1024/1024 [00:46<00:00, 22.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00025 | Loss 0.1111 | Train Acc. 0.9993 | Validation Acc. 0.9993| Test Acc. 0.9993 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [01:00<00:00, 16.81it/s]\n",
      "100%|██████████| 1024/1024 [00:45<00:00, 22.58it/s]\n",
      "100%|██████████| 1024/1024 [00:45<00:00, 22.39it/s]\n",
      "100%|██████████| 1024/1024 [00:45<00:00, 22.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00026 | Loss 0.1026 | Train Acc. 0.9995 | Validation Acc. 0.9995| Test Acc. 0.9995 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:58<00:00, 17.63it/s]\n",
      "100%|██████████| 1024/1024 [00:46<00:00, 22.18it/s]\n",
      "100%|██████████| 1024/1024 [00:46<00:00, 21.98it/s]\n",
      "100%|██████████| 1024/1024 [00:46<00:00, 22.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00027 | Loss 0.1049 | Train Acc. 0.9995 | Validation Acc. 0.9995| Test Acc. 0.9995 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [01:04<00:00, 15.85it/s]\n",
      "100%|██████████| 1024/1024 [00:46<00:00, 21.94it/s]\n",
      "100%|██████████| 1024/1024 [00:46<00:00, 21.79it/s]\n",
      "100%|██████████| 1024/1024 [00:46<00:00, 22.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00028 | Loss 0.1123 | Train Acc. 0.9995 | Validation Acc. 0.9995| Test Acc. 0.9995 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:58<00:00, 17.53it/s]\n",
      "100%|██████████| 1024/1024 [00:46<00:00, 22.06it/s]\n",
      "100%|██████████| 1024/1024 [00:46<00:00, 21.93it/s]\n",
      "100%|██████████| 1024/1024 [00:46<00:00, 22.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00029 | Loss 0.0737 | Train Acc. 0.9998 | Validation Acc. 0.9998| Test Acc. 0.9998 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:59<00:00, 17.29it/s]\n",
      "100%|██████████| 1024/1024 [00:46<00:00, 22.26it/s]\n",
      "100%|██████████| 1024/1024 [00:46<00:00, 22.09it/s]\n",
      "100%|██████████| 1024/1024 [00:46<00:00, 22.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00030 | Loss 0.0499 | Train Acc. 0.9995 | Validation Acc. 0.9995| Test Acc. 0.9995 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:59<00:00, 17.14it/s]\n",
      "100%|██████████| 1024/1024 [00:46<00:00, 22.05it/s]\n",
      "100%|██████████| 1024/1024 [00:45<00:00, 22.29it/s]\n",
      "100%|██████████| 1024/1024 [00:46<00:00, 22.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00031 | Loss 0.0761 | Train Acc. 0.9998 | Validation Acc. 0.9998| Test Acc. 0.9998 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [01:05<00:00, 15.61it/s]\n",
      "100%|██████████| 1024/1024 [00:47<00:00, 21.70it/s]\n",
      "100%|██████████| 1024/1024 [00:46<00:00, 21.94it/s]\n",
      "100%|██████████| 1024/1024 [00:46<00:00, 21.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00032 | Loss 0.0527 | Train Acc. 1.0000 | Validation Acc. 1.0000| Test Acc. 1.0000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [01:01<00:00, 16.68it/s]\n",
      "100%|██████████| 1024/1024 [00:46<00:00, 22.00it/s]\n",
      "100%|██████████| 1024/1024 [00:46<00:00, 22.02it/s]\n",
      "100%|██████████| 1024/1024 [00:46<00:00, 22.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00033 | Loss 0.1509 | Train Acc. 0.9998 | Validation Acc. 0.9998| Test Acc. 0.9998 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [01:01<00:00, 16.65it/s]\n",
      "100%|██████████| 1024/1024 [00:46<00:00, 22.06it/s]\n",
      "100%|██████████| 1024/1024 [00:46<00:00, 21.93it/s]\n",
      "100%|██████████| 1024/1024 [00:46<00:00, 22.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00034 | Loss 0.0770 | Train Acc. 1.0000 | Validation Acc. 1.0000| Test Acc. 1.0000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [01:03<00:00, 16.21it/s]\n",
      "100%|██████████| 1024/1024 [00:45<00:00, 22.51it/s]\n",
      "100%|██████████| 1024/1024 [00:46<00:00, 22.24it/s]\n",
      "100%|██████████| 1024/1024 [00:46<00:00, 21.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00035 | Loss 0.0950 | Train Acc. 0.9998 | Validation Acc. 0.9998| Test Acc. 0.9998 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [01:00<00:00, 16.91it/s]\n",
      "100%|██████████| 1024/1024 [00:46<00:00, 21.96it/s]\n",
      "100%|██████████| 1024/1024 [00:46<00:00, 22.01it/s]\n",
      "100%|██████████| 1024/1024 [00:46<00:00, 22.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00036 | Loss 0.1063 | Train Acc. 1.0000 | Validation Acc. 1.0000| Test Acc. 1.0000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [01:00<00:00, 16.87it/s]\n",
      "100%|██████████| 1024/1024 [00:45<00:00, 22.41it/s]\n",
      "100%|██████████| 1024/1024 [00:46<00:00, 22.14it/s]\n",
      "100%|██████████| 1024/1024 [00:46<00:00, 22.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00037 | Loss 0.0442 | Train Acc. 1.0000 | Validation Acc. 1.0000| Test Acc. 1.0000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [01:02<00:00, 16.49it/s]\n",
      "100%|██████████| 1024/1024 [00:46<00:00, 22.03it/s]\n",
      "100%|██████████| 1024/1024 [00:46<00:00, 22.17it/s]\n",
      "100%|██████████| 1024/1024 [00:46<00:00, 22.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00038 | Loss 0.0828 | Train Acc. 1.0000 | Validation Acc. 1.0000| Test Acc. 1.0000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [01:00<00:00, 17.05it/s]\n",
      "100%|██████████| 1024/1024 [00:46<00:00, 22.22it/s]\n",
      "100%|██████████| 1024/1024 [00:45<00:00, 22.31it/s]\n",
      "100%|██████████| 1024/1024 [00:46<00:00, 22.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00039 | Loss 0.0611 | Train Acc. 0.9998 | Validation Acc. 0.9998| Test Acc. 0.9998 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:58<00:00, 17.43it/s]\n",
      "100%|██████████| 1024/1024 [00:46<00:00, 21.91it/s]\n",
      "100%|██████████| 1024/1024 [00:46<00:00, 21.89it/s]\n",
      "100%|██████████| 1024/1024 [00:46<00:00, 21.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00040 | Loss 0.0421 | Train Acc. 1.0000 | Validation Acc. 1.0000| Test Acc. 1.0000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [01:01<00:00, 16.73it/s]\n",
      "100%|██████████| 1024/1024 [00:46<00:00, 21.93it/s]\n",
      "100%|██████████| 1024/1024 [00:46<00:00, 21.99it/s]\n",
      "100%|██████████| 1024/1024 [00:46<00:00, 21.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00041 | Loss 0.0404 | Train Acc. 1.0000 | Validation Acc. 1.0000| Test Acc. 1.0000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 699/1024 [00:39<00:18, 17.61it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-14379a441370>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    155\u001b[0m     \u001b[0;31m# model training/validating\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Training Procedure...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-8-14379a441370>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(train_loader, val_loader, test_loader, device, model)\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0mtotal_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbatched_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m             \u001b[0mbatched_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatched_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m             \u001b[0;31m#print(batch, labels, type(labels))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1184\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1185\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1186\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1187\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/envs/mntd/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/envs/mntd/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    559\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 561\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    562\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/envs/mntd/lib/python3.6/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/envs/mntd/lib/python3.6/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-7b53382fc0c8>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0midx\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Out of index when get item.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0;31m# load data, process and return\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m         \u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_g\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-7b53382fc0c8>\u001b[0m in \u001b[0;36mload_g\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0mbasic_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m         \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbasic_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/envs/mntd/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m   1466\u001b[0m                     \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchild\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprefix\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1467\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1468\u001b[0;31m         \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1469\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1470\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/envs/mntd/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(module, prefix)\u001b[0m\n\u001b[1;32m   1464\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchild\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1465\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mchild\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1466\u001b[0;31m                     \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchild\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprefix\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1467\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1468\u001b[0m         \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/envs/mntd/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(module, prefix)\u001b[0m\n\u001b[1;32m   1461\u001b[0m             \u001b[0mlocal_metadata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mmetadata\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprefix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1462\u001b[0m             module._load_from_state_dict(\n\u001b[0;32m-> 1463\u001b[0;31m                 state_dict, prefix, local_metadata, True, missing_keys, unexpected_keys, error_msgs)\n\u001b[0m\u001b[1;32m   1464\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchild\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1465\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mchild\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/envs/mntd/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_load_from_state_dict\u001b[0;34m(self, state_dict, prefix, local_metadata, strict, missing_keys, unexpected_keys, error_msgs)\u001b[0m\n\u001b[1;32m   1396\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1397\u001b[0m                     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1398\u001b[0;31m                         \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_param\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1399\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1400\u001b[0m                     error_msgs.append('While copying the parameter named \"{}\", '\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from dgl.data import GINDataset\n",
    "from dgl.dataloading import GraphDataLoader\n",
    "from dgl.nn.pytorch.conv import GINConv\n",
    "from dgl.nn.pytorch.glob import SumPooling\n",
    "import argparse\n",
    "from tqdm import tqdm\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    \"\"\"Construct two-layer MLP-type aggreator for GIN model\"\"\"\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super().__init__()\n",
    "        self.linears = nn.ModuleList()\n",
    "        # two-layer MLP    \n",
    "        self.linears.append(nn.Linear(input_dim, hidden_dim, bias=False))\n",
    "        self.linears.append(nn.Linear(hidden_dim, output_dim, bias=False))\n",
    "        self.batch_norm = nn.BatchNorm1d((hidden_dim))\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = x\n",
    "        h = F.relu(self.batch_norm(self.linears[0](h)))\n",
    "        return self.linears[1](h)\n",
    "    \n",
    "class GIN(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, pooling='sum'):\n",
    "        super().__init__()\n",
    "        self.ginlayers = nn.ModuleList()\n",
    "        self.batch_norms = nn.ModuleList()\n",
    "        assert pooling in ['sum', 'avg', 'max']\n",
    "        num_layers = 5\n",
    "        # five-layer GCN with two-layer MLP aggregator and sum-neighbor-pooling scheme\n",
    "        for layer in range(num_layers - 1): # excluding the input layer\n",
    "            if layer == 0:\n",
    "                mlp = MLP(input_dim, hidden_dim, hidden_dim)\n",
    "            else:\n",
    "                mlp = MLP(hidden_dim, hidden_dim, hidden_dim)\n",
    "            self.ginlayers.append(GINConv(mlp, learn_eps=False)) # set to True if learning epsilon\n",
    "            self.batch_norms.append(nn.BatchNorm1d(hidden_dim))\n",
    "        # linear functions for graph sum poolings of output of each layer\n",
    "        self.linear_prediction = nn.ModuleList()\n",
    "        for layer in range(num_layers):\n",
    "            if layer == 0:\n",
    "                self.linear_prediction.append(nn.Linear(input_dim, output_dim))\n",
    "            else:\n",
    "                self.linear_prediction.append(nn.Linear(hidden_dim, output_dim))\n",
    "        self.drop = nn.Dropout(0.5)\n",
    "        if pooling == 'sum'\n",
    "            self.pool = SumPooling() # change to mean readout (AvgPooling) on social network datasets\n",
    "        elif pooling == 'avg':\n",
    "            self.pool = AvgPooling()\n",
    "        else:\n",
    "            self.pool = MaxPooling()\n",
    "\n",
    "    def forward(self, g, h):\n",
    "        # list of hidden representation at each layer (including the input layer)\n",
    "        hidden_rep = [h]\n",
    "        for i, layer in enumerate(self.ginlayers):\n",
    "            h = layer(g, h)\n",
    "            h = self.batch_norms[i](h)\n",
    "            h = F.relu(h)\n",
    "            hidden_rep.append(h)\n",
    "        score_over_layer = 0\n",
    "        # perform graph sum pooling over all nodes in each layer\n",
    "        for i, h in enumerate(hidden_rep):\n",
    "            pooled_h = self.pool(g, h)\n",
    "            score_over_layer += self.drop(self.linear_prediction[i](pooled_h))\n",
    "        return score_over_layer\n",
    "    \n",
    "def split_fold10(labels, fold_idx=0):\n",
    "    skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=0)\n",
    "    idx_list = []\n",
    "    for idx in skf.split(np.zeros(len(labels)), labels):\n",
    "        idx_list.append(idx)\n",
    "    train_idx, valid_idx = idx_list[fold_idx]\n",
    "    return train_idx, valid_idx\n",
    "\n",
    "def evaluate(dataloader, device, model):\n",
    "    model.eval()\n",
    "    total = 0\n",
    "    total_correct = 0\n",
    "    for batch, (batched_graph, labels) in enumerate(tqdm(train_loader)):\n",
    "        batched_graph = batched_graph.to(device)\n",
    "        labels = labels.to(device)\n",
    "        feat = batched_graph.ndata.pop('x')\n",
    "        total += len(labels)\n",
    "        logits = model(batched_graph, feat.view(len(feat), -1))\n",
    "        _, predicted = torch.max(logits, 1)\n",
    "        total_correct += (predicted == labels).sum().item()\n",
    "    acc = 1.0 * total_correct / total\n",
    "    return acc\n",
    "\n",
    "def train(train_loader, val_loader, test_loader, device, model):\n",
    "    # loss function, optimizer and scheduler\n",
    "    loss_fcn = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=50, gamma=0.5)\n",
    "    \n",
    "    # training loop    \n",
    "    for epoch in range(350):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        for batch, (batched_graph, labels) in enumerate(tqdm(train_loader)):\n",
    "            batched_graph = batched_graph.to(device)\n",
    "            #print(batch, labels, type(labels))\n",
    "            labels = labels.to(device)\n",
    "            # print(labels)\n",
    "            feat = batched_graph.ndata.pop('x')\n",
    "            # print(feat.view(50,-1).shape)\n",
    "            logits = model(batched_graph, feat.view(len(feat), -1))\n",
    "            # print(logits)\n",
    "            # print(logits.shape, labels.shape)\n",
    "            loss = loss_fcn(logits, labels)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        scheduler.step()\n",
    "        train_acc = evaluate(train_loader, device, model)\n",
    "        valid_acc = evaluate(val_loader, device, model)\n",
    "        test_acc = evaluate(test_loader, device, model)\n",
    "        print(\"Epoch {:05d} | Loss {:.4f} | Train Acc. {:.4f} | Validation Acc. {:.4f}| Test Acc. {:.4f} \"\n",
    "              . format(epoch, total_loss / (batch + 1), train_acc, valid_acc, test_acc))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "#     parser = argparse.ArgumentParser()\n",
    "#     parser.add_argument('--dataset', type=str, default=\"MUTAG\",\n",
    "#                         choices=['MUTAG', 'PTC', 'NCI1', 'PROTEINS'],\n",
    "#                         help='name of dataset (default: MUTAG)')\n",
    "#     args = parser.parse_args()\n",
    "    print(f'Training with DGL built-in GINConv module with a fixed epsilon = 0')\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    # load and split dataset\n",
    "    # dataset = GINDataset(args.dataset, self_loop=True, degree_as_nlabel=False) # add self_loop and disable one-hot encoding for input features\n",
    "    dataset = HomoStrucBackdoorDataset()\n",
    "    dataset.load()\n",
    "    labels  = [y for y in dataset.iter_y()]\n",
    "    \n",
    "    # train_idx, val_idx = split_fold10(labels)\n",
    "    # print(train_idx, val_idx)\n",
    "    \n",
    "    # create dataloader\n",
    "    train_loader = GraphDataLoader(dataset, batch_size=4, pin_memory=torch.cuda.is_available())\n",
    "    val_dataset = HomoStrucBackdoorDataset(mode='valid')\n",
    "    val_loader = GraphDataLoader(val_dataset, batch_size=4, pin_memory=torch.cuda.is_available())\n",
    "    test_dataset = HomoStrucBackdoorDataset(mode='test')\n",
    "    test_loader = GraphDataLoader(test_dataset, batch_size=4, pin_memory=torch.cuda.is_available())\n",
    "    # create GIN model\n",
    "    in_size = 512 * 513\n",
    "    gin_dataset = GINDataset('MUTAG', self_loop=True, degree_as_nlabel=False) # add self_loop and disable one-hot encoding for input features\n",
    "    # print(gin_dataset.dim_nfeats)\n",
    "    out_size = 2\n",
    "    model = GIN(in_size, 16, out_size).to(device)\n",
    "\n",
    "    # model training/validating\n",
    "    print('Training Procedure...')\n",
    "    train(train_loader, val_loader, test_loader, device, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c7752719",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "(Graph(num_nodes=200, num_edges=2180,\n",
      "      ndata_schemes={'x': Scheme(shape=(512, 513), dtype=torch.float32)}\n",
      "      edata_schemes={}), tensor([0, 0, 1, 0]))\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'DGLHeteroGraph' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-53-88808dbf9850>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatched_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatched_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'DGLHeteroGraph' has no len()"
     ]
    }
   ],
   "source": [
    "train_loader = GraphDataLoader(dataset, batch_size=4, pin_memory=torch.cuda.is_available())\n",
    "for batch, (batched_graph, labels) in enumerate(train_loader):\n",
    "    print(batch, )\n",
    "    print((batched_graph, labels))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0cd8329",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mntd-real",
   "language": "python",
   "name": "mntd-real"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
